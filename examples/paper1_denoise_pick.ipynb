{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf73e7fe",
   "metadata": {},
   "source": [
    "# Enhanced Offshore Earthquake Monitoring by DAS Denoising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4d7ccf",
   "metadata": {},
   "source": [
    "**Authors: Qibin Shi (qibins@uw.edu/ qshi003@e.ntu.edu.sg), Marine Denolle (mdenolle@uw.edu)**\n",
    "\n",
    "Comments obtained from Ethan Williams and Kuan-Fu Feng\n",
    "\n",
    "This notebook is created originally to analyze the Alaska DAS data maintained by the UWQuake research group.\n",
    "\n",
    "It has 4 sessions. Each session will save the essential results for the next steps. \n",
    "\n",
    "For optimized experience, we recommend:\n",
    "\n",
    "1. GPU\n",
    "\n",
    "2. H5 file format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4c57bc",
   "metadata": {},
   "source": [
    "## 0. Modules and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6878d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/denoiser/')\n",
    "import h5py\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from obspy import read_events\n",
    "from obspy.taup import TauPyModel\n",
    "from obspy.core import UTCDateTime\n",
    "from distaz import DistAz\n",
    "from joblib import Parallel, delayed\n",
    "import scipy.signal as sgn\n",
    "from scipy.signal import filtfilt, butter\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.integrate import cumulative_trapezoid\n",
    "\n",
    "from das_util import *\n",
    "from das_denoise_models import unet\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "matplotlib.rcParams['font.size'] = 20\n",
    "\n",
    "### Parameters for DAS \n",
    "sample_rate = 25\n",
    "dchan = 9.5714\n",
    "ch_max = 4500  # max channel of each cable (4500 or 6000)\n",
    "ch_itv=2  # channels are downsampled for faster picking\n",
    "\n",
    "### Directories and files\n",
    "raw_dir = '/fd1/QibinShi_data/akdas/qibin_data/'\n",
    "out_dir = raw_dir + 'largerEQ_plots_test_picking_dec_ch' + str(ch_max) + '/'\n",
    "record_time_file = 'recording_times_larger.csv'\n",
    "qml = raw_dir + 'ak_Dec1_31_a120b065.xml'\n",
    "\n",
    "# out_dir = raw_dir + 'plots_test_picking_dec_ch4500_withSNRstd/'\n",
    "# record_time_file = 'recording_times_smaller.csv'\n",
    "# qml = raw_dir + 'ak_Dec1_31.xml'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa48bce",
   "metadata": {},
   "source": [
    "#### Time differece between TERRA and KKFLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "395effc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 0.32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with h5py.File('/fd1/QibinShi_data/akdas/qibin_data/Dec2023/kkfls_2023-12-02_08.30.57_UTC.h5', 'r') as f:\n",
    "    timestamp_ffkls = f['Acquisition']['Raw[0]']['RawDataTime'][:]\n",
    "    gauge_len = f['Acquisition'].attrs['GaugeLength']\n",
    "    attrs_raw0 = dict(f['Acquisition']['Raw[0]'].attrs)\n",
    "    attrs = dict(f['Acquisition'].attrs)\n",
    "\n",
    "with h5py.File('/fd1/QibinShi_data/akdas/qibin_data/Dec2023/terra_2023-12-02_08.30.56_UTC.h5', 'r') as f:\n",
    "    timestamp_terra = f['Acquisition']['Raw[0]']['RawDataTime'][:]\n",
    "\n",
    "times_ffkls=[datetime.datetime.utcfromtimestamp(time1/1000000) for time1 in timestamp_ffkls]\n",
    "times_terra=[datetime.datetime.utcfromtimestamp(time1/1000000) for time1 in timestamp_terra]\n",
    "\n",
    "## get the difference in start time of two fibers\n",
    "terra_early = (timestamp_ffkls[0] - timestamp_terra[0]) / 1e6\n",
    "terra_early_pt = int(terra_early * 25)\n",
    "terra_early_pt, terra_early"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b60a4c",
   "metadata": {},
   "source": [
    "## 1. How Raw DAS Looks Like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad743a01",
   "metadata": {},
   "source": [
    "Where is the data file? size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66481fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47G\t/fd1/QibinShi_data/akdas/qibin_data/KKFLStill2024_02_16.hdf5\n",
      "8.0G\t/fd1/QibinShi_data/akdas/qibin_data/KKFLStill2024_02_24.hdf5\n",
      "47G\t/fd1/QibinShi_data/akdas/qibin_data/TERRAtill2024_02_16.hdf5\n",
      "8.0G\t/fd1/QibinShi_data/akdas/qibin_data/TERRAtill2024_02_24.hdf5\n"
     ]
    }
   ],
   "source": [
    "! du -sh {raw_dir+\"*till2024_02*\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ce92f5",
   "metadata": {},
   "source": [
    "### Read DAS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806ae000",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge two DAS cables\n",
    "data_terra = raw_dir + 'TERRAtill2024_02_24.hdf5'  ## testing data (larger), and smaller ones in *02_16*\n",
    "data_kkfls = raw_dir + 'KKFLStill2024_02_24.hdf5'\n",
    "# data_terra = raw_dir + 'TERRAtill2023_11_11.hdf5'  ## training data\n",
    "# data_kkfls = raw_dir + 'KKFLStill2023_11_11.hdf5'\n",
    "with h5py.File(data_terra, 'r') as f:\n",
    "    quake1 = f['raw_quake'][:,:ch_max,:]  \n",
    "with h5py.File(data_kkfls, 'r') as f:\n",
    "    quake2 = f['raw_quake'][:,:ch_max,:]\n",
    "    \n",
    "### concatenate cable 1 and cable 2 along channels\n",
    "rawdata = np.append(quake2[:, ::-1, :], quake1[:,:,:], axis=1)\n",
    "rawdata = np.nan_to_num(rawdata)\n",
    "\n",
    "### Bandpass filter\n",
    "b, a = butter(4, (0.5, 12), fs=sample_rate, btype='bandpass')\n",
    "filt = filtfilt(b, a, rawdata, axis=2)\n",
    "rawdata = filt / np.std(filt, axis=(1,2), keepdims=True)  ## Rawdata w.r.t. Denoised "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69996757",
   "metadata": {},
   "source": [
    "### Earthquake metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996826e0",
   "metadata": {},
   "source": [
    "1. Magnitude\n",
    "2. Location\n",
    "3. Origin time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41308f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = read_events(qml)\n",
    "\n",
    "print(len(cat), 'records of metadata')\n",
    "print(len(rawdata), 'earthquake images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a9205c",
   "metadata": {},
   "source": [
    "### Predict the P and S time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e23afdc",
   "metadata": {},
   "source": [
    "What do we need?\n",
    "1. Cable locations  -- relative times\n",
    "2. Recording time  -- absolute times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6f0abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cable coordinates from Ethan Williams\n",
    "kkfls = pd.read_csv('cable_geometry/KKFLS_coords.xycz',header=None,names=['lon','lat','cha','dep'],delim_whitespace=True)\n",
    "terra = pd.read_csv('cable_geometry/TERRA_coords.xycz',header=None,names=['lon','lat','cha','dep'],delim_whitespace=True)\n",
    "\n",
    "### calculate the along-cable distance from reference channels\n",
    "### Here the 500th channels of both cables are reference points\n",
    "kkfls = kkfls[(kkfls['cha']>499) & (kkfls['cha']<(500+ch_max))]\n",
    "terra = terra[(terra['cha']>499) & (terra['cha']<(500+ch_max))]\n",
    "kkfls['dist'] = (500 - kkfls['cha']) * dchan\n",
    "terra['dist'] = (terra['cha'] - 500) * dchan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa9578f",
   "metadata": {},
   "source": [
    "### Plot DAS and P/S times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05faae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline   ## change to agg when savefig\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "matplotlib.rcParams['font.size'] = 20\n",
    "### predict phases for a given event in the catalog\n",
    "event_number =11  ## for testing the best model\n",
    "kkfls, terra, mag0,lon0,lat0,dep0,ort0 = akdas_tpts(cat, event_number, kkfls, terra, terra_early)\n",
    "\n",
    "print(\"time is calculated\")\n",
    "### Shift for recording time\n",
    "df = pd.read_csv(raw_dir + record_time_file).iloc[event_number]\n",
    "start_times = df['record_time']\n",
    "shift_time = cat[event_number].origins[0].time - UTCDateTime.strptime(start_times, format='decimator2_%Y-%m-%d_%H.%M.%S_UTC.h5') \n",
    "        \n",
    "\n",
    "### plot\n",
    "time_data = rawdata[event_number]\n",
    "# time_data = mul_denoised[event_number]\n",
    "# time_data = one_denoised[event_number]\n",
    "time_data = time_data - np.mean(time_data, axis=1, keepdims=True)\n",
    "\n",
    "print(\"plotting\")\n",
    "x = np.arange(time_data.shape[1])/sample_rate\n",
    "y = np.arange(0-time_data.shape[0]/2, time_data.shape[0]/2)*dchan/1000\n",
    "cmap=matplotlib.colormaps['RdBu']\n",
    "bound = np.percentile(np.fabs(rawdata[event_number]), 90)/2\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 7), constrained_layout=True,\n",
    "                gridspec_kw={'width_ratios': [1, 3], 'wspace': 0.1}, dpi=300)\n",
    "plt.title(f'Event M{mag0}   [{lat0}, {lon0}, {dep0}]   {ort0}',fontsize=22)\n",
    "\n",
    "### full array\n",
    "print(\"fig1\")\n",
    "ax[0].pcolormesh(x+terra_early, y[:ch_max], time_data[:ch_max,:], shading='auto', vmin=-bound, vmax=bound, cmap=cmap, rasterized=True)\n",
    "ax[0].pcolormesh(x, y[ch_max:], time_data[ch_max:,:], shading='auto', vmin=-bound, vmax=bound, cmap=cmap, rasterized=True)\n",
    "ax[0].plot(kkfls['ts']+shift_time+terra_early, kkfls['dist']/1000, color='green', linestyle='--', lw=1)\n",
    "ax[0].plot(kkfls['tp']+shift_time+terra_early, kkfls['dist']/1000, color='orange', linestyle='--', lw=1)\n",
    "ax[0].plot(terra['ts']+shift_time, terra['dist']/1000, color='green', linestyle='--', lw=1)\n",
    "ax[0].plot(terra['tp']+shift_time, terra['dist']/1000, color='orange', linestyle='--', lw=1)\n",
    "ax[0].set_xlabel(\"Time (s)\", fontsize=20); \n",
    "ax[0].set_ylabel(\"Distance (km)\", fontsize=20)\n",
    "ax[0].set_xlim(0, 25)\n",
    "\n",
    "pty=np.arange(5000,9000,1000)\n",
    "ptx=(((pty-4500) * dchan / 5500 + 15) * 25).astype(int)\n",
    "ax[0].scatter(x[ptx], y[pty], s=100, marker='o',c='k',alpha=0.9)\n",
    "\n",
    "### sub array\n",
    "print(\"fig2\")\n",
    "st_terra = 0\n",
    "ch1=ch_max +st_terra\n",
    "ch2=ch1 + 1500\n",
    "y= y[ch1:ch2]\n",
    "x= x[15*25:25*25]\n",
    "time_data=time_data[ch1:ch2, 15*25:25*25]\n",
    "# ax[0].plot([x[5],x[5],x[-5],x[-5],x[5]],\n",
    "#         [y[0],y[-1],y[-1],y[0],y[0]], \n",
    "#         color='orange', linestyle='-', lw=5)\n",
    "\n",
    "img=ax[1].pcolormesh(x, y, time_data, shading='auto', vmin=-bound, vmax=bound, cmap=cmap, rasterized=True)\n",
    "ax[1].plot(terra['ts'].iloc[st_terra:st_terra+1500]+shift_time, terra['dist'].iloc[st_terra:st_terra+1500]/1000, color='green', linestyle='--', lw=1)\n",
    "ax[1].plot(terra['tp'].iloc[st_terra:st_terra+1500]+shift_time, terra['dist'].iloc[st_terra:st_terra+1500]/1000, color='orange', linestyle='--', lw=1)\n",
    "# cbr=plt.colorbar(img, aspect=50, ax=ax[1]); cbr.set_label('amplitude', fontsize = 20)\n",
    "ax[1].set_xlabel(\"Time (s)\", fontsize=20)\n",
    "ax[1].set_xlim(15, 25)\n",
    "\n",
    "\n",
    "print(\"fig done\", bound)\n",
    "\n",
    "# plt.savefig(out_dir + 'event_mul_test.pdf', format='pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9104be99",
   "metadata": {},
   "source": [
    "## 2. How the Denoiser Works?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41489700",
   "metadata": {},
   "source": [
    "### Unet model, trained on DAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fc2eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Initialize the U-net model \"\"\"\n",
    "devc = try_gpu(i=1)\n",
    "\n",
    "model_1 = unet(1, 16, 1024, factors=(5, 3, 2, 2), use_att=False)\n",
    "model_1 = nn.DataParallel(model_1, device_ids=[1,2,3])\n",
    "model_1.to(devc)\n",
    "\n",
    "\"\"\" Load the pretrained weights \"\"\"\n",
    "model_1.load_state_dict(torch.load('../models/checkpoint_noatt_LRdecays0.8_mask0.5_raw2raw_chmax4500.pt'))  # raw2raw\n",
    "# model_1.load_state_dict(torch.load('../models/checkpoint_noatt_LRdecays0.8_mask0.5_raw2fk_chmax4500.pt'))  # raw2fk\n",
    "model_1.eval() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aacfcf",
   "metadata": {},
   "source": [
    "Minimal showcase of usage, don't run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0976d2f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X=rawdata[:,:,:].astype(np.float32)\n",
    "X = torch.from_numpy(X).to(devc)\n",
    "\n",
    "### denoise\n",
    "with torch.no_grad():\n",
    "    ### raw2raw\n",
    "    oneDenoise_1 = model_1(X)\n",
    "    mulDenoise_1 = model_1(oneDenoise_1)\n",
    "    mulDenoise_1 = model_1(mulDenoise_1)\n",
    "    mulDenoise_1 = model_1(mulDenoise_1)\n",
    "\n",
    "### convert back to numpy, trim edges\n",
    "rawdata_trim = X.to('cpu').numpy()\n",
    "oneDenoise_1 = oneDenoise_1.to('cpu').numpy()\n",
    "mulDenoise_1 = mulDenoise_1.to('cpu').numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fc17dd",
   "metadata": {},
   "source": [
    "### Denoise many earthquakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1008a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1 = cat[:]\n",
    "inp_data = rawdata[:,:,:]\n",
    "one_denoised = np.zeros_like(inp_data)\n",
    "mul_denoised = np.zeros_like(inp_data)\n",
    "\n",
    "for eid in np.arange(len(inp_data)):\n",
    "    one_denoised[eid,:,:], mul_denoised[eid,:,:] = Denoise_largeDAS(inp_data[eid], \n",
    "                                                                    model_1, \n",
    "                                                                    devc, \n",
    "                                                                    repeat=4, \n",
    "                                                                    norm_batch=False)\n",
    "\n",
    "%matplotlib inline\n",
    "# vizRawDenoise(inp_data, one_denoised, mul_denoised, index=range(len(inp_data)), model=\"raw-raw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f153c78b",
   "metadata": {},
   "source": [
    "### Plot frequency-wavenumber before and after denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b205daaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from das_util import next_power_of_2, fk_filter_2cones\n",
    "event_number =11 \n",
    "st_terra = 0\n",
    "# ch1=ch_max +st_terra\n",
    "ch1=0\n",
    "ch2=ch1 + 4500\n",
    "\n",
    "sub_rawdata = rawdata[event_number, ch1:ch2, 0*25:60*25]\n",
    "sub_rawdata = sub_rawdata - np.mean(sub_rawdata, axis=1, keepdims=True)\n",
    "sub_denoise = mul_denoised[event_number, ch1:ch2, 0*25:60*25]\n",
    "sub_denoise = sub_denoise - np.mean(sub_denoise, axis=1, keepdims=True)\n",
    "\n",
    "_, _, fk_rawdata = fk_filter_2cones(sub_rawdata.T, w1=0.003, w2=0.003, cone1=True, cone2=True)\n",
    "_, _, fk_denoise = fk_filter_2cones(sub_denoise.T, w1=0.003, w2=0.003, cone1=True, cone2=True)\n",
    "\n",
    "f0 = np.fft.fftshift(np.fft.fftfreq(next_power_of_2(1500),d=1./sample_rate))\n",
    "k0 = np.fft.fftshift(np.fft.fftfreq(next_power_of_2(4500),d=dchan))\n",
    "df = f0[1]-f0[0]\n",
    "dk = k0[1]-k0[0]\n",
    "\n",
    "%matplotlib agg\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "matplotlib.rcParams['font.size'] = 20\n",
    "\n",
    "amps = np.log10(np.abs(fk_denoise)).flatten()\n",
    "q1=np.percentile(amps, q=20)\n",
    "q2=np.percentile(amps, q=99)\n",
    "\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 9), constrained_layout=True)\n",
    "ax[0].set_title(f'Event M{mag0}   [{lat0}, {lon0}, {dep0}]   {ort0}',fontsize=22)\n",
    "cmap=matplotlib.colormaps['RdBu']\n",
    "\n",
    "im=ax[0].pcolormesh(k0, f0, np.log10(np.abs(fk_rawdata)), shading='auto', vmax=q2, vmin=q1, cmap=cmap.reversed(), rasterized=True)\n",
    "plt.colorbar(im, ax=ax[0], aspect=50)\n",
    "\n",
    "\n",
    "im=ax[1].pcolormesh(k0, f0, np.log10(np.abs(fk_denoise)), shading='auto', vmax=q2, vmin=q1, cmap=cmap.reversed(), rasterized=True)\n",
    "plt.colorbar(im, ax=ax[1], aspect=50)\n",
    "\n",
    "ax[0].set_ylabel(\"Frequency(Hz)\", fontsize=20)\n",
    "ax[1].set_xlabel(\"Wavenumber (1/m)\", fontsize=20)\n",
    "ax[1].set_ylabel(\"Frequency(Hz)\", fontsize=20)\n",
    "ax[1].set_xlim(-0.04, 0.04)\n",
    "ax[0].set_xlim(-0.04, 0.04)\n",
    "# plt.savefig(out_dir + 'event_fk_kkfls.pdf', format='pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a195af",
   "metadata": {},
   "source": [
    "### Plot spectra of noise and signal before and after denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60e8ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "matplotlib.rcParams['font.size'] = 20\n",
    "\n",
    "plt.close('all')\n",
    "fig,ax = plt.subplots(1,2,figsize=(25,12))\n",
    "\n",
    "colors = matplotlib.colormaps['Blues'](np.linspace(0.2, 1, 5))\n",
    "\n",
    "for i, chan in tqdm(enumerate(np.array([5000, 6000, 7000, 8000, 9000]))):\n",
    "\n",
    "    ptx=(((chan-4500) * dchan / 5500 + 8) * 25).astype(int)\n",
    "\n",
    "    print(ptx)\n",
    "\n",
    "    \n",
    "    ### Correct raw data to strain\n",
    "    trs_raw = rawdata[1,chan-500:chan,ptx:ptx+500].astype(float) * (1550 * 1e-9) / (0.78 * 4 * np.pi * 1.4682 * 23.9)\n",
    "    trs_den = mul_denoised[1,chan-500:chan,ptx:ptx+500].astype(float) * (1550 * 1e-9) / (0.78 * 4 * np.pi * 1.4682 * 23.9)\n",
    "    \n",
    "    H,xm,ym = ppsd(trs_raw,sample_rate,0.015,12)\n",
    "    xm,mn,vr = psd_stats(H,xm,ym)\n",
    "    ax[0].plot(1/xm, mn,linewidth=5, label='%.1f km' % ((chan-4500-250)*dchan*1e-3), zorder=2, color=colors[int(abs(i))])\n",
    "\n",
    "    # if i == 0:\n",
    "    #     img=ax[0].pcolormesh(1/xm,ym,H.T,cmap='hot_r',vmin=0,vmax=0.2, zorder=1)\n",
    "\n",
    "    H,xm,ym = ppsd(trs_den,sample_rate,0.015,12)\n",
    "    xm,mn,vr = psd_stats(H,xm,ym)\n",
    "    ax[1].plot(1/xm, mn*2,linewidth=5, label='%.1f km' % ((chan-4500-250)*dchan*1e-3), zorder=2, color=colors[int(abs(i))])\n",
    "    \n",
    "    # if i == 0:\n",
    "    #     img=ax[1].pcolormesh(1/xm,ym,H.T,cmap='hot_r',vmin=0,vmax=0.2, zorder=1)\n",
    "\n",
    "    if i > 2:\n",
    "        \n",
    "        ## noise window\n",
    "        trs = rawdata[1,chan-500:chan, ptx-350:ptx+150].astype(float) * (1550 * 1e-9) / (0.78 * 4 * np.pi * 1.4682 * 23.9)\n",
    "        \n",
    "        H,xm,ym = ppsd(trs,sample_rate,0.015,12)\n",
    "        xm,mn,vr = psd_stats(H,xm,ym)\n",
    "        ax[0].plot(1/xm,mn,'k',linewidth=5, zorder=2, linestyle='dotted', color=colors[i])\n",
    "\n",
    "        trs = mul_denoised[1,chan-500:chan, ptx-350:ptx+150].astype(float) * (1550 * 1e-9) / (0.78 * 4 * np.pi * 1.4682 * 23.9)\n",
    "        \n",
    "        H,xm,ym = ppsd(trs,sample_rate,0.015,12)\n",
    "        xm,mn,vr = psd_stats(H,xm,ym)\n",
    "        ax[1].plot(1/xm,mn*2,'k',linewidth=5, zorder=2, linestyle='dotted', color=colors[i])\n",
    "            \n",
    "ax[0].set_xscale('log')\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].set_xlim(1/12.5, 4)\n",
    "ax[0].set_ylim(1e-22,3e-17) \n",
    "ax[1].set_xscale('log')\n",
    "ax[1].set_yscale('log')   \n",
    "ax[1].set_xlim(1/12.5, 4)\n",
    "ax[1].set_ylim(1e-22,3e-17)\n",
    "ax[0].set_xlabel('Period (s)')\n",
    "ax[0].set_ylabel('PSD rel. strain ^2')\n",
    "ax[1].set_xlabel('Period (s)')\n",
    "ax[1].set_ylabel('PSD rel. strain ^2')\n",
    "\n",
    "ax[0].grid(which='major', color='#DDDDDD', linewidth=3, zorder=0)\n",
    "ax[0].grid(which='minor', color='#EEEEEE', linewidth=2, linestyle='--', zorder=0)\n",
    "ax[1].grid(which='major', color='#DDDDDD', linewidth=3, zorder=0)\n",
    "ax[1].grid(which='minor', color='#EEEEEE', linewidth=2, linestyle='--', zorder=0)\n",
    "plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(out_dir + 'event_spec1.pdf', format='pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b417fce",
   "metadata": {},
   "source": [
    "### Plot small space-time to show before and after denoising "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a31b242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vizRawDenoise_lite(in_data, oneDenoise, mulDenoise, sample_rate=25, dchan=10, index=[0,1], model=\"MAE\"):\n",
    "    \"\"\"\n",
    "    in_data, oneDenoise, mulDenoise: 3D -- [event, channel, time]\n",
    "    index: list, subset of the events\n",
    "    model: string, descriptions about the model\n",
    "    \"\"\"\n",
    "    len1, len2 = oneDenoise[0].shape[0], oneDenoise[0].shape[1]\n",
    "    x, y = np.arange(len2)/sample_rate, np.arange(0-len1/2, len1/2)*dchan/1000\n",
    "    rawdata = process_3d_array(in_data, len1=len1, len2=len2)\n",
    "    \n",
    "    matplotlib.rcParams['font.size'] = 20\n",
    "\n",
    "    for j in index:\n",
    "        bound = np.percentile(np.fabs(in_data[j]), 80)\n",
    "        cmp = matplotlib.colormaps['RdBu']\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(12, 3.5), constrained_layout=True)\n",
    "\n",
    "        img=ax[0].pcolormesh(x, y, rawdata[j], shading='auto', vmin=-bound, vmax=bound, cmap=cmap, rasterized=True)\n",
    "        ax[1].pcolormesh(x, y, mulDenoise[j], shading='auto', vmin=-bound, vmax=bound, cmap=cmap)\n",
    "        ax[0].set_title(\"Raw data #\"+str(j))\n",
    "        ax[1].set_title(model+\" Denoised\")\n",
    "        ax[0].set_ylabel('Distance (km)')\n",
    "        ax[0].set_xlabel('Time (s)')\n",
    "        ax[1].set_xlabel('Time (s)')\n",
    "\n",
    "        plt.colorbar(img, ax=ax[1], aspect=20)\n",
    "        plt.savefig(out_dir + 'event'+ str(model)+'PandS.pdf', format='pdf', dpi=300)\n",
    "\n",
    "%matplotlib agg\n",
    "vizRawDenoise_lite(inp_data[:,3600:3900,:], one_denoised[:,3600:3900,:], mul_denoised[:,3600:3900,:], index=[18], model=\"1\")\n",
    "vizRawDenoise_lite(inp_data[:,0:300,:], one_denoised[:,0:300,:], mul_denoised[:,0:300,:], index=[21], model=\"2\")\n",
    "vizRawDenoise_lite(inp_data[:,3000:3300,:], one_denoised[:,3000:3300,:], mul_denoised[:,3000:3300,:], index=[21], model=\"3\")\n",
    "vizRawDenoise_lite(inp_data[:,3500:3800,:], one_denoised[:,3500:3800,:], mul_denoised[:,3500:3800,:], index=[21], model=\"4\")\n",
    "vizRawDenoise_lite(inp_data[:,3800:4100,:], one_denoised[:,3800:4100,:], mul_denoised[:,3800:4100,:], index=[34], model=\"5\")\n",
    "vizRawDenoise_lite(inp_data[:,900:1200,:], one_denoised[:,900:1200,:], mul_denoised[:,900:1200,:], index=[43], model=\"6\")\n",
    "vizRawDenoise_lite(inp_data[:,7000:7300,:], one_denoised[:,7000:7300,:], mul_denoised[:,7000:7300,:], index=[43], model=\"7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d44887",
   "metadata": {},
   "source": [
    "### Save as H5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35c3e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save denoised data\n",
    "with h5py.File(out_dir + 'das_raw_denoised.hdf5', 'w') as f:\n",
    "    f.create_dataset(\"input_data\", data=inp_data)\n",
    "    f.create_dataset(\"one_denoise\", data=one_denoised)\n",
    "    f.create_dataset(\"mul_denoise\", data=mul_denoised)\n",
    "cat1.write(out_dir + \"denoised_catalog.xml\", format=\"QUAKEML\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c309fa",
   "metadata": {},
   "source": [
    "## 3. Pick Phases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038dad68",
   "metadata": {},
   "source": [
    "### Interpolate DAS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1114e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read raw and denoised DAS\n",
    "with h5py.File(out_dir + 'das_raw_denoised.hdf5', 'r') as f:\n",
    "    inp_data = f[\"input_data\"][:]\n",
    "    one_denoised = f[\"one_denoise\"][:]\n",
    "    mul_denoised = f[\"mul_denoise\"][:]\n",
    "\n",
    "cat1 = read_events(out_dir + \"denoised_catalog.xml\")\n",
    "\n",
    "### The phase picker needs 6000 time points as input\n",
    "interp_func = interp1d(np.linspace(0, 1, 1500), inp_data, axis=-1, kind='linear')\n",
    "interpolated_image = interp_func(np.linspace(0, 1, 6000))\n",
    "interp_func = interp1d(np.linspace(0, 1, 1500), one_denoised, axis=-1, kind='linear')\n",
    "interpolated_onedenoised = interp_func(np.linspace(0, 1, 6000))\n",
    "interp_func = interp1d(np.linspace(0, 1, 1500), mul_denoised, axis=-1, kind='linear')\n",
    "interpolated_muldenoised = interp_func(np.linspace(0, 1, 6000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2f5680",
   "metadata": {},
   "source": [
    "### Set up phase picker\n",
    "Emsemble-learning framework for picking (Yuan et al, 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073a07ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ML picker parameters\n",
    "paras_semblance = {'dt':0.01, \n",
    "                   'semblance_order':2, \n",
    "                   'window_flag':True, \n",
    "                   'semblance_win':0.5, \n",
    "                   'weight_flag':'max'}\n",
    "\n",
    "### Download models\n",
    "devcc = try_gpu(i=1)\n",
    "\n",
    "pn_ethz_model = sbm.EQTransformer.from_pretrained(\"ethz\")\n",
    "pn_instance_model = sbm.EQTransformer.from_pretrained(\"instance\")\n",
    "pn_scedc_model = sbm.EQTransformer.from_pretrained(\"scedc\")\n",
    "pn_stead_model = sbm.EQTransformer.from_pretrained(\"stead\")\n",
    "pn_geofon_model = sbm.EQTransformer.from_pretrained(\"geofon\")\n",
    "pn_neic_model = sbm.EQTransformer.from_pretrained(\"neic\")\n",
    "\n",
    "pn_ethz_model.to(devcc)\n",
    "pn_scedc_model.to(devcc)\n",
    "pn_neic_model.to(devcc)\n",
    "pn_geofon_model.to(devcc)\n",
    "pn_stead_model.to(devcc)\n",
    "pn_instance_model.to(devcc)\n",
    "\n",
    "list_models = [pn_ethz_model,pn_scedc_model,pn_neic_model,\n",
    "               pn_geofon_model,pn_stead_model,pn_instance_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118126f3",
   "metadata": {},
   "source": [
    "### Pick many earthquaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ed315",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Nevent=len(inp_data)\n",
    "\n",
    "fs=100\n",
    "ch_itv=2  # data are downsampled to pick\n",
    "dchan=9.5714\n",
    "\n",
    "nsta = interpolated_image.shape[1] // ch_itv\n",
    "raw_picks = np.zeros([Nevent, nsta, 2, 2], dtype = np.float32)\n",
    "one_picks = np.zeros([Nevent, nsta, 2, 2], dtype = np.float32)\n",
    "mul_picks = np.zeros([Nevent, nsta, 2, 2], dtype = np.float32)\n",
    "pred_picks = np.zeros([Nevent, nsta, 2], dtype = np.float32)\n",
    "\n",
    "for i in tqdm(np.arange(Nevent)):\n",
    "    \n",
    "    ### Predict arrivals\n",
    "    fiber1, fiber2, _,_,_,_,_ = akdas_tpts(cat1, i, kkfls, terra, terra_early)\n",
    "    array = pd.concat([fiber1.iloc[::-1], fiber2], axis=0)\n",
    "    pred_picks[i, :, 0] = array['tp'].values[::ch_itv]\n",
    "    pred_picks[i, :, 1] = array['ts'].values[::ch_itv]\n",
    "    array_dist = array['dist']/1000\n",
    "    \n",
    "    ### Pick RAW data\n",
    "    image = np.nan_to_num(interpolated_image[i,::ch_itv,:])\n",
    "    raw_picks[i,:,:,:] = apply_elep(image, list_models, fs, paras_semblance, devcc)\n",
    "    \n",
    "    ### Pick oneDENOISED  \n",
    "    image =np.nan_to_num(interpolated_onedenoised[i,::ch_itv,:])\n",
    "    one_picks[i,:,:,:] = apply_elep(image, list_models, fs, paras_semblance, devcc)\n",
    "    \n",
    "    ### Pick mulDENOISED \n",
    "    image = np.nan_to_num(interpolated_muldenoised[i,::ch_itv,:])\n",
    "    mul_picks[i,:,:,:] = apply_elep(image, list_models, fs, paras_semblance, devcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40fbc10",
   "metadata": {},
   "source": [
    "### Save results to H5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723356a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(out_dir + 'phase_picks.hdf5', 'w') as f:\n",
    "    f.create_dataset(\"raw_alldata_picks\", data=raw_picks)\n",
    "    f.create_dataset(\"one_denoise_picks\", data=one_picks)\n",
    "    f.create_dataset(\"mul_denoise_picks\", data=mul_picks)\n",
    "    f.create_dataset(\"predicted_picks\", data=pred_picks)\n",
    "    f.create_dataset(\"array_dist\", data=array_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd7474b",
   "metadata": {},
   "source": [
    "## 4. Quality Control and Visualization \n",
    "### Read picks and DAS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ce9592",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read phase picks from the previous session\n",
    "with h5py.File(out_dir + 'phase_picks_400_555.hdf5', 'r') as f:\n",
    "    raw_picks = f[\"raw_alldata_picks\"][:]\n",
    "    one_picks = f[\"one_denoise_picks\"][:]\n",
    "    mul_picks = f[\"mul_denoise_picks\"][:]\n",
    "    pred_picks = f[\"predicted_picks\"][:]\n",
    "    array_dist = f[\"array_dist\"][:]\n",
    "    \n",
    "### Read raw and denoised DAS\n",
    "with h5py.File(out_dir + 'das_raw_denoised_400_555.hdf5', 'r') as f:\n",
    "    inp_data = f[\"input_data\"][:]\n",
    "    one_denoised = f[\"one_denoise\"][:]\n",
    "    mul_denoised = f[\"mul_denoise\"][:]\n",
    "\n",
    "### Read the catalog\n",
    "cat1 = read_events(out_dir + \"denoised_catalog_400_555.xml\")\n",
    "\n",
    "### Recording time\n",
    "df = pd.read_csv(raw_dir + record_time_file).iloc[200:400]\n",
    "start_times = df['record_time'].values\n",
    "org_times = [evt.origins[0].time - UTCDateTime.strptime(start_t, format='decimator2_%Y-%m-%d_%H.%M.%S_UTC.h5') for evt, start_t in zip(cat1 , start_times)]\n",
    "pred_picks += np.array(org_times)[:, np.newaxis, np.newaxis]\n",
    "\n",
    "### interpolate\n",
    "interp_func = interp1d(np.linspace(0, 1, 1500), inp_data, axis=-1, kind='linear')\n",
    "interpolated_image = interp_func(np.linspace(0, 1, 6000))\n",
    "interp_func = interp1d(np.linspace(0, 1, 1500), one_denoised, axis=-1, kind='linear')\n",
    "interpolated_onedenoised = interp_func(np.linspace(0, 1, 6000))\n",
    "interp_func = interp1d(np.linspace(0, 1, 1500), mul_denoised, axis=-1, kind='linear')\n",
    "interpolated_muldenoised = interp_func(np.linspace(0, 1, 6000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3ecebf",
   "metadata": {},
   "source": [
    "### QC the picks and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ce745b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Nevent=len(inp_data)\n",
    "thr=0.05\n",
    "fs=100\n",
    "ch_itv=2  # data are downsampled to pick\n",
    "dchan=9.5714\n",
    "st, ed = 5, 55\n",
    "tax=np.arange(interpolated_image.shape[2])/fs\n",
    "win=np.where(np.logical_and(tax>st,tax<ed))[0]\n",
    "\n",
    "snr_raw = np.zeros((Nevent, 2), dtype = np.float32)\n",
    "snr_one = np.zeros((Nevent, 2), dtype = np.float32)\n",
    "snr_mul = np.zeros((Nevent, 2), dtype = np.float32)\n",
    "npk_raw = np.zeros((Nevent, 2), dtype = np.float32)\n",
    "npk_one = np.zeros((Nevent, 2), dtype = np.float32)\n",
    "npk_mul = np.zeros((Nevent, 2), dtype = np.float32)\n",
    "std_raw = np.zeros((Nevent, 2), dtype = np.float32)\n",
    "std_one = np.zeros((Nevent, 2), dtype = np.float32)\n",
    "std_mul = np.zeros((Nevent, 2), dtype = np.float32)\n",
    "\n",
    "for i in tqdm(np.arange(Nevent)):\n",
    "    evt = cat1[i]\n",
    "    mag = evt.magnitudes[0].mag\n",
    "    lon = evt.origins[0].longitude\n",
    "    lat = evt.origins[0].latitude\n",
    "    dep = evt.origins[0].depth/1000  ## too shallow depth+ long distance = bugs\n",
    "    ort = evt.origins[0].time\n",
    "    \n",
    "    mag0, lon0, lat0, dep0, ort0= \\\n",
    "    round(mag,1), round(lon,2), round(lat,2), round(dep,0), ort.strftime('%Y-%m-%d')\n",
    "\n",
    "    plt.figure(figsize=(24, 8), constrained_layout=True)\n",
    "\n",
    "    ### Raw data\n",
    "    image = np.nan_to_num(interpolated_image[i,::ch_itv,:])\n",
    "    offset_s, std_raw[i,1], mean_offset_s, ind_s = fit_series(\n",
    "        raw_picks[i,:,1,0], pred_picks[i,:,1], raw_picks[i,:,1,1], thr=0.05, vmin=st, vmax=ed)\n",
    "    \n",
    "    offset_p, std_raw[i,0], mean_offset_p, ind_p = fit_series(\n",
    "        raw_picks[i,:,0,0], pred_picks[i,:,0], raw_picks[i,:,0,1], thr=0.1, vmin=st, vmax=ed)\n",
    "    \n",
    "    plt.subplot(2, 6, 1) \n",
    "    subfig_img(image, raw_picks[i], ind_p, ind_s, pred_picks[i], array_dist[::ch_itv],\n",
    "               \"M\"+str(mag0)+\" lat. \"+str(lat0)+\" lon. \"+str(lon0))\n",
    "        \n",
    "    plt.subplot(2, 6, 2) \n",
    "    subfig_histpick(raw_picks[i])\n",
    "    \n",
    "    plt.subplot(2, 6, 7) \n",
    "    snr_raw[i,0], snr_raw[i,1] = subfig_goodtrace(\n",
    "        image, raw_picks[i], ind_p, ind_s, tax, win)\n",
    "    npk_raw[i,0], npk_raw[i,1] = len(ind_p), len(ind_s)\n",
    "            \n",
    "    plt.subplot(2, 6, 8)\n",
    "    plt.hist(offset_p,bins=20,edgecolor='b',fill=False,label='p',range=(-1,1))\n",
    "    plt.hist(offset_s,bins=20,edgecolor='g',fill=False,label='s',range=(-1,1))\n",
    "    plt.title(str(npk_raw[i,0])+\"p|\"+str(npk_raw[i,1])+\"s|\"+\n",
    "              \"SNR \"+str(round(snr_raw[i,0],1))+\"/\"+str(round(snr_raw[i,1],1)))\n",
    "    \n",
    "    ### oneDENOISED  \n",
    "    image = np.nan_to_num(interpolated_onedenoised[i,::ch_itv,:])\n",
    "    offset_s, std_one[i,1], mean_offset_s, ind_s= fit_series(\n",
    "        one_picks[i,:,1,0], pred_picks[i,:,1], one_picks[i,:,1,1], thr=0.05, vmin=st, vmax=ed)\n",
    "    \n",
    "    offset_p, std_one[i,0], mean_offset_p, ind_p= fit_series(\n",
    "        one_picks[i,:,0,0], pred_picks[i,:,0], one_picks[i,:,0,1], thr=0.1, vmin=st, vmax=ed)\n",
    "    \n",
    "    plt.subplot(2, 6, 3) \n",
    "    subfig_img(image, one_picks[i], ind_p, ind_s, pred_picks[i], array_dist[::ch_itv], \n",
    "                \"Ensemble Picking on Denoised data\")\n",
    "    \n",
    "    plt.subplot(2, 6, 4) \n",
    "    subfig_histpick(one_picks[i])\n",
    "    \n",
    "    plt.subplot(2, 6, 9) \n",
    "    snr_one[i,0], snr_one[i,1]=subfig_goodtrace(\n",
    "        image, one_picks[i], ind_p, ind_s, tax, win)\n",
    "    npk_one[i,0], npk_one[i,1] = len(ind_p), len(ind_s)\n",
    "    \n",
    "    plt.subplot(2, 6, 10) \n",
    "    plt.hist(offset_p,bins=20,edgecolor='b',fill=False,label='p',range=(-1,1))\n",
    "    plt.hist(offset_s,bins=20,edgecolor='g',fill=False,label='s',range=(-1,1))\n",
    "    plt.title(str(npk_one[i,0])+\"p|\"+str(npk_one[i,1])+\"s|\"+\n",
    "              \"SNR \"+str(round(snr_one[i,0],1))+\"/\"+str(round(snr_one[i,1],1)))\n",
    "    \n",
    "    ### mulDENOISED \n",
    "    image = np.nan_to_num(interpolated_muldenoised[i,::ch_itv,:])\n",
    "    offset_s, std_mul[i,1], mean_offset_s, ind_s= fit_series(\n",
    "        mul_picks[i,:,1,0], pred_picks[i,:,1], mul_picks[i,:,1,1], thr=0.05, vmin=st, vmax=ed)\n",
    "    \n",
    "    offset_p, std_mul[i,0], mean_offset_p, ind_p= fit_series(\n",
    "        mul_picks[i,:,0,0], pred_picks[i,:,0], mul_picks[i,:,0,1], thr=0.1, vmin=st, vmax=ed)\n",
    "    \n",
    "    plt.subplot(2, 6, 5) \n",
    "    subfig_img(image, mul_picks[i], ind_p, ind_s, pred_picks[i], array_dist[::ch_itv], \n",
    "               \"Ensemble Picking on Denoised data\")\n",
    "    \n",
    "    plt.subplot(2, 6, 6) \n",
    "    subfig_histpick(mul_picks[i])\n",
    "    \n",
    "    plt.subplot(2, 6, 11) \n",
    "    snr_mul[i,0], snr_mul[i,1]= subfig_goodtrace(\n",
    "        image, mul_picks[i], ind_p, ind_s, tax, win)\n",
    "    npk_mul[i,0], npk_mul[i,1]  = len(ind_p), len(ind_s)\n",
    "    \n",
    "    plt.subplot(2, 6, 12) \n",
    "    plt.hist(offset_p,bins=20,edgecolor='b',fill=False,label='p',range=(-1,1))\n",
    "    plt.hist(offset_s,bins=20,edgecolor='g',fill=False,label='s',range=(-1,1))\n",
    "    plt.title(str(npk_mul[i,0])+\"p|\"+str(npk_mul[i,1])+\"s|\"+\n",
    "              \"SNR \"+str(round(snr_mul[i,0],1))+\"/\"+str(round(snr_mul[i,1],1)))\n",
    "\n",
    "            \n",
    "    plt.savefig(f\"{out_dir}picks_event_{i+400}_thr010p005s.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0e7dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(out_dir + 'pick_stats_400_555_thr010p005s.hdf5', 'w') as f:\n",
    "    f.create_dataset(\"raw_alldata_picks\", data=raw_picks)\n",
    "    f.create_dataset(\"one_denoise_picks\", data=one_picks)\n",
    "    f.create_dataset(\"mul_denoise_picks\", data=mul_picks)\n",
    "    f.create_dataset(\"predicted_picks\", data=pred_picks)\n",
    "    f.create_dataset(\"array_dist\", data=array_dist)\n",
    "    f.create_dataset(\"raw_alldata_snr\", data=snr_raw)\n",
    "    f.create_dataset(\"one_denoise_snr\", data=snr_one)\n",
    "    f.create_dataset(\"mul_denoise_snr\", data=snr_mul)\n",
    "    f.create_dataset(\"raw_alldata_numpick\", data=npk_raw)\n",
    "    f.create_dataset(\"one_denoise_numpick\", data=npk_one)\n",
    "    f.create_dataset(\"mul_denoise_numpick\", data=npk_mul)\n",
    "    f.create_dataset(\"raw_alldata_pickerr\", data=std_raw)\n",
    "    f.create_dataset(\"one_denoise_pickerr\", data=std_one)\n",
    "    f.create_dataset(\"mul_denoise_pickerr\", data=std_mul)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c28c43",
   "metadata": {},
   "source": [
    "## 5. Wiggle anaysis to refine picks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9b5fdf",
   "metadata": {},
   "source": [
    "Read picks and DAS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bf044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read phase picks from the previous session\n",
    "with h5py.File(out_dir + 'phase_picks.hdf5', 'r') as f:\n",
    "    raw_picks = f[\"raw_alldata_picks\"][:]\n",
    "    one_picks = f[\"one_denoise_picks\"][:]\n",
    "    mul_picks = f[\"mul_denoise_picks\"][:]\n",
    "    pred_picks = f[\"predicted_picks\"][:]\n",
    "    array_dist = f[\"array_dist\"][:]\n",
    "    \n",
    "### Read raw and denoised DAS\n",
    "with h5py.File(out_dir + 'das_raw_denoised.hdf5', 'r') as f:\n",
    "    inp_data = f[\"input_data\"][:]\n",
    "    one_denoised = f[\"one_denoise\"][:]\n",
    "    mul_denoised = f[\"mul_denoise\"][:]\n",
    "\n",
    "### Read the catalog\n",
    "cat1 = read_events(out_dir + \"denoised_catalog.xml\")\n",
    "\n",
    "### Recording time\n",
    "df = pd.read_csv(raw_dir + record_time_file)\n",
    "start_times = df['record_time'].values\n",
    "org_times = [evt.origins[0].time - UTCDateTime.strptime(start_t, format='decimator2_%Y-%m-%d_%H.%M.%S_UTC.h5') for evt, start_t in zip(cat1 , start_times)]\n",
    "pred_picks += np.array(org_times)[:, np.newaxis, np.newaxis]\n",
    "\n",
    "### interpolate\n",
    "# interp_func = interp1d(np.linspace(0, 1, 1500), inp_data, axis=-1, kind='linear')\n",
    "# interpolated_image = interp_func(np.linspace(0, 1, 6000))\n",
    "# interp_func = interp1d(np.linspace(0, 1, 1500), one_denoised, axis=-1, kind='linear')\n",
    "# interpolated_onedenoised = interp_func(np.linspace(0, 1, 6000))\n",
    "# interp_func = interp1d(np.linspace(0, 1, 1500), mul_denoised, axis=-1, kind='linear')\n",
    "# interpolated_muldenoised = interp_func(np.linspace(0, 1, 6000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1638632b",
   "metadata": {},
   "source": [
    "### Plot the refined wiggles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0529d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib agg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "matplotlib.rcParams['font.size'] = 20\n",
    "    \n",
    "maxshift =1\n",
    "cc_thres =0.25\n",
    "######################################################\n",
    "def plot_record(ind, image, picks, fs, tax, t_bef=2, t_aft=3, integrate=False):\n",
    "\n",
    "    wave = np.zeros((len(ind), int((t_bef+t_aft)*fs)), dtype = np.float32)\n",
    "        \n",
    "    for j, ch in enumerate(ind): \n",
    "        pt = int(picks[ch]*fs)\n",
    "        trace = image[ch, pt- t_bef*fs:pt+ t_aft*fs]\n",
    "        if integrate:\n",
    "            int1 = cumulative_trapezoid(trace, tax, initial=0)\n",
    "            wave[j] = (int1-np.mean(int1))\n",
    "        else:\n",
    "            wave[j] = trace * 20\n",
    "\n",
    "    alighed_wave, shifts, cccs = align_channels_twice(wave, ref_ch=0, maxshift=int(maxshift*fs), cc_thres=cc_thres)\n",
    "\n",
    "    if len(alighed_wave)>0:\n",
    "        y = np.arange(alighed_wave.shape[0])\n",
    "        bound = np.percentile(np.fabs(alighed_wave), 80)\n",
    "        plt.pcolormesh(tax,y,alighed_wave, shading='auto',vmin=-bound,vmax=bound,cmap=matplotlib.colormaps['RdBu']) \n",
    "        \n",
    "    stack = np.mean(alighed_wave[cccs>cc_thres,:], axis=0)\n",
    "    \n",
    "    ### plot the stacked trace\n",
    "    plt.plot(tax, stack/np.std(stack)*len(ind)/20, color='g', linestyle='-', lw=2)\n",
    "    plt.xlim(0-t_bef, t_aft)\n",
    "\n",
    "    return shifts, cccs\n",
    "######################################################\n",
    "\n",
    "ch_itv=2  # data are downsampled to pick, so also downsampled to visualize\n",
    "dchan=9.5714\n",
    "fs=25\n",
    "st, ed = 5, 55\n",
    "tax=np.arange(0-2*fs,3*fs)/fs\n",
    "\n",
    "offsets_raw = []\n",
    "offsets_mul = []\n",
    "offsets_mul_noalign = []\n",
    "offsets_raw_noalign = []\n",
    "cccs_raw = []\n",
    "cccs_mul = []\n",
    "\n",
    "### Choose several events from the catalog\n",
    "for i in tqdm(range(0,95)):\n",
    "    evt = cat1[i]\n",
    "    mag = evt.magnitudes[0].mag\n",
    "    lon = evt.origins[0].longitude\n",
    "    lat = evt.origins[0].latitude\n",
    "    dep = evt.origins[0].depth/1000\n",
    "    ort = evt.origins[0].time\n",
    "\n",
    "    mag0, lon0, lat0, dep0, ort0= \\\n",
    "    round(mag,1), round(lon,2), round(lat,2), round(dep,0), ort.strftime('%Y-%m-%d')\n",
    "                  \n",
    "    plt.figure(figsize=(25, 7.5), constrained_layout=True)\n",
    "    gs = gridspec.GridSpec(2, 5, width_ratios=[1, 2, 2, 1, 1])\n",
    "\n",
    "    ## mul denoised\n",
    "    image = np.nan_to_num(mul_denoised[i,::ch_itv,:])\n",
    "\n",
    "    offset_s, std_raw_s, mean_offset_s, ind_s = fit_series(\n",
    "        mul_picks[i,:,1,0], pred_picks[i,:,1], mul_picks[i,:,1,1], thr=0.05, vmin=st, vmax=ed)\n",
    "    \n",
    "    if len(ind_s)==0:\n",
    "        continue\n",
    "\n",
    "    # plt.subplot(gs[1, 0])\n",
    "    # subfig_img(image, mul_picks[i], ind_p, ind_s, pred_picks[i], array_dist[::ch_itv])\n",
    "    # plt.title(\"Denoised\")\n",
    "    # plt.xlabel(\"Record time (s)\")\n",
    "\n",
    "    plt.subplot(gs[1, 1])\n",
    "    shifts1, cccs1 = plot_record(ind_s[ind_s<2250], image, mul_picks[i,:,1,0], fs, tax)\n",
    "    plt.xlabel(\"Time relative to S arrival (s)\")\n",
    "    \n",
    "    plt.subplot(gs[1, 2])\n",
    "    shifts2, cccs2 = plot_record(ind_s[ind_s>=2250], image, mul_picks[i,:,1,0], fs, tax)\n",
    "    plt.xlabel(\"Time relative to S arrival (s)\")\n",
    "\n",
    "    # plt.subplot(gs[1, 3])\n",
    "    cccs = np.concatenate((cccs1, cccs2),axis=None)\n",
    "    # plt.hist(cccs, bins=20,edgecolor='k',fill=False)\n",
    "    # plt.xlim(0,1)\n",
    "    # plt.title('Cross-correlation coefficients')\n",
    "\n",
    "    # plt.subplot(gs[1, 4])\n",
    "    shifts = np.concatenate((shifts1, shifts2),axis=None)/fs\n",
    "    # plt.hist(shifts,bins=20,edgecolor='k',fill=False)\n",
    "    # plt.xlim(-1,1)\n",
    "    # plt.title('Time shifts')\n",
    "\n",
    "    offsets_mul.append(mul_picks[i,ind_s,1,0] + shifts - pred_picks[i,ind_s,1])\n",
    "    offsets_mul_noalign.append(mul_picks[i,ind_s,1,0] - pred_picks[i,ind_s,1])\n",
    "    cccs_mul.append(cccs)\n",
    "\n",
    "    \n",
    "    ### Raw data\n",
    "    image = np.nan_to_num(inp_data[i,::ch_itv,:])\n",
    "\n",
    "    offset_s, std_raw_s, mean_offset_s, ind_s = fit_series(\n",
    "        raw_picks[i,:,1,0], pred_picks[i,:,1], raw_picks[i,:,1,1], thr=0.05, vmin=st, vmax=ed)\n",
    "\n",
    "    # plt.subplot(gs[0, 0]) \n",
    "    # subfig_img(image, raw_picks[i], ind_p, ind_s, pred_picks[i], array_dist[::ch_itv])\n",
    "    # plt.title(\"M\"+str(mag0)+\" lat. \"+str(lat0)+\" lon. \"+str(lon0))\n",
    "            \n",
    "    plt.subplot(gs[0, 1])\n",
    "    shifts1, cccs1 = plot_record(ind_s[ind_s<2250], image, raw_picks[i,:,1,0], fs, tax, integrate=False)\n",
    "    plt.title(\"KKFL-S cable\")\n",
    "    \n",
    "    plt.subplot(gs[0, 2])\n",
    "    shifts2, cccs2 = plot_record(ind_s[ind_s>=2250], image, raw_picks[i,:,1,0], fs, tax, integrate=False)\n",
    "    plt.title(\"TERRA cable\")\n",
    "\n",
    "    # plt.subplot(gs[0, 3])\n",
    "    cccs = np.concatenate((cccs1, cccs2),axis=None)\n",
    "    # plt.hist(cccs, bins=20, edgecolor='k', fill=False)\n",
    "    # plt.xlim(0,1)\n",
    "    # plt.title('Cross-correlation coefficients')\n",
    "\n",
    "    # plt.subplot(gs[0, 4])\n",
    "    shifts = np.concatenate((shifts1, shifts2),axis=None)/fs\n",
    "    # plt.hist(shifts,bins=20,edgecolor='k',fill=False)\n",
    "    # plt.title('Time shifts')\n",
    "    # plt.xlim(-1,1)\n",
    "\n",
    "    offsets_raw.append(raw_picks[i,ind_s,1,0] + shifts - pred_picks[i,ind_s,1])\n",
    "    offsets_raw_noalign.append(raw_picks[i,ind_s,1,0] - pred_picks[i,ind_s,1])\n",
    "    cccs_raw.append(cccs)\n",
    "\n",
    "    plt.savefig(f\"{out_dir}align_event_{i}.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b37ee4",
   "metadata": {},
   "source": [
    "### Plot the CC between traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595e5187",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "matplotlib.rcParams['font.size'] = 20\n",
    "mul_pick_offsets = np.concatenate(offsets_mul_noalign, axis=None)\n",
    "mul_align_offsets = np.concatenate(offsets_mul, axis=None)\n",
    "cccs_mul = np.concatenate(cccs_mul, axis=None)\n",
    "cccs_raw = np.concatenate(cccs_raw, axis=None)\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(7.5, 7.5), constrained_layout=True)\n",
    "\n",
    "# Plot the S time error histogram\n",
    "plt.hist(mul_pick_offsets, bins=300, alpha=0.5, color='gray', label='Picked S time - prediction')\n",
    "plt.axvline(np.percentile(mul_pick_offsets,2.5), color='gray', linestyle='--', label='95% confidence')\n",
    "plt.axvline(np.percentile(mul_pick_offsets,97.5), color='gray', linestyle='--')\n",
    "\n",
    "plt.hist(mul_align_offsets, bins=300, alpha=0.5, color='b', label='Aligned S time - prediction')\n",
    "plt.axvline(np.percentile(mul_align_offsets,2.5), color='b', linestyle='--', label='95% confidence')\n",
    "plt.axvline(np.percentile(mul_align_offsets,97.5), color='b', linestyle='--')\n",
    "\n",
    "plt.xlabel('Offsets')\n",
    "plt.ylabel('Counts')\n",
    "plt.legend()\n",
    "plt.title('S Time Error Histogram')\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(7.5, 7.5), constrained_layout=True)\n",
    "plt.hist(cccs_raw, bins=300, alpha=0.5, color='gray', label='Raw CC')\n",
    "plt.hist(cccs_mul, bins=300, alpha=0.5, color='b', label='Denoised CC')\n",
    "plt.legend()\n",
    "plt.xlabel('CC between traces')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('CC improvement')\n",
    "plt.savefig(f\"{out_dir}align_cc.pdf\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo (SHARED)",
   "language": "python",
   "name": "seismo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
