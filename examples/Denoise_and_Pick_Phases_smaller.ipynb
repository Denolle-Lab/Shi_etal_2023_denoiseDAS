{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf73e7fe",
   "metadata": {},
   "source": [
    "# Phase Picking of Denoised DAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6878d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from das_util import try_gpu\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.random import default_rng\n",
    "from scipy.signal import filtfilt, butter\n",
    "from torch.utils.data import DataLoader\n",
    "from das_denoise_models import unet, dataflow, datalabel\n",
    "from das_denoise_training import train_augmentation\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b60a4c",
   "metadata": {},
   "source": [
    "## 1. Read and pre-filter the benchmark data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2b8ebd",
   "metadata": {},
   "source": [
    "Use the __seismo__ ipykernel on **Siletzia** for two reasons:\n",
    "\n",
    "1. It has GPUs\n",
    "\n",
    "2. It stores AK-DAS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66481fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! du -sh /fd1/QibinShi_data/akdas/qibin_data/KKFLStill2023*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806ae000",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read (change the file to the latest if needed)\n",
    "data_terra = '/fd1/QibinShi_data/akdas/qibin_data/TERRAtill2023_12_12.hdf5'\n",
    "data_kkfls = '/fd1/QibinShi_data/akdas/qibin_data/KKFLStill2023_12_12.hdf5'\n",
    "with h5py.File(data_terra, 'r') as f:\n",
    "    quake1 = f['raw_quake'][:]\n",
    "with h5py.File(data_kkfls, 'r') as f:\n",
    "    quake2 = f['raw_quake'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e73263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filter\n",
    "sample_rate = 25\n",
    "delta_space = 10\n",
    "rawdata = np.append(quake2[:,500:2000,:], quake1[:,500:2000,:], axis=0)\n",
    "b, a = butter(4, (0.5, 12), fs=sample_rate, btype='bandpass')\n",
    "filt = filtfilt(b, a, rawdata, axis=2)\n",
    "rawdata = filt / np.std(filt, axis=(1,2), keepdims=True)  ## Rawdata w.r.t. Denoised "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41308f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import read_events\n",
    "\n",
    "qml = '/fd1/QibinShi_data/akdas/qibin_data/ak_July1_3.xml'\n",
    "\n",
    "cat = read_events(qml)\n",
    "\n",
    "evt = cat[48%48]\n",
    "mag = evt.magnitudes[0].mag\n",
    "lat = evt.origins[0].longitude\n",
    "lon = evt.origins[0].latitude\n",
    "evt = evt.origins[0].time\n",
    "\n",
    "print(mag, lat, lon, evt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf54a617",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cat[94%48])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9104be99",
   "metadata": {},
   "source": [
    "## 2. Load models trained in different ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fc2eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Initialize the U-net model \"\"\"\n",
    "devc = try_gpu(i=1)\n",
    "\n",
    "model_1 = unet(1, 16, 1024, factors=(5, 3, 2, 2), use_att=False)\n",
    "model_1 = nn.DataParallel(model_1, device_ids=[1,2,3])\n",
    "model_1.to(devc)\n",
    "model_1.load_state_dict(torch.load('models/checkpoint_noatt_LRdecays0.8_mask0.5_raw2raw_chmax4500.pt'))  # raw2raw\n",
    "model_1.eval() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2735eea",
   "metadata": {},
   "source": [
    "## 3. Denoise to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0976d2f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X=rawdata[:100,:,:].astype(np.float32)\n",
    "\n",
    "del rawdata\n",
    "gc.collect()\n",
    "\n",
    "X = torch.from_numpy(X).to(devc)\n",
    "### denoise\n",
    "with torch.no_grad():\n",
    "    ### raw2raw\n",
    "    oneDenoise_1 = model_1(X)\n",
    "    mulDenoise_1 = model_1(oneDenoise_1)\n",
    "    mulDenoise_1 = model_1(mulDenoise_1)\n",
    "    mulDenoise_1 = model_1(mulDenoise_1)\n",
    "\n",
    "### convert back to numpy, trim edges\n",
    "rawdata = X.to('cpu').numpy()\n",
    "oneDenoise_1 = oneDenoise_1.to('cpu').numpy()\n",
    "mulDenoise_1 = mulDenoise_1.to('cpu').numpy()\n",
    "\n",
    "### save denoised data to file\n",
    "# with h5py.File('/fd1/QibinShi_data/akdas/qibin_data/' + 'raw_and_one_mul_denoise.hdf5', 'w') as f:\n",
    "#     f.create_dataset(\"raw\", data=rawdata)\n",
    "#     f.create_dataset(\"raw2raw_oneDenoise\", data=oneDenoise_1)\n",
    "#     f.create_dataset(\"fk2fk_oneDenoise\", data=oneDenoise_2)\n",
    "#     f.create_dataset(\"raw2fk_oneDenoise\", data=oneDenoise_3)\n",
    "#     f.create_dataset(\"raw2raw_mulDenoise\", data=mulDenoise_1)\n",
    "#     f.create_dataset(\"fk2fk_mulDenoise\", data=mulDenoise_2)\n",
    "#     f.create_dataset(\"raw2fk_mulDenoise\", data=mulDenoise_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df333fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_3d_array(arr, len1=1500, len2=1500):\n",
    "    \"\"\"convert to numpy array\"\"\"\n",
    "    arr = np.array(arr)\n",
    "    \n",
    "    \"\"\"Ensure the array has at least len1 rows and len2 columns\"\"\"\n",
    "    slices, rows, cols = arr.shape\n",
    "    arr = arr[:, :min(rows, len1), :min(cols, len2)]\n",
    "    \n",
    "    \"\"\"Pad zeros if it has fewer than len1 rows or len2 columns\"\"\"\n",
    "    if rows < len1 or cols < len2:\n",
    "        padding_rows = max(len1 - rows, 0)\n",
    "        padding_cols = max(len2 - cols, 0)\n",
    "        arr = np.pad(arr, ((0, 0), (0, padding_rows), (0, padding_cols)), 'constant')\n",
    "    \n",
    "    return arr\n",
    "\n",
    "def vizRawDenoise(in_data, oneDenoise, mulDenoise, sample_rate=25, dchan=10, index=[0,1], model=\"MAE\"):\n",
    "    \"\"\"\n",
    "    in_data, oneDenoise, mulDenoise: 3D -- [event, channel, time]\n",
    "    index: list, subset of the events\n",
    "    model: string, descriptions about the model\n",
    "    \"\"\"\n",
    "    len1, len2 = oneDenoise[0].shape[0], oneDenoise[0].shape[1]\n",
    "    x, y = np.arange(len2), np.arange(len1)\n",
    "    rawdata = process_3d_array(in_data, len1=len1, len2=len2)\n",
    "\n",
    "    for j in index:\n",
    "        bound = np.median(np.fabs(in_data[j]))*2\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(18, 6), constrained_layout=True)\n",
    "\n",
    "        img=ax[0].pcolormesh(x, y, rawdata[j], shading='auto', vmin=-bound, vmax=bound, cmap=plt.cm.get_cmap('RdBu'))\n",
    "        ax[1].pcolormesh(x, y, oneDenoise[j], shading='auto',  vmin=-bound, vmax=bound, cmap=plt.cm.get_cmap('RdBu'))\n",
    "        ax[2].pcolormesh(x, y, mulDenoise[j], shading='auto', vmin=-bound, vmax=bound, cmap=plt.cm.get_cmap('RdBu'))\n",
    "\n",
    "        ax[0].set_title(\"Raw data #\"+str(j), fontsize=24)\n",
    "        ax[1].set_title(model+\" 1-time denoised\", fontsize=24)\n",
    "        ax[2].set_title(model+\" multi-time denoised\", fontsize=24)\n",
    "        ax[0].set_ylabel('Distance (km)', fontsize=24)\n",
    "\n",
    "        plt.colorbar(img, ax=ax[2])\n",
    "\n",
    "        for i in range(3):\n",
    "            ax[i].set_xlabel('Time (s)', fontsize=24)\n",
    "            ax[i].set_xticks(np.arange(0, 250*(len2//250), 250)) \n",
    "            ax[i].set_xticklabels(np.arange(0, 250*(len2//250)/sample_rate, 250/sample_rate).astype(int))\n",
    "            ax[i].set_yticks(np.arange(0, 200*(len1//200), 200))\n",
    "            ax[i].set_yticklabels((np.arange(0, dchan*200*(len1//200), 200*dchan)/1000).astype(int))\n",
    "            \n",
    "vizRawDenoise(rawdata, oneDenoise_1, mulDenoise_1, index=range(50), model=\"raw-raw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c309fa",
   "metadata": {},
   "source": [
    "# Phase picking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa4d2bf",
   "metadata": {},
   "source": [
    "### Read the denoised data (if you don't run the cells above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4b4e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/denoiser/\")\n",
    "sys.path.append(\"../src/ensemble_picker/\")\n",
    "sys.path.append(\"models/\")\n",
    "import os\n",
    "import gc\n",
    "import h5py\n",
    "import torch\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.random import default_rng\n",
    "from scipy.signal import filtfilt, butter\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.interpolate import interp1d\n",
    "from collections import OrderedDict\n",
    "from obspy import read_events\n",
    "\n",
    "# This package\n",
    "from das_denoise_models import unet, dataflow, datalabel\n",
    "from das_denoise_training import train_augmentation\n",
    "from das_util import try_gpu\n",
    "\n",
    "# seisbench\n",
    "import seisbench.models as sbm\n",
    "\n",
    "# some ELEP functions\n",
    "# from mbf_elep_func import apply_elep\n",
    "\n",
    "\n",
    "# import os\n",
    "# devc = torch.cuda.current_device()\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = str(devc)\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073a07ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML picker parameters\n",
    "paras_semblance = {'dt':0.01, \n",
    "                   'semblance_order':2, \n",
    "                   'window_flag':True, \n",
    "                   'semblance_win':0.5, \n",
    "                   'weight_flag':'max'}\n",
    "\n",
    "p_thrd, s_thrd = 0.01, 0.05\n",
    "fqmin = 0.1\n",
    "fqmax = 5\n",
    "\n",
    "dt = 0.01; fs = 100\n",
    "nfqs = 10\n",
    "nt = 6000; nc = 3\n",
    "fq_list = [1]  # make_LogFq(fqmin, fqmax, dt, nfqs)\n",
    "coeff_HP, coeff_LP = [1,1]  # rec_filter_coeff(fq_list, dt)\n",
    "MBF_paras = {'f_min':fqmin, \n",
    "             'f_max':fqmax,\n",
    "             'nfqs':nfqs, \n",
    "             'frequencies':fq_list, \n",
    "             'CN_HP':coeff_HP, \n",
    "             'CN_LP':coeff_LP,\n",
    "             'dt':dt, \n",
    "             'fs':fs, \n",
    "             'nt':nt, \n",
    "             'nc':nc, \n",
    "             'npoles': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45b89d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download models\n",
    "devcc = torch.device(f'cuda:{1}')\n",
    "pretrain_list = [\"ethz\",\"instance\",\"scedc\",\"stead\",\"geofon\",\"neic\"]\n",
    "# pn_pnw_model = sbm.EQTransformer.from_pretrained('original')\n",
    "pn_ethz_model = sbm.EQTransformer.from_pretrained(\"ethz\")\n",
    "pn_instance_model = sbm.EQTransformer.from_pretrained(\"instance\")\n",
    "pn_scedc_model = sbm.EQTransformer.from_pretrained(\"scedc\")\n",
    "pn_stead_model = sbm.EQTransformer.from_pretrained(\"stead\")\n",
    "pn_geofon_model = sbm.EQTransformer.from_pretrained(\"geofon\")\n",
    "pn_neic_model = sbm.EQTransformer.from_pretrained(\"neic\")\n",
    "\n",
    "list_models = [pn_ethz_model,pn_scedc_model,pn_neic_model,pn_geofon_model,pn_stead_model,pn_instance_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eee2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn_ethz_model.to(devcc);\n",
    "pn_scedc_model.to(devcc);\n",
    "pn_neic_model.to(devcc);\n",
    "pn_geofon_model.to(devcc);\n",
    "pn_stead_model.to(devcc);\n",
    "pn_instance_model.to(devcc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21838758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate\n",
    "interpolation_function = interp1d(np.linspace(0, 1, 1500), rawdata[0:100,:,:], axis=-1, kind='linear')\n",
    "interpolated_image = interpolation_function(np.linspace(0, 1, 6000))\n",
    "interpolation_function = interp1d(np.linspace(0, 1, 1500), oneDenoise_1[0:100,:,:], axis=-1, kind='linear')\n",
    "interpolated_onedenoised = interpolation_function(np.linspace(0, 1, 6000))\n",
    "interpolation_function = interp1d(np.linspace(0, 1, 1500), mulDenoise_1[0:100,:,:], axis=-1, kind='linear')\n",
    "interpolated_muldenoised = interpolation_function(np.linspace(0, 1, 6000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afe71d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as time\n",
    "from joblib import Parallel, delayed\n",
    "from ELEP.elep.ensemble_coherence import ensemble_semblance \n",
    "\n",
    "\n",
    "def apply_elep(DAS_data, list_models, MBF_paras, paras_semblance, \\\n",
    "              thr=0.6,device=devc):\n",
    "    \n",
    "    \"\"\"\"\n",
    "    This function takes a array of stream, a list of ML models and \n",
    "    apply these models to the data, predict phase picks, and\n",
    "    return an array of picks .\n",
    "    DAS_data: NDArray of DAS data: [channel,time stamp - 6000]\n",
    "    \"\"\"\n",
    "    \n",
    "    twin = 6000\n",
    "    nsta = DAS_data.shape[0]\n",
    "    bigS = np.zeros(shape=(DAS_data.shape[0], 3, DAS_data.shape[1]))\n",
    "    for i in range(nsta):\n",
    "        bigS[i,0,:] = DAS_data[i,:]\n",
    "        bigS[i,1,:] = DAS_data[i,:]\n",
    "        bigS[i,2,:] = DAS_data[i,:]\n",
    "\n",
    "    # allocating memory for the ensemble predictions\n",
    "    batch_pred_P = np.zeros(shape=(len(list_models),nsta,twin)) \n",
    "    batch_pred_S = np.zeros(shape=(len(list_models),nsta,twin))\n",
    "        \n",
    "    ######### Broadband workflow ################\n",
    "    crap2 = bigS.copy()\n",
    "    crap2 -= np.mean(crap2, axis=-1, keepdims= True) # demean data\n",
    "    # original use std norm\n",
    "    data_std = crap2 / (np.std(crap2) + 1e-7)\n",
    "    # could use max data\n",
    "    mmax = np.max(np.abs(crap2), axis=-1, keepdims=True)\n",
    "    data_max = np.divide(crap2 , mmax,out=np.zeros_like(crap2), where=mmax!=0)\n",
    "    del bigS\n",
    "    \n",
    "    # data to tensor\n",
    "    data_tt = torch.from_numpy(data_max).to(device, dtype=torch.float64)\n",
    "    \n",
    "    t0=time.time()\n",
    "    for ii, imodel in enumerate(list_models):\n",
    "        imodel.to(device)\n",
    "        imodel=imodel.double()\n",
    "        imodel.eval()\n",
    "        with torch.no_grad():\n",
    "            batch_pred_P[ii, :, :] = imodel(data_tt)[1].cpu().numpy()[:, :]\n",
    "            batch_pred_S[ii, :, :] = imodel(data_tt)[2].cpu().numpy()[:, :]\n",
    "    \n",
    "    print(f\"Picks predicted in broadband workflow on the GPU in {time.time()-t0} seconds\")\n",
    "    \n",
    "    smb_peak = np.zeros([nsta,2,2], dtype = np.float32)\n",
    "\n",
    "    sfs = MBF_paras[\"fs\"]\n",
    "    istart = 0 \n",
    "\n",
    "    def process_p(ista,paras_semblance,batch_pred,istart):\n",
    "        crap = ensemble_semblance(batch_pred[:, ista, :], paras_semblance)\n",
    "        imax = np.argmax(crap[istart:])\n",
    "        prob = crap[istart+imax]\n",
    "        smb_peak=0\n",
    "        if crap[imax+istart] > thr:\n",
    "            smb_peak = float((imax)/sfs)+istart/sfs \n",
    "            \n",
    "        return smb_peak, prob\n",
    "\n",
    "    smb_peak[:,0,:] = np.array(Parallel(n_jobs=100)(delayed(process_p)(ista,paras_semblance,batch_pred_P,istart) for ista in range(nsta)))\n",
    "    smb_peak[:,1,:] = np.array(Parallel(n_jobs=100)(delayed(process_p)(ista,paras_semblance,batch_pred_S,istart) for ista in range(nsta)))\n",
    "    \n",
    "    return smb_peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66dc64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tzoom=np.arange(-1,1,0.04)\n",
    "tzoom.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ed315",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Nevent=96\n",
    "\n",
    "devc = torch.device(f'cuda:{1}')\n",
    "fs=100\n",
    "wd=int(fs * 2)\n",
    "ch_itv=10\n",
    "dchan=10\n",
    "tax=np.arange(1500)/25\n",
    "tzoom=np.arange(-1,1,0.04)\n",
    "thr=0.05\n",
    "\n",
    "for i in np.arange(Nevent):\n",
    "    \n",
    "    evt = cat[i%48]\n",
    "    mag = evt.magnitudes[0].mag\n",
    "    lat = evt.origins[0].longitude\n",
    "    lon = evt.origins[0].latitude\n",
    "    \n",
    "    # pick on the RAW data\n",
    "    pickr=apply_elep(interpolated_image[i,::ch_itv,:], list_models, MBF_paras, paras_semblance,thr=thr,device=devc)\n",
    "    # pick on the denoised data\n",
    "    pick1=apply_elep(interpolated_onedenoised[i,::ch_itv,:], list_models, MBF_paras, paras_semblance,thr=thr,device=devc)\n",
    "    pick2=apply_elep(interpolated_muldenoised[i,::ch_itv,:], list_models, MBF_paras, paras_semblance,thr=thr,device=devc) \n",
    "\n",
    "    colors = ['blue', 'green']\n",
    "    labels = ['P BB', 'S BB']\n",
    "    \n",
    "    ######## Plotting\n",
    "    cmap=plt.cm.get_cmap('RdBu')\n",
    "    image = rawdata[i,::ch_itv,:]\n",
    "    bound = np.median(np.fabs(image))*2\n",
    "    x, y = (np.arange(image.shape[1])/25), (np.arange(image.shape[0])*ch_itv*dchan/1000)\n",
    "    plt.figure(figsize=(36, 12), constrained_layout=True)\n",
    "    plt.subplot(2, 6, 1) \n",
    "    plt.pcolormesh(x, y, image, shading='auto', vmin=-bound, vmax=bound, cmap=cmap)\n",
    "#     plt.scatter(pickr[:,0,0],y, s=12,marker='o',c=\"b\",alpha=0.3)\n",
    "    plt.scatter(pickr[:,1,0],y, s=12,marker='o',c=colors[1],alpha=0.3)\n",
    "    plt.title(\"M\"+str(mag)+\" lat. \"+str(lat)+\" lon. \"+str(lon))\n",
    "    plt.xlabel(\"Time since starttime (s)\")\n",
    "    plt.ylabel(\"Distance along cable (km)\")\n",
    "    \n",
    "    plt.subplot(2, 6, 2) \n",
    "#     plt.hist(pickr[:,0,1],bins=20,color=colors[0],label=labels[0],range=(0,0.3))\n",
    "    plt.hist(pickr[:,1,1],bins=20,color=colors[1],label=labels[1],range=(0,0.3))\n",
    "#     plt.legend(labels)\n",
    "    plt.title(\"Picks count\")\n",
    "    plt.xlabel(\"Probability\")\n",
    "    plt.ylim(0,20)\n",
    "    plt.xlim(0.05,0.3)\n",
    "    \n",
    "    plt.subplot(2, 6, 7) \n",
    "    count=0\n",
    "    for ch in range(image.shape[0]):\n",
    "        if pickr[ch,1,1] > thr and pickr[ch,1,0]>1:\n",
    "            plt.plot(tax, image[ch])\n",
    "            count=count+1\n",
    "            \n",
    "    plt.subplot(2, 6, 8) \n",
    "    snr=0\n",
    "    for ch in range(image.shape[0]):\n",
    "        if pickr[ch,1,1] > thr and pickr[ch,1,0]>1:\n",
    "            pt=int(pickr[ch,1,0]*25)\n",
    "            plt.plot(np.arange(len(image[ch, pt-25:pt+25]))/25,image[ch, pt-25:pt+25])\n",
    "            snr+=np.std(image[ch, pt:pt+25]) / (np.std(image[ch, pt-25:pt])+1e-7)\n",
    "    snr=snr/(count+1e-7)\n",
    "            \n",
    "    plt.title(str(count) + \" picks totally | SNR \"+str(round(snr,1)))\n",
    "    \n",
    "\n",
    "    # oneDENOISED  \n",
    "    image = oneDenoise_1[i,::ch_itv,:]\n",
    "    x, y = np.arange(image.shape[1])/25, np.arange(image.shape[0])*ch_itv*dchan/1000\n",
    "    plt.subplot(2, 6, 3) \n",
    "    plt.pcolormesh(x, y, image, shading='auto', vmin=-bound, vmax=bound, cmap=cmap)\n",
    "#     plt.scatter(pick1[:,0,0],y, s=12,marker='o',c=\"b\",alpha=0.3)\n",
    "    plt.scatter(pick1[:,1,0],y, s=12,marker='o',c=colors[1],alpha=0.3)\n",
    "    plt.title(\"Ensemble Picking on Denoised data\")\n",
    "    plt.xlabel(\"Time since starttime (s)\")\n",
    "    plt.ylabel(\"Distance along cable (km)\")\n",
    "\n",
    "    plt.subplot(2, 6, 4) \n",
    "#     plt.hist(pick1[:,0,1],bins=20,color=colors[0],label=labels[0],range=(0,0.3))\n",
    "    plt.hist(pick1[:,1,1],bins=20,color=colors[1],label=labels[1],range=(0,0.3))\n",
    "#     plt.legend(labels)\n",
    "    plt.title(\"Picks count\")\n",
    "    plt.xlabel(\"Probability\")\n",
    "    plt.ylim(0,20)\n",
    "    plt.xlim(0.05,0.3)\n",
    "    \n",
    "    plt.subplot(2, 6, 9) \n",
    "    count=0\n",
    "    for ch in range(image.shape[0]):\n",
    "        if pick1[ch,1,1] > thr and pick1[ch,1,0]>1:\n",
    "            plt.plot(tax, image[ch])\n",
    "            count=count+1\n",
    "            \n",
    "    plt.subplot(2, 6, 10) \n",
    "    for ch in range(image.shape[0]):\n",
    "        if pick1[ch,1,1] > thr and pick1[ch,1,0]>1:\n",
    "            pt=int(pick1[ch,1,0]*25)\n",
    "            plt.plot(np.arange(len(image[ch, pt-25:pt+25]))/25,image[ch, pt-25:pt+25])\n",
    "            snr+=np.std(image[ch, pt:pt+25]) / (np.std(image[ch, pt-25:pt])+1e-7)\n",
    "    snr=snr/(count+1e-7)\n",
    "            \n",
    "    plt.title(str(count) + \" picks totally | SNR \"+str(round(snr,1)))\n",
    "    \n",
    "    # mulDENOISED  \n",
    "    image = mulDenoise_1[i,::ch_itv,:]\n",
    "    x, y = np.arange(image.shape[1])/25, np.arange(image.shape[0])*ch_itv*dchan/1000\n",
    "    plt.subplot(2, 6, 5) \n",
    "    plt.pcolormesh(x, y, image, shading='auto', vmin=-bound, vmax=bound, cmap=cmap)\n",
    "#     plt.scatter(pick2[:,0,0],y, s=12,marker='o',c=\"b\",alpha=0.3)\n",
    "    plt.scatter(pick2[:,1,0],y, s=12,marker='o',c=colors[1],alpha=0.3)\n",
    "    plt.title(\"Ensemble Picking on Denoised data\")\n",
    "    plt.xlabel(\"Time since starttime (s)\")\n",
    "    plt.ylabel(\"Distance along cable (km)\")\n",
    "\n",
    "    plt.subplot(2, 6, 6) \n",
    "#     plt.hist(pick2[:,0,1],bins=20,color=colors[0],label=labels[0],range=(0,0.3))\n",
    "    plt.hist(pick2[:,1,1],bins=20,color=colors[1],label=labels[1],range=(0,0.3))\n",
    "#     plt.legend(labels)\n",
    "    plt.title(\"Picks count\")\n",
    "    plt.xlabel(\"Probability\")\n",
    "    plt.ylim(0,20)\n",
    "    plt.xlim(0.05,0.3)\n",
    "    \n",
    "    plt.subplot(2, 6, 11) \n",
    "    count=0\n",
    "    for ch in range(image.shape[0]):\n",
    "        if pick2[ch,1,1] > thr and pick2[ch,1,0]>1:\n",
    "            plt.plot(tax, image[ch])\n",
    "            count=count+1\n",
    "    \n",
    "    plt.subplot(2, 6, 12) \n",
    "    for ch in range(image.shape[0]):\n",
    "        if pick2[ch,1,1] > thr and pick2[ch,1,0]>1:\n",
    "            pt=int(pick2[ch,1,0]*25)\n",
    "            plt.plot(np.arange(len(image[ch, pt-25:pt+25]))/25,image[ch, pt-25:pt+25])\n",
    "            snr+=np.std(image[ch, pt:pt+25]) / (np.std(image[ch, pt-25:pt])+1e-7)\n",
    "    snr=snr/(count+1e-7)\n",
    "            \n",
    "    plt.title(str(count) + \" picks totally | SNR \"+str(round(snr,1)))\n",
    "            \n",
    "    plt.savefig(f\"./plots/ELEP_bb_picks_event_smaller_{i}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo (SHARED)",
   "language": "python",
   "name": "seismo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
