{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1c253be",
   "metadata": {},
   "source": [
    "# Self-supervised DAS denoising "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f5a4657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import h5py\n",
    "import torch\n",
    "import scipy\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from das_util import try_gpu\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.random import default_rng\n",
    "from scipy.signal import filtfilt, butter\n",
    "from scipy.signal.windows import tukey\n",
    "from torch.utils.data import DataLoader\n",
    "from das_denoise_models import unet, dataflow1280, datalabel\n",
    "from das_denoise_training import train_augmentation_fly\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib\n",
    "plt.rcParams.update({'font.size':24})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311a3ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def light_tukey(win_len, alpha=0.5, taper_level=0.5):\n",
    "    org_func = scipy.signal.windows.tukey(win_len, alpha)\n",
    "    new_func = (1 - taper_level) * org_func + taper_level\n",
    "    \n",
    "    return new_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aebed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Secret cell for read while training\n",
    "\n",
    "\n",
    "\n",
    "class CustomH5Dataset(Dataset):\n",
    "    def __init__(self, h5_directory, Nx_sub=1280, Nt=1280, max_ch=5000, mask_ratio=0.5):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            h5_directory (string): Path to the folder containing all the h5 files.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.h5_filepaths = glob.glob(os.path.join(h5_directory, '*.h5'))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.h5_filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "    \n",
    "        # Get the path to the .h5 file\n",
    "        h5_filepath = self.h5_filepaths[idx]\n",
    "            \n",
    "        mask = np.ones((Nx_sub, Nt), dtype=np.float32)\n",
    "            \n",
    "        with h5py.File(h5_filepath, 'r') as f:\n",
    "            time_data = f['Acquisition']['Raw[0]']['RawData'][:Nt, 100:(100+max_ch)]\n",
    "        assert time_data.shape[1] == max_ch, \"Not enough #ch to read, adjust max_ch!\"\n",
    "        assert Nx_sub <= max_ch, \"max_ch is smaller than the #ch needed for the sample, adjust Nx_sub!\"\n",
    "        \n",
    "        # %% slice a random portion\n",
    "        st_ch = np.random.randint(low=0, high=max_ch - Nx_sub)\n",
    "        sample = time_data.T[st_ch:st_ch+Nx_sub, :Nt]\n",
    "\n",
    "        rng = np.random.default_rng()\n",
    "        trace_masked = rng.choice(Nx_sub, size=int(mask_ratio * Nx_sub), replace=False)\n",
    "        mask[trace_masked, :] = mask[trace_masked, :] * 0\n",
    "        \n",
    "        return (samples, mask), sample * (1 - mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1e8b4e",
   "metadata": {},
   "source": [
    "### Option 1: read raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e4d35e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(182, 7500, 1500)\n",
      "(182, 7500, 1500)\n"
     ]
    }
   ],
   "source": [
    "data_terra = '/fd1/QibinShi_data/akdas/qibin_data/TERRAtill2023_11_14.hdf5'\n",
    "data_kkfls = '/fd1/QibinShi_data/akdas/qibin_data/KKFLStill2023_11_14.hdf5'\n",
    "with h5py.File(data_terra, 'r') as f:\n",
    "    quake1 = f['raw_quake'][:]\n",
    "with h5py.File(data_kkfls, 'r') as f:\n",
    "    quake2 = f['raw_quake'][:]\n",
    "print(quake1.shape)\n",
    "print(quake2.shape)\n",
    "    \n",
    "sample_rate = 25\n",
    "dchan = 10\n",
    "    \n",
    "# tmp = np.append(quake2[:,:4500,:], quake1[:,:4500,:], axis=0)\n",
    "tmp = np.append(quake2[:,:,:], quake1[:,:,:], axis=0)\n",
    "\n",
    "del quake2, quake1\n",
    "gc.collect()\n",
    "\n",
    "b, a = butter(4, (0.5, 12), fs=sample_rate, btype='bandpass')\n",
    "filt = filtfilt(b, a, tmp, axis=2)\n",
    "rawdata = filt / np.std(filt, axis=(1,2), keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd0dcaf",
   "metadata": {},
   "source": [
    "### Option 2: read the raw and FK-filtered data\n",
    "\n",
    "Note: \n",
    "1. the files *11_14 are for relatively stronger earthquakes (a=-0.95, b=0.65)\n",
    "2. Other files are using a=-1, b=0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eae42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_terra = '/fd1/QibinShi_data/akdas/qibin_data/TERRAtill2023_11_14.hdf5'\n",
    "data_kkfls = '/fd1/QibinShi_data/akdas/qibin_data/KKFLStill2023_11_14.hdf5'\n",
    "with h5py.File(data_terra, 'r') as f:\n",
    "    quake1 = f['raw_quake'][:]\n",
    "    label1 = f['fk_quake'][:]\n",
    "with h5py.File(data_kkfls, 'r') as f:\n",
    "    quake2 = f['raw_quake'][:]\n",
    "    label2 = f['fk_quake'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7b5469",
   "metadata": {},
   "outputs": [],
   "source": [
    "taper_func = light_tukey(1500, alpha=0.1, taper_level=0.5)\n",
    "plt.plot(taper_func)\n",
    "plt.xlim(0,1500)\n",
    "plt.ylim(0,1.1)\n",
    "plt.xticks(np.arange(0, 1500, 250), np.arange(0, 60, 10).astype(int))\n",
    "plt.xlabel('time (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e346e5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 25\n",
    "dchan = 10\n",
    "    \n",
    "tmp_q = np.append(quake2[:,:4500,:], quake1[:,:4500,:], axis=0)\n",
    "tmp_l = np.append(label2[:,:4500,:], label1[:,:4500,:], axis=0)\n",
    "\n",
    "# tmp_q = np.append(quake2[:,:,:], quake1[:,:,:], axis=0)\n",
    "# tmp_l = np.append(label2[:,:,:], label1[:,:,:], axis=0)\n",
    "\n",
    "del quake1, quake2, label1, label2\n",
    "gc.collect()\n",
    "\n",
    "b, a = butter(4, (0.5, 12), fs=sample_rate, btype='bandpass')\n",
    "filt_q = filtfilt(b, a, tmp_q, axis=2)\n",
    "filt_l = filtfilt(b, a, tmp_l, axis=2)\n",
    "rawdata = filt_q / np.std(filt_q, axis=(1,2), keepdims=True)\n",
    "fkdata = filt_l / np.std(filt_l, axis=(1,2), keepdims=True) # * taper_func\n",
    "\n",
    "del tmp_q, tmp_l, filt_q, filt_l\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5146a72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% visualize data\n",
    "time_data = rawdata[2]\n",
    "plt.figure(figsize=(12, 9)); cmap=plt.cm.get_cmap('RdBu'); max_amp = np.median(np.fabs(time_data))*2\n",
    "x, y=np.arange(time_data.shape[1]), np.arange(time_data.shape[0])\n",
    "plt.pcolormesh(x, y, time_data, shading='auto', vmin=-max_amp, vmax=max_amp, cmap=cmap)\n",
    "plt.xticks(np.arange(0, 1500, 250), np.arange(0, 1500/sample_rate, 250/sample_rate).astype(int))\n",
    "plt.yticks(np.arange(0, len(y)//1000*1000, 1000), (np.arange(0, len(y)//1000*1000*dchan, 1000*dchan)/1000).astype(int))\n",
    "plt.xlabel(\"Time (s)\", fontsize=20); plt.ylabel(\"Distance (km)\", fontsize=20)\n",
    "cbr=plt.colorbar(); cbr.set_label('amplitude', fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2a8b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% visualize data and label\n",
    "i=14\n",
    "data_in = rawdata[i, :1500,:]\n",
    "data_lb = fkdata[i, :1500,:]\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 8), constrained_layout=True)\n",
    "cmap=plt.cm.get_cmap('RdBu'); max_amp = np.median(np.fabs(data_in))*2\n",
    "x, y=np.arange(data_in.shape[1]), np.arange(data_in.shape[0])\n",
    "ax[0].pcolormesh(x, y, data_in, shading='auto', vmin=-max_amp, vmax=max_amp, cmap=cmap)\n",
    "ax[1].pcolormesh(x, y, data_lb, shading='auto', vmin=-max_amp, vmax=max_amp, cmap=cmap)\n",
    "# ax[2].pcolormesh(x, y, data_lb/taper_func*light_tukey(1500, alpha=0.1, taper_level=0.3), shading='auto', vmin=-max_amp, vmax=max_amp, cmap=cmap)\n",
    "for i in range(2):\n",
    "    ax[i].set_xticks(np.arange(0, 1500, 250)) \n",
    "    ax[i].set_xticklabels(np.arange(0, 1500/sample_rate, 250/sample_rate).astype(int))\n",
    "    ax[i].set_yticks(np.arange(0, len(y)//200*200, 200))\n",
    "    ax[i].set_yticklabels((np.arange(0, len(y)//200*200*dchan, 200*dchan)/1000).astype(int))\n",
    "    ax[i].set_xlabel(\"Time (s)\", fontsize=24)\n",
    "    ax[i].set_ylabel(\"Distance (km)\", fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d10f1c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f2afebb",
   "metadata": {},
   "source": [
    "### Option 1: input=target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59a1457b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% Shuffle and split dataset\n",
    "X_tr, X, Y_tr, Y = train_test_split(rawdata, rawdata,\n",
    "                                        train_size=0.7,\n",
    "                                        random_state=111)\n",
    "X_va, X_te, Y_va, Y_te = train_test_split(X, Y,\n",
    "                                        train_size=0.5,\n",
    "                                        random_state=121)\n",
    "\n",
    "training_data = dataflow1280(X_tr, stride=320)\n",
    "validation_data = dataflow1280(X_va, stride=320)\n",
    "# test_data = dataflow1280(X_te, mask_ratio=0.5)\n",
    "\n",
    "del tmp, filt, rawdata, X, Y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd83bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f594908c",
   "metadata": {},
   "source": [
    "### Option 2: input !=target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2ea62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Shuffle and split dataset\n",
    "X_tr, X, Y_tr, Y = train_test_split(rawdata, fkdata,\n",
    "                                        train_size=0.7,\n",
    "                                        random_state=111)\n",
    "\n",
    "del rawdata, fkdata\n",
    "gc.collect()\n",
    "\n",
    "X_va, X_te, Y_va, Y_te = train_test_split(X, Y,\n",
    "                                        train_size=0.5,\n",
    "                                        random_state=121)\n",
    "\n",
    "training_data = datalabel(X_tr, Y_tr, mask_ratio=0.5, stride=750, n_masks=5)\n",
    "validation_data = datalabel(X_va, Y_va, mask_ratio=0.5, stride=750, n_masks=5)\n",
    "# test_data = datalabel(X_te, Y_te, mask_ratio=0.5)\n",
    "\n",
    "del X, Y, X_tr, Y_tr, X_va, Y_va, X_te, Y_te\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d955ff",
   "metadata": {},
   "source": [
    "### Construct the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3200dad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Initialize the U-net model \"\"\"\n",
    "model = unet(1, 16, 1024, factors=(5, 3, 2, 2), use_att=False)\n",
    "devc = try_gpu(i=0)\n",
    "model = nn.DataParallel(model, device_ids=[0,1,2,3])  # comment if gpus<4 \n",
    "model.to(devc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e9a2647",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter_share/anaconda3/envs/seismo/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/jupyter_share/anaconda3/envs/seismo/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): MaskedAutoencoderSwinV2(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(1, 48, kernel_size=(10, 10), stride=(10, 10))\n",
       "      (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0): BasicLayer(\n",
       "        dim=48, input_resolution=(128, 128), depth=2\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinTransformerBlock(\n",
       "            dim=48, input_resolution=(128, 128), num_heads=3, window_size=(8, 8), shift_size=(0, 0), mlp_ratio=4\n",
       "            (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=48, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=3\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=48, out_features=144, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=48, out_features=48, bias=True)\n",
       "              (proj_drop): Dropout(p=0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=48, out_features=192, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=192, out_features=48, bias=True)\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            dim=48, input_resolution=(128, 128), num_heads=3, window_size=(8, 8), shift_size=(4, 4), mlp_ratio=4\n",
       "            (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=48, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=3\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=48, out_features=144, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=48, out_features=48, bias=True)\n",
       "              (proj_drop): Dropout(p=0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.018)\n",
       "            (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=48, out_features=192, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=192, out_features=48, bias=True)\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          input_resolution=(128, 128), dim=48\n",
       "          (reduction): Linear(in_features=192, out_features=96, bias=False)\n",
       "          (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicLayer(\n",
       "        dim=96, input_resolution=(64, 64), depth=2\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinTransformerBlock(\n",
       "            dim=96, input_resolution=(64, 64), num_heads=6, window_size=(8, 8), shift_size=(0, 0), mlp_ratio=4\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=96, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=6\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=96, out_features=288, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (proj_drop): Dropout(p=0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.036)\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            dim=96, input_resolution=(64, 64), num_heads=6, window_size=(8, 8), shift_size=(4, 4), mlp_ratio=4\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=96, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=6\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=96, out_features=288, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (proj_drop): Dropout(p=0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.055)\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          input_resolution=(64, 64), dim=96\n",
       "          (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "          (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (2): BasicLayer(\n",
       "        dim=192, input_resolution=(32, 32), depth=6\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinTransformerBlock(\n",
       "            dim=192, input_resolution=(32, 32), num_heads=12, window_size=(8, 8), shift_size=(0, 0), mlp_ratio=4\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=192, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=12\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.073)\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            dim=192, input_resolution=(32, 32), num_heads=12, window_size=(8, 8), shift_size=(4, 4), mlp_ratio=4\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=192, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=12\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.091)\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): SwinTransformerBlock(\n",
       "            dim=192, input_resolution=(32, 32), num_heads=12, window_size=(8, 8), shift_size=(0, 0), mlp_ratio=4\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=192, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=12\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.109)\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): SwinTransformerBlock(\n",
       "            dim=192, input_resolution=(32, 32), num_heads=12, window_size=(8, 8), shift_size=(4, 4), mlp_ratio=4\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=192, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=12\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.127)\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): SwinTransformerBlock(\n",
       "            dim=192, input_resolution=(32, 32), num_heads=12, window_size=(8, 8), shift_size=(0, 0), mlp_ratio=4\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=192, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=12\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.145)\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): SwinTransformerBlock(\n",
       "            dim=192, input_resolution=(32, 32), num_heads=12, window_size=(8, 8), shift_size=(4, 4), mlp_ratio=4\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=192, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=12\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.164)\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          input_resolution=(32, 32), dim=192\n",
       "          (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (3): BasicLayer(\n",
       "        dim=384, input_resolution=(16, 16), depth=2\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinTransformerBlock(\n",
       "            dim=384, input_resolution=(16, 16), num_heads=24, window_size=(8, 8), shift_size=(0, 0), mlp_ratio=4\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=384, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=24\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.182)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            dim=384, input_resolution=(16, 16), num_heads=24, window_size=(8, 8), shift_size=(4, 4), mlp_ratio=4\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=384, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=24\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.200)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decode_layers): ModuleList(\n",
       "      (0): PatchExpand(\n",
       "        input_resolution=(16, 16), dim=384\n",
       "        (expand): Linear(in_features=384, out_features=768, bias=False)\n",
       "        (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): BasicLayer(\n",
       "        dim=192, input_resolution=(32, 32), depth=6\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinTransformerBlock(\n",
       "            dim=192, input_resolution=(32, 32), num_heads=12, window_size=(8, 8), shift_size=(0, 0), mlp_ratio=4\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=192, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=12\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.073)\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            dim=192, input_resolution=(32, 32), num_heads=12, window_size=(8, 8), shift_size=(4, 4), mlp_ratio=4\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=192, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=12\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.091)\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): SwinTransformerBlock(\n",
       "            dim=192, input_resolution=(32, 32), num_heads=12, window_size=(8, 8), shift_size=(0, 0), mlp_ratio=4\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=192, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=12\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.109)\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): SwinTransformerBlock(\n",
       "            dim=192, input_resolution=(32, 32), num_heads=12, window_size=(8, 8), shift_size=(4, 4), mlp_ratio=4\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=192, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=12\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.127)\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): SwinTransformerBlock(\n",
       "            dim=192, input_resolution=(32, 32), num_heads=12, window_size=(8, 8), shift_size=(0, 0), mlp_ratio=4\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=192, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=12\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.145)\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): SwinTransformerBlock(\n",
       "            dim=192, input_resolution=(32, 32), num_heads=12, window_size=(8, 8), shift_size=(4, 4), mlp_ratio=4\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=192, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=12\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.164)\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchExpand(\n",
       "          input_resolution=(32, 32), dim=192\n",
       "          (expand): Linear(in_features=192, out_features=384, bias=False)\n",
       "          (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (2): BasicLayer(\n",
       "        dim=96, input_resolution=(64, 64), depth=2\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinTransformerBlock(\n",
       "            dim=96, input_resolution=(64, 64), num_heads=6, window_size=(8, 8), shift_size=(0, 0), mlp_ratio=4\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=96, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=6\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=96, out_features=288, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (proj_drop): Dropout(p=0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.036)\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            dim=96, input_resolution=(64, 64), num_heads=6, window_size=(8, 8), shift_size=(4, 4), mlp_ratio=4\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=96, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=6\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=96, out_features=288, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (proj_drop): Dropout(p=0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.055)\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchExpand(\n",
       "          input_resolution=(64, 64), dim=96\n",
       "          (expand): Linear(in_features=96, out_features=192, bias=False)\n",
       "          (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (3): BasicLayer(\n",
       "        dim=48, input_resolution=(128, 128), depth=2\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinTransformerBlock(\n",
       "            dim=48, input_resolution=(128, 128), num_heads=3, window_size=(8, 8), shift_size=(0, 0), mlp_ratio=4\n",
       "            (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=48, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=3\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=48, out_features=144, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=48, out_features=48, bias=True)\n",
       "              (proj_drop): Dropout(p=0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=48, out_features=192, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=192, out_features=48, bias=True)\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            dim=48, input_resolution=(128, 128), num_heads=3, window_size=(8, 8), shift_size=(4, 4), mlp_ratio=4\n",
       "            (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              dim=48, window_size=(8, 8), pretrained_window_size=(0, 0), num_heads=3\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "              )\n",
       "              (qkv): Linear(in_features=48, out_features=144, bias=False)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=48, out_features=48, bias=True)\n",
       "              (proj_drop): Dropout(p=0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.018)\n",
       "            (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=48, out_features=192, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (fc2): Linear(in_features=192, out_features=48, bias=True)\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (reverse_patch_embed): ReversePatchEmbed(\n",
       "      (proj): Linear(in_features=48, out_features=100, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models_mae_swinv2 import MaskedAutoencoderSwinV2\n",
    "\n",
    "model = MaskedAutoencoderSwinV2(img_size=1280,\n",
    "                                patch_size=10,\n",
    "                                in_chans=1,\n",
    "                                out_chans=1,\n",
    "                                max_dim=768,\n",
    "                                embed_dim=48,\n",
    "                                depths=[2, 2, 6, 2],\n",
    "                                num_heads=[3, 6, 12, 24],\n",
    "                                window_size=8,\n",
    "                                mlp_ratio=4,\n",
    "                                qkv_bias=True,\n",
    "                                drop_rate=0,\n",
    "                                drop_path_rate=0.2,\n",
    "                                patch_norm=True,\n",
    "                                use_checkpoint=False,\n",
    "                                pretrained_window_sizes=[0, 0, 0, 0],\n",
    "                                skip_connection=False,\n",
    "                                map_to_RGB=False,\n",
    "                                frozen_stages=[])\n",
    "\n",
    "devc = try_gpu(i=0)\n",
    "model = nn.DataParallel(model, device_ids=[0,1,2,3])  # comment if gpus<4 \n",
    "model.to(devc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1dfb12",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f15765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Hyper-parameters for training\n",
    "batch_size = 128\n",
    "lr = 1e-4\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "lr_schedule = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                         mode='min', \n",
    "                                                         factor=0.8, \n",
    "                                                         patience=5, \n",
    "                                                         threshold=0.001, \n",
    "                                                         threshold_mode='rel', \n",
    "                                                         cooldown=0, \n",
    "                                                         min_lr=1e-6, \n",
    "                                                         eps=1e-08, \n",
    "                                                         verbose=True)\n",
    "\n",
    "train_iter = DataLoader(training_data, batch_size=batch_size, shuffle=False)\n",
    "validate_iter = DataLoader(validation_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc1156c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bfec074",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1/1000] train_loss: 0.60424 valid_loss: 0.57310 time per epoch: 83.251 s\n",
      "[   2/1000] train_loss: 0.58093 valid_loss: 0.55154 time per epoch: 79.418 s\n",
      "[   3/1000] train_loss: 0.56257 valid_loss: 0.53178 time per epoch: 79.221 s\n",
      "[   4/1000] train_loss: 0.54437 valid_loss: 0.51689 time per epoch: 79.334 s\n",
      "[   5/1000] train_loss: 0.53226 valid_loss: 0.50589 time per epoch: 79.411 s\n",
      "[   6/1000] train_loss: 0.52312 valid_loss: 0.49807 time per epoch: 79.237 s\n",
      "[   7/1000] train_loss: 0.51573 valid_loss: 0.49083 time per epoch: 79.139 s\n",
      "[   8/1000] train_loss: 0.50878 valid_loss: 0.48384 time per epoch: 79.206 s\n",
      "[   9/1000] train_loss: 0.50240 valid_loss: 0.47797 time per epoch: 80.258 s\n",
      "[  10/1000] train_loss: 0.49568 valid_loss: 0.47090 time per epoch: 79.879 s\n",
      "[  11/1000] train_loss: 0.48911 valid_loss: 0.46442 time per epoch: 79.488 s\n",
      "[  12/1000] train_loss: 0.48274 valid_loss: 0.45847 time per epoch: 80.237 s\n",
      "[  13/1000] train_loss: 0.47709 valid_loss: 0.45328 time per epoch: 79.578 s\n",
      "[  14/1000] train_loss: 0.47229 valid_loss: 0.44919 time per epoch: 78.277 s\n",
      "[  15/1000] train_loss: 0.46807 valid_loss: 0.44532 time per epoch: 78.178 s\n",
      "[  16/1000] train_loss: 0.46423 valid_loss: 0.44148 time per epoch: 79.083 s\n",
      "[  17/1000] train_loss: 0.46062 valid_loss: 0.43844 time per epoch: 79.536 s\n",
      "[  18/1000] train_loss: 0.45717 valid_loss: 0.43498 time per epoch: 79.476 s\n",
      "[  19/1000] train_loss: 0.45376 valid_loss: 0.43202 time per epoch: 79.422 s\n",
      "[  20/1000] train_loss: 0.45073 valid_loss: 0.42920 time per epoch: 79.378 s\n",
      "[  21/1000] train_loss: 0.44786 valid_loss: 0.42678 time per epoch: 79.065 s\n",
      "[  22/1000] train_loss: 0.44518 valid_loss: 0.42430 time per epoch: 78.976 s\n",
      "[  23/1000] train_loss: 0.44263 valid_loss: 0.42203 time per epoch: 78.571 s\n",
      "[  24/1000] train_loss: 0.44034 valid_loss: 0.41993 time per epoch: 78.756 s\n",
      "[  25/1000] train_loss: 0.43818 valid_loss: 0.41802 time per epoch: 79.285 s\n",
      "[  26/1000] train_loss: 0.43603 valid_loss: 0.41604 time per epoch: 79.677 s\n",
      "[  27/1000] train_loss: 0.43395 valid_loss: 0.41420 time per epoch: 79.452 s\n",
      "[  28/1000] train_loss: 0.43184 valid_loss: 0.41238 time per epoch: 79.434 s\n",
      "[  29/1000] train_loss: 0.42988 valid_loss: 0.41103 time per epoch: 79.315 s\n",
      "[  30/1000] train_loss: 0.42791 valid_loss: 0.40870 time per epoch: 79.579 s\n",
      "[  31/1000] train_loss: 0.42594 valid_loss: 0.40707 time per epoch: 79.590 s\n",
      "[  32/1000] train_loss: 0.42379 valid_loss: 0.40518 time per epoch: 79.434 s\n",
      "[  33/1000] train_loss: 0.42207 valid_loss: 0.40354 time per epoch: 79.454 s\n",
      "[  34/1000] train_loss: 0.42023 valid_loss: 0.40272 time per epoch: 79.464 s\n",
      "[  35/1000] train_loss: 0.41835 valid_loss: 0.39994 time per epoch: 79.243 s\n",
      "[  36/1000] train_loss: 0.41595 valid_loss: 0.39930 time per epoch: 78.971 s\n",
      "[  37/1000] train_loss: 0.41413 valid_loss: 0.39593 time per epoch: 78.455 s\n",
      "[  38/1000] train_loss: 0.41238 valid_loss: 0.39447 time per epoch: 78.187 s\n",
      "[  39/1000] train_loss: 0.40969 valid_loss: 0.39187 time per epoch: 77.993 s\n",
      "[  40/1000] train_loss: 0.40720 valid_loss: 0.38964 time per epoch: 78.044 s\n",
      "[  41/1000] train_loss: 0.40516 valid_loss: 0.38756 time per epoch: 77.870 s\n",
      "[  42/1000] train_loss: 0.40285 valid_loss: 0.38557 time per epoch: 77.881 s\n",
      "[  43/1000] train_loss: 0.40071 valid_loss: 0.38441 time per epoch: 77.797 s\n",
      "[  44/1000] train_loss: 0.39897 valid_loss: 0.38220 time per epoch: 78.629 s\n",
      "[  45/1000] train_loss: 0.39694 valid_loss: 0.38029 time per epoch: 79.131 s\n",
      "[  46/1000] train_loss: 0.39518 valid_loss: 0.37843 time per epoch: 78.965 s\n",
      "[  47/1000] train_loss: 0.39305 valid_loss: 0.37699 time per epoch: 78.858 s\n",
      "[  48/1000] train_loss: 0.39118 valid_loss: 0.37512 time per epoch: 79.318 s\n",
      "[  49/1000] train_loss: 0.38923 valid_loss: 0.37339 time per epoch: 78.699 s\n",
      "[  50/1000] train_loss: 0.38758 valid_loss: 0.37210 time per epoch: 78.745 s\n",
      "[  51/1000] train_loss: 0.38632 valid_loss: 0.37079 time per epoch: 78.746 s\n",
      "Validation loss decreased (inf --> 0.370786).  Saving model ...\n",
      "[  52/1000] train_loss: 0.38484 valid_loss: 0.37047 time per epoch: 78.037 s\n",
      "Validation loss decreased (0.370786 --> 0.370472).  Saving model ...\n",
      "[  53/1000] train_loss: 0.38323 valid_loss: 0.36873 time per epoch: 78.442 s\n",
      "Validation loss decreased (0.370472 --> 0.368732).  Saving model ...\n",
      "[  54/1000] train_loss: 0.38856 valid_loss: 0.37063 time per epoch: 78.380 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[  55/1000] train_loss: 0.38277 valid_loss: 0.36764 time per epoch: 78.562 s\n",
      "Validation loss decreased (0.368732 --> 0.367639).  Saving model ...\n",
      "[  56/1000] train_loss: 0.38113 valid_loss: 0.36632 time per epoch: 78.534 s\n",
      "Validation loss decreased (0.367639 --> 0.366320).  Saving model ...\n",
      "[  57/1000] train_loss: 0.37924 valid_loss: 0.36511 time per epoch: 78.444 s\n",
      "Validation loss decreased (0.366320 --> 0.365108).  Saving model ...\n",
      "[  58/1000] train_loss: 0.37791 valid_loss: 0.36412 time per epoch: 78.469 s\n",
      "Validation loss decreased (0.365108 --> 0.364119).  Saving model ...\n",
      "[  59/1000] train_loss: 0.37661 valid_loss: 0.36334 time per epoch: 78.448 s\n",
      "Validation loss decreased (0.364119 --> 0.363336).  Saving model ...\n",
      "[  60/1000] train_loss: 0.37552 valid_loss: 0.36223 time per epoch: 78.524 s\n",
      "Validation loss decreased (0.363336 --> 0.362232).  Saving model ...\n",
      "[  61/1000] train_loss: 0.37454 valid_loss: 0.36158 time per epoch: 78.345 s\n",
      "Validation loss decreased (0.362232 --> 0.361576).  Saving model ...\n",
      "[  62/1000] train_loss: 0.37349 valid_loss: 0.36064 time per epoch: 78.501 s\n",
      "Validation loss decreased (0.361576 --> 0.360645).  Saving model ...\n",
      "[  63/1000] train_loss: 0.37259 valid_loss: 0.35979 time per epoch: 78.584 s\n",
      "Validation loss decreased (0.360645 --> 0.359786).  Saving model ...\n",
      "[  64/1000] train_loss: 0.37152 valid_loss: 0.35908 time per epoch: 78.678 s\n",
      "Validation loss decreased (0.359786 --> 0.359077).  Saving model ...\n",
      "[  65/1000] train_loss: 0.37051 valid_loss: 0.35828 time per epoch: 79.551 s\n",
      "Validation loss decreased (0.359077 --> 0.358275).  Saving model ...\n",
      "[  66/1000] train_loss: 0.37012 valid_loss: 0.35864 time per epoch: 79.534 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[  67/1000] train_loss: 0.36908 valid_loss: 0.35681 time per epoch: 79.625 s\n",
      "Validation loss decreased (0.358275 --> 0.356815).  Saving model ...\n",
      "[  68/1000] train_loss: 0.36795 valid_loss: 0.35621 time per epoch: 79.749 s\n",
      "Validation loss decreased (0.356815 --> 0.356215).  Saving model ...\n",
      "[  69/1000] train_loss: 0.36665 valid_loss: 0.35521 time per epoch: 79.014 s\n",
      "Validation loss decreased (0.356215 --> 0.355210).  Saving model ...\n",
      "[  70/1000] train_loss: 0.36559 valid_loss: 0.35439 time per epoch: 79.505 s\n",
      "Validation loss decreased (0.355210 --> 0.354393).  Saving model ...\n",
      "[  71/1000] train_loss: 0.36479 valid_loss: 0.35362 time per epoch: 79.351 s\n",
      "Validation loss decreased (0.354393 --> 0.353623).  Saving model ...\n",
      "[  72/1000] train_loss: 0.36366 valid_loss: 0.35314 time per epoch: 79.451 s\n",
      "Validation loss decreased (0.353623 --> 0.353136).  Saving model ...\n",
      "[  73/1000] train_loss: 0.36260 valid_loss: 0.35216 time per epoch: 79.678 s\n",
      "Validation loss decreased (0.353136 --> 0.352164).  Saving model ...\n",
      "[  74/1000] train_loss: 0.36159 valid_loss: 0.35172 time per epoch: 79.711 s\n",
      "Validation loss decreased (0.352164 --> 0.351721).  Saving model ...\n",
      "[  75/1000] train_loss: 0.36058 valid_loss: 0.35044 time per epoch: 79.245 s\n",
      "Validation loss decreased (0.351721 --> 0.350436).  Saving model ...\n",
      "[  76/1000] train_loss: 0.35963 valid_loss: 0.34977 time per epoch: 79.281 s\n",
      "Validation loss decreased (0.350436 --> 0.349768).  Saving model ...\n",
      "[  77/1000] train_loss: 0.35861 valid_loss: 0.34885 time per epoch: 79.276 s\n",
      "Validation loss decreased (0.349768 --> 0.348851).  Saving model ...\n",
      "[  78/1000] train_loss: 0.35825 valid_loss: 0.34854 time per epoch: 79.417 s\n",
      "Validation loss decreased (0.348851 --> 0.348541).  Saving model ...\n",
      "[  79/1000] train_loss: 0.35924 valid_loss: 0.35227 time per epoch: 79.399 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[  80/1000] train_loss: 0.35759 valid_loss: 0.34738 time per epoch: 79.210 s\n",
      "Validation loss decreased (0.348541 --> 0.347380).  Saving model ...\n",
      "[  81/1000] train_loss: 0.35634 valid_loss: 0.34713 time per epoch: 79.529 s\n",
      "Validation loss decreased (0.347380 --> 0.347132).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  82/1000] train_loss: 0.35484 valid_loss: 0.34534 time per epoch: 79.240 s\n",
      "Validation loss decreased (0.347132 --> 0.345342).  Saving model ...\n",
      "[  83/1000] train_loss: 0.35307 valid_loss: 0.34403 time per epoch: 79.295 s\n",
      "Validation loss decreased (0.345342 --> 0.344031).  Saving model ...\n",
      "[  84/1000] train_loss: 0.35179 valid_loss: 0.34280 time per epoch: 79.505 s\n",
      "Validation loss decreased (0.344031 --> 0.342796).  Saving model ...\n",
      "[  85/1000] train_loss: 0.35078 valid_loss: 0.34207 time per epoch: 79.531 s\n",
      "Validation loss decreased (0.342796 --> 0.342068).  Saving model ...\n",
      "[  86/1000] train_loss: 0.34963 valid_loss: 0.34104 time per epoch: 79.550 s\n",
      "Validation loss decreased (0.342068 --> 0.341042).  Saving model ...\n",
      "[  87/1000] train_loss: 0.34841 valid_loss: 0.34032 time per epoch: 79.329 s\n",
      "Validation loss decreased (0.341042 --> 0.340319).  Saving model ...\n",
      "[  88/1000] train_loss: 0.34734 valid_loss: 0.33929 time per epoch: 79.569 s\n",
      "Validation loss decreased (0.340319 --> 0.339292).  Saving model ...\n",
      "[  89/1000] train_loss: 0.34653 valid_loss: 0.33828 time per epoch: 79.702 s\n",
      "Validation loss decreased (0.339292 --> 0.338277).  Saving model ...\n",
      "[  90/1000] train_loss: 0.34521 valid_loss: 0.33770 time per epoch: 79.618 s\n",
      "Validation loss decreased (0.338277 --> 0.337697).  Saving model ...\n",
      "[  91/1000] train_loss: 0.34429 valid_loss: 0.33632 time per epoch: 79.584 s\n",
      "Validation loss decreased (0.337697 --> 0.336318).  Saving model ...\n",
      "[  92/1000] train_loss: 0.34320 valid_loss: 0.33567 time per epoch: 79.608 s\n",
      "Validation loss decreased (0.336318 --> 0.335673).  Saving model ...\n",
      "[  93/1000] train_loss: 0.34338 valid_loss: 0.35933 time per epoch: 79.746 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[  94/1000] train_loss: 0.35311 valid_loss: 0.33963 time per epoch: 79.970 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[  95/1000] train_loss: 0.34563 valid_loss: 0.33560 time per epoch: 79.942 s\n",
      "Validation loss decreased (0.335673 --> 0.335602).  Saving model ...\n",
      "[  96/1000] train_loss: 0.34188 valid_loss: 0.33281 time per epoch: 79.580 s\n",
      "Validation loss decreased (0.335602 --> 0.332806).  Saving model ...\n",
      "[  97/1000] train_loss: 0.33890 valid_loss: 0.33153 time per epoch: 79.151 s\n",
      "Validation loss decreased (0.332806 --> 0.331527).  Saving model ...\n",
      "[  98/1000] train_loss: 0.33756 valid_loss: 0.33052 time per epoch: 79.100 s\n",
      "Validation loss decreased (0.331527 --> 0.330515).  Saving model ...\n",
      "[  99/1000] train_loss: 0.33651 valid_loss: 0.33007 time per epoch: 79.079 s\n",
      "Validation loss decreased (0.330515 --> 0.330074).  Saving model ...\n",
      "[ 100/1000] train_loss: 0.33573 valid_loss: 0.32894 time per epoch: 79.241 s\n",
      "Validation loss decreased (0.330074 --> 0.328944).  Saving model ...\n",
      "[ 101/1000] train_loss: 0.33432 valid_loss: 0.32817 time per epoch: 79.518 s\n",
      "Validation loss decreased (0.328944 --> 0.328168).  Saving model ...\n",
      "[ 102/1000] train_loss: 0.33345 valid_loss: 0.32708 time per epoch: 79.478 s\n",
      "Validation loss decreased (0.328168 --> 0.327081).  Saving model ...\n",
      "[ 103/1000] train_loss: 0.33236 valid_loss: 0.32607 time per epoch: 79.541 s\n",
      "Validation loss decreased (0.327081 --> 0.326066).  Saving model ...\n",
      "[ 104/1000] train_loss: 0.33138 valid_loss: 0.32533 time per epoch: 79.310 s\n",
      "Validation loss decreased (0.326066 --> 0.325328).  Saving model ...\n",
      "[ 105/1000] train_loss: 0.33038 valid_loss: 0.32476 time per epoch: 79.294 s\n",
      "Validation loss decreased (0.325328 --> 0.324759).  Saving model ...\n",
      "[ 106/1000] train_loss: 0.32916 valid_loss: 0.32337 time per epoch: 79.412 s\n",
      "Validation loss decreased (0.324759 --> 0.323375).  Saving model ...\n",
      "[ 107/1000] train_loss: 0.32819 valid_loss: 0.32228 time per epoch: 79.593 s\n",
      "Validation loss decreased (0.323375 --> 0.322284).  Saving model ...\n",
      "[ 108/1000] train_loss: 0.32713 valid_loss: 0.32194 time per epoch: 79.519 s\n",
      "Validation loss decreased (0.322284 --> 0.321942).  Saving model ...\n",
      "[ 109/1000] train_loss: 0.32617 valid_loss: 0.32047 time per epoch: 79.412 s\n",
      "Validation loss decreased (0.321942 --> 0.320473).  Saving model ...\n",
      "[ 110/1000] train_loss: 0.32488 valid_loss: 0.32188 time per epoch: 79.311 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 111/1000] train_loss: 0.32437 valid_loss: 0.31894 time per epoch: 79.414 s\n",
      "Validation loss decreased (0.320473 --> 0.318938).  Saving model ...\n",
      "[ 112/1000] train_loss: 0.32283 valid_loss: 0.31858 time per epoch: 79.454 s\n",
      "Validation loss decreased (0.318938 --> 0.318578).  Saving model ...\n",
      "[ 113/1000] train_loss: 0.32166 valid_loss: 0.31730 time per epoch: 79.329 s\n",
      "Validation loss decreased (0.318578 --> 0.317301).  Saving model ...\n",
      "[ 114/1000] train_loss: 0.32096 valid_loss: 0.31597 time per epoch: 79.435 s\n",
      "Validation loss decreased (0.317301 --> 0.315974).  Saving model ...\n",
      "[ 115/1000] train_loss: 0.31956 valid_loss: 0.31505 time per epoch: 78.996 s\n",
      "Validation loss decreased (0.315974 --> 0.315049).  Saving model ...\n",
      "[ 116/1000] train_loss: 0.31865 valid_loss: 0.31448 time per epoch: 79.059 s\n",
      "Validation loss decreased (0.315049 --> 0.314477).  Saving model ...\n",
      "[ 117/1000] train_loss: 0.31781 valid_loss: 0.31425 time per epoch: 79.188 s\n",
      "Validation loss decreased (0.314477 --> 0.314252).  Saving model ...\n",
      "[ 118/1000] train_loss: 0.31696 valid_loss: 0.31288 time per epoch: 79.115 s\n",
      "Validation loss decreased (0.314252 --> 0.312881).  Saving model ...\n",
      "[ 119/1000] train_loss: 0.31595 valid_loss: 0.31254 time per epoch: 79.077 s\n",
      "Validation loss decreased (0.312881 --> 0.312541).  Saving model ...\n",
      "[ 120/1000] train_loss: 0.31534 valid_loss: 0.31148 time per epoch: 79.042 s\n",
      "Validation loss decreased (0.312541 --> 0.311480).  Saving model ...\n",
      "[ 121/1000] train_loss: 0.31453 valid_loss: 0.31117 time per epoch: 79.130 s\n",
      "Validation loss decreased (0.311480 --> 0.311174).  Saving model ...\n",
      "[ 122/1000] train_loss: 0.31387 valid_loss: 0.31136 time per epoch: 79.056 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 123/1000] train_loss: 0.31309 valid_loss: 0.30961 time per epoch: 79.533 s\n",
      "Validation loss decreased (0.311174 --> 0.309608).  Saving model ...\n",
      "[ 124/1000] train_loss: 0.31594 valid_loss: 0.31546 time per epoch: 79.631 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 125/1000] train_loss: 0.31613 valid_loss: 0.30943 time per epoch: 79.661 s\n",
      "Validation loss decreased (0.309608 --> 0.309430).  Saving model ...\n",
      "[ 126/1000] train_loss: 0.31113 valid_loss: 0.30729 time per epoch: 79.378 s\n",
      "Validation loss decreased (0.309430 --> 0.307290).  Saving model ...\n",
      "[ 127/1000] train_loss: 0.30963 valid_loss: 0.30666 time per epoch: 79.315 s\n",
      "Validation loss decreased (0.307290 --> 0.306663).  Saving model ...\n",
      "[ 128/1000] train_loss: 0.30890 valid_loss: 0.30608 time per epoch: 79.621 s\n",
      "Validation loss decreased (0.306663 --> 0.306078).  Saving model ...\n",
      "[ 129/1000] train_loss: 0.30768 valid_loss: 0.30512 time per epoch: 79.766 s\n",
      "Validation loss decreased (0.306078 --> 0.305118).  Saving model ...\n",
      "[ 130/1000] train_loss: 0.30744 valid_loss: 0.30583 time per epoch: 79.673 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 131/1000] train_loss: 0.30638 valid_loss: 0.30433 time per epoch: 79.574 s\n",
      "Validation loss decreased (0.305118 --> 0.304328).  Saving model ...\n",
      "[ 132/1000] train_loss: 0.30553 valid_loss: 0.30332 time per epoch: 79.326 s\n",
      "Validation loss decreased (0.304328 --> 0.303321).  Saving model ...\n",
      "[ 133/1000] train_loss: 0.30454 valid_loss: 0.30283 time per epoch: 79.316 s\n",
      "Validation loss decreased (0.303321 --> 0.302832).  Saving model ...\n",
      "[ 134/1000] train_loss: 0.30448 valid_loss: 0.30215 time per epoch: 79.236 s\n",
      "Validation loss decreased (0.302832 --> 0.302149).  Saving model ...\n",
      "[ 135/1000] train_loss: 0.30379 valid_loss: 0.30160 time per epoch: 79.328 s\n",
      "Validation loss decreased (0.302149 --> 0.301602).  Saving model ...\n",
      "[ 136/1000] train_loss: 0.30261 valid_loss: 0.30200 time per epoch: 79.369 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 137/1000] train_loss: 0.30236 valid_loss: 0.30055 time per epoch: 79.231 s\n",
      "Validation loss decreased (0.301602 --> 0.300545).  Saving model ...\n",
      "[ 138/1000] train_loss: 0.30120 valid_loss: 0.30086 time per epoch: 79.306 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 139/1000] train_loss: 0.30105 valid_loss: 0.29966 time per epoch: 79.175 s\n",
      "Validation loss decreased (0.300545 --> 0.299660).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 140/1000] train_loss: 0.30048 valid_loss: 0.29944 time per epoch: 79.489 s\n",
      "Validation loss decreased (0.299660 --> 0.299443).  Saving model ...\n",
      "[ 141/1000] train_loss: 0.29978 valid_loss: 0.29953 time per epoch: 79.390 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 142/1000] train_loss: 0.29928 valid_loss: 0.29829 time per epoch: 79.129 s\n",
      "Validation loss decreased (0.299443 --> 0.298291).  Saving model ...\n",
      "[ 143/1000] train_loss: 0.29829 valid_loss: 0.29790 time per epoch: 79.179 s\n",
      "Validation loss decreased (0.298291 --> 0.297896).  Saving model ...\n",
      "[ 144/1000] train_loss: 0.29815 valid_loss: 0.29812 time per epoch: 79.228 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 145/1000] train_loss: 0.29786 valid_loss: 0.29739 time per epoch: 79.415 s\n",
      "Validation loss decreased (0.297896 --> 0.297391).  Saving model ...\n",
      "[ 146/1000] train_loss: 0.29727 valid_loss: 0.29731 time per epoch: 79.102 s\n",
      "Validation loss decreased (0.297391 --> 0.297314).  Saving model ...\n",
      "[ 147/1000] train_loss: 0.29663 valid_loss: 0.29682 time per epoch: 79.130 s\n",
      "Validation loss decreased (0.297314 --> 0.296822).  Saving model ...\n",
      "[ 148/1000] train_loss: 0.29573 valid_loss: 0.29581 time per epoch: 79.117 s\n",
      "Validation loss decreased (0.296822 --> 0.295812).  Saving model ...\n",
      "[ 149/1000] train_loss: 0.29558 valid_loss: 0.29579 time per epoch: 79.250 s\n",
      "Validation loss decreased (0.295812 --> 0.295792).  Saving model ...\n",
      "[ 150/1000] train_loss: 0.29527 valid_loss: 0.29567 time per epoch: 79.522 s\n",
      "Validation loss decreased (0.295792 --> 0.295672).  Saving model ...\n",
      "[ 151/1000] train_loss: 0.29503 valid_loss: 0.29521 time per epoch: 79.424 s\n",
      "Validation loss decreased (0.295672 --> 0.295206).  Saving model ...\n",
      "[ 152/1000] train_loss: 0.29410 valid_loss: 0.29498 time per epoch: 79.382 s\n",
      "Validation loss decreased (0.295206 --> 0.294976).  Saving model ...\n",
      "[ 153/1000] train_loss: 0.29387 valid_loss: 0.29510 time per epoch: 79.270 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 154/1000] train_loss: 0.29289 valid_loss: 0.29399 time per epoch: 79.427 s\n",
      "Validation loss decreased (0.294976 --> 0.293990).  Saving model ...\n",
      "[ 155/1000] train_loss: 0.29279 valid_loss: 0.29385 time per epoch: 79.385 s\n",
      "Validation loss decreased (0.293990 --> 0.293850).  Saving model ...\n",
      "[ 156/1000] train_loss: 0.29243 valid_loss: 0.29380 time per epoch: 79.476 s\n",
      "Validation loss decreased (0.293850 --> 0.293795).  Saving model ...\n",
      "[ 157/1000] train_loss: 0.29260 valid_loss: 0.29616 time per epoch: 80.052 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 158/1000] train_loss: 0.30788 valid_loss: 0.30033 time per epoch: 79.095 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 159/1000] train_loss: 0.29773 valid_loss: 0.29693 time per epoch: 79.182 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 160/1000] train_loss: 0.29310 valid_loss: 0.29361 time per epoch: 79.343 s\n",
      "Validation loss decreased (0.293795 --> 0.293609).  Saving model ...\n",
      "[ 161/1000] train_loss: 0.29195 valid_loss: 0.29307 time per epoch: 79.138 s\n",
      "Validation loss decreased (0.293609 --> 0.293067).  Saving model ...\n",
      "[ 162/1000] train_loss: 0.29066 valid_loss: 0.29266 time per epoch: 79.128 s\n",
      "Validation loss decreased (0.293067 --> 0.292656).  Saving model ...\n",
      "[ 163/1000] train_loss: 0.28986 valid_loss: 0.29222 time per epoch: 79.280 s\n",
      "Validation loss decreased (0.292656 --> 0.292221).  Saving model ...\n",
      "[ 164/1000] train_loss: 0.28946 valid_loss: 0.29223 time per epoch: 79.430 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 165/1000] train_loss: 0.28917 valid_loss: 0.29138 time per epoch: 79.401 s\n",
      "Validation loss decreased (0.292221 --> 0.291382).  Saving model ...\n",
      "[ 166/1000] train_loss: 0.28898 valid_loss: 0.29122 time per epoch: 79.478 s\n",
      "Validation loss decreased (0.291382 --> 0.291216).  Saving model ...\n",
      "[ 167/1000] train_loss: 0.28865 valid_loss: 0.29245 time per epoch: 79.252 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 168/1000] train_loss: 0.28826 valid_loss: 0.29314 time per epoch: 79.423 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 169/1000] train_loss: 0.28805 valid_loss: 0.29114 time per epoch: 79.257 s\n",
      "Validation loss decreased (0.291216 --> 0.291143).  Saving model ...\n",
      "[ 170/1000] train_loss: 0.28751 valid_loss: 0.29018 time per epoch: 79.239 s\n",
      "Validation loss decreased (0.291143 --> 0.290181).  Saving model ...\n",
      "[ 171/1000] train_loss: 0.28775 valid_loss: 0.29034 time per epoch: 79.369 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 172/1000] train_loss: 0.28794 valid_loss: 0.29086 time per epoch: 79.564 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 173/1000] train_loss: 0.28745 valid_loss: 0.29081 time per epoch: 79.699 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 174/1000] train_loss: 0.28726 valid_loss: 0.29162 time per epoch: 79.449 s\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[ 175/1000] train_loss: 0.28796 valid_loss: 0.29054 time per epoch: 79.525 s\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch 00176: reducing learning rate of group 0 to 8.0000e-05.\n",
      "[ 176/1000] train_loss: 0.28760 valid_loss: 0.29341 time per epoch: 79.273 s\n",
      "EarlyStopping counter: 6 out of 30\n",
      "[ 177/1000] train_loss: 0.28703 valid_loss: 0.28922 time per epoch: 79.334 s\n",
      "Validation loss decreased (0.290181 --> 0.289219).  Saving model ...\n",
      "[ 178/1000] train_loss: 0.28546 valid_loss: 0.28869 time per epoch: 79.612 s\n",
      "Validation loss decreased (0.289219 --> 0.288691).  Saving model ...\n",
      "[ 179/1000] train_loss: 0.28470 valid_loss: 0.28824 time per epoch: 79.491 s\n",
      "Validation loss decreased (0.288691 --> 0.288238).  Saving model ...\n",
      "[ 180/1000] train_loss: 0.28415 valid_loss: 0.28798 time per epoch: 79.300 s\n",
      "Validation loss decreased (0.288238 --> 0.287984).  Saving model ...\n",
      "[ 181/1000] train_loss: 0.28402 valid_loss: 0.28778 time per epoch: 79.352 s\n",
      "Validation loss decreased (0.287984 --> 0.287784).  Saving model ...\n",
      "[ 182/1000] train_loss: 0.28356 valid_loss: 0.28774 time per epoch: 79.013 s\n",
      "Validation loss decreased (0.287784 --> 0.287743).  Saving model ...\n",
      "[ 183/1000] train_loss: 0.28374 valid_loss: 0.28756 time per epoch: 79.538 s\n",
      "Validation loss decreased (0.287743 --> 0.287555).  Saving model ...\n",
      "[ 184/1000] train_loss: 0.28323 valid_loss: 0.28751 time per epoch: 79.586 s\n",
      "Validation loss decreased (0.287555 --> 0.287512).  Saving model ...\n",
      "[ 185/1000] train_loss: 0.28314 valid_loss: 0.28723 time per epoch: 79.279 s\n",
      "Validation loss decreased (0.287512 --> 0.287226).  Saving model ...\n",
      "[ 186/1000] train_loss: 0.28282 valid_loss: 0.28740 time per epoch: 79.685 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 187/1000] train_loss: 0.28284 valid_loss: 0.28714 time per epoch: 79.500 s\n",
      "Validation loss decreased (0.287226 --> 0.287136).  Saving model ...\n",
      "[ 188/1000] train_loss: 0.28236 valid_loss: 0.28736 time per epoch: 79.254 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 189/1000] train_loss: 0.28250 valid_loss: 0.28831 time per epoch: 79.377 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 190/1000] train_loss: 0.28251 valid_loss: 0.28688 time per epoch: 79.160 s\n",
      "Validation loss decreased (0.287136 --> 0.286882).  Saving model ...\n",
      "[ 191/1000] train_loss: 0.28219 valid_loss: 0.28732 time per epoch: 79.438 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 192/1000] train_loss: 0.28195 valid_loss: 0.28711 time per epoch: 79.414 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 193/1000] train_loss: 0.28151 valid_loss: 0.28757 time per epoch: 79.024 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 194/1000] train_loss: 0.28145 valid_loss: 0.28649 time per epoch: 79.162 s\n",
      "Validation loss decreased (0.286882 --> 0.286495).  Saving model ...\n",
      "[ 195/1000] train_loss: 0.28100 valid_loss: 0.28596 time per epoch: 79.109 s\n",
      "Validation loss decreased (0.286495 --> 0.285956).  Saving model ...\n",
      "[ 196/1000] train_loss: 0.28041 valid_loss: 0.28580 time per epoch: 79.031 s\n",
      "Validation loss decreased (0.285956 --> 0.285805).  Saving model ...\n",
      "[ 197/1000] train_loss: 0.28042 valid_loss: 0.28631 time per epoch: 79.065 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 198/1000] train_loss: 0.28025 valid_loss: 0.28634 time per epoch: 79.274 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 199/1000] train_loss: 0.28018 valid_loss: 0.28560 time per epoch: 79.372 s\n",
      "Validation loss decreased (0.285805 --> 0.285598).  Saving model ...\n",
      "[ 200/1000] train_loss: 0.28002 valid_loss: 0.28558 time per epoch: 78.975 s\n",
      "Validation loss decreased (0.285598 --> 0.285583).  Saving model ...\n",
      "[ 201/1000] train_loss: 0.27978 valid_loss: 0.28530 time per epoch: 79.110 s\n",
      "Validation loss decreased (0.285583 --> 0.285299).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 202/1000] train_loss: 0.27961 valid_loss: 0.28578 time per epoch: 79.335 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 203/1000] train_loss: 0.27978 valid_loss: 0.28592 time per epoch: 79.268 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 204/1000] train_loss: 0.28032 valid_loss: 0.28670 time per epoch: 79.062 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 205/1000] train_loss: 0.27963 valid_loss: 0.28568 time per epoch: 78.942 s\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[ 206/1000] train_loss: 0.27934 valid_loss: 0.28711 time per epoch: 78.992 s\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch 00207: reducing learning rate of group 0 to 6.4000e-05.\n",
      "[ 207/1000] train_loss: 0.27927 valid_loss: 0.28536 time per epoch: 79.094 s\n",
      "EarlyStopping counter: 6 out of 30\n",
      "[ 208/1000] train_loss: 0.27845 valid_loss: 0.28458 time per epoch: 79.238 s\n",
      "Validation loss decreased (0.285299 --> 0.284582).  Saving model ...\n",
      "[ 209/1000] train_loss: 0.27770 valid_loss: 0.28428 time per epoch: 79.099 s\n",
      "Validation loss decreased (0.284582 --> 0.284280).  Saving model ...\n",
      "[ 210/1000] train_loss: 0.27745 valid_loss: 0.28398 time per epoch: 79.174 s\n",
      "Validation loss decreased (0.284280 --> 0.283981).  Saving model ...\n",
      "[ 211/1000] train_loss: 0.27723 valid_loss: 0.28363 time per epoch: 79.322 s\n",
      "Validation loss decreased (0.283981 --> 0.283628).  Saving model ...\n",
      "[ 212/1000] train_loss: 0.27705 valid_loss: 0.28348 time per epoch: 79.242 s\n",
      "Validation loss decreased (0.283628 --> 0.283483).  Saving model ...\n",
      "[ 213/1000] train_loss: 0.27677 valid_loss: 0.28331 time per epoch: 79.151 s\n",
      "Validation loss decreased (0.283483 --> 0.283309).  Saving model ...\n",
      "[ 214/1000] train_loss: 0.27638 valid_loss: 0.28336 time per epoch: 79.211 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 215/1000] train_loss: 0.27633 valid_loss: 0.28320 time per epoch: 79.133 s\n",
      "Validation loss decreased (0.283309 --> 0.283202).  Saving model ...\n",
      "[ 216/1000] train_loss: 0.27619 valid_loss: 0.28315 time per epoch: 79.139 s\n",
      "Validation loss decreased (0.283202 --> 0.283146).  Saving model ...\n",
      "[ 217/1000] train_loss: 0.27595 valid_loss: 0.28305 time per epoch: 79.231 s\n",
      "Validation loss decreased (0.283146 --> 0.283049).  Saving model ...\n",
      "[ 218/1000] train_loss: 0.27600 valid_loss: 0.28288 time per epoch: 79.110 s\n",
      "Validation loss decreased (0.283049 --> 0.282878).  Saving model ...\n",
      "[ 219/1000] train_loss: 0.27585 valid_loss: 0.28310 time per epoch: 78.980 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 220/1000] train_loss: 0.27568 valid_loss: 0.28296 time per epoch: 79.245 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 221/1000] train_loss: 0.27562 valid_loss: 0.28327 time per epoch: 79.369 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 222/1000] train_loss: 0.27588 valid_loss: 0.28310 time per epoch: 79.119 s\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[ 223/1000] train_loss: 0.27565 valid_loss: 0.28318 time per epoch: 79.073 s\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch 00224: reducing learning rate of group 0 to 5.1200e-05.\n",
      "[ 224/1000] train_loss: 0.27537 valid_loss: 0.28285 time per epoch: 78.894 s\n",
      "Validation loss decreased (0.282878 --> 0.282852).  Saving model ...\n",
      "[ 225/1000] train_loss: 0.27494 valid_loss: 0.28239 time per epoch: 78.959 s\n",
      "Validation loss decreased (0.282852 --> 0.282391).  Saving model ...\n",
      "[ 226/1000] train_loss: 0.27476 valid_loss: 0.28216 time per epoch: 79.030 s\n",
      "Validation loss decreased (0.282391 --> 0.282159).  Saving model ...\n",
      "[ 227/1000] train_loss: 0.27454 valid_loss: 0.28218 time per epoch: 79.046 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 228/1000] train_loss: 0.27435 valid_loss: 0.28196 time per epoch: 78.952 s\n",
      "Validation loss decreased (0.282159 --> 0.281959).  Saving model ...\n",
      "[ 229/1000] train_loss: 0.27395 valid_loss: 0.28193 time per epoch: 79.046 s\n",
      "Validation loss decreased (0.281959 --> 0.281929).  Saving model ...\n",
      "[ 230/1000] train_loss: 0.27401 valid_loss: 0.28194 time per epoch: 79.180 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 231/1000] train_loss: 0.27426 valid_loss: 0.28228 time per epoch: 79.099 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 232/1000] train_loss: 0.27388 valid_loss: 0.28176 time per epoch: 79.020 s\n",
      "Validation loss decreased (0.281929 --> 0.281757).  Saving model ...\n",
      "[ 233/1000] train_loss: 0.27409 valid_loss: 0.28225 time per epoch: 79.191 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch 00234: reducing learning rate of group 0 to 4.0960e-05.\n",
      "[ 234/1000] train_loss: 0.27395 valid_loss: 0.28192 time per epoch: 79.225 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 235/1000] train_loss: 0.27353 valid_loss: 0.28172 time per epoch: 79.041 s\n",
      "Validation loss decreased (0.281757 --> 0.281716).  Saving model ...\n",
      "[ 236/1000] train_loss: 0.27317 valid_loss: 0.28210 time per epoch: 79.390 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 237/1000] train_loss: 0.27326 valid_loss: 0.28155 time per epoch: 79.116 s\n",
      "Validation loss decreased (0.281716 --> 0.281547).  Saving model ...\n",
      "[ 238/1000] train_loss: 0.27305 valid_loss: 0.28143 time per epoch: 79.234 s\n",
      "Validation loss decreased (0.281547 --> 0.281428).  Saving model ...\n",
      "[ 239/1000] train_loss: 0.27279 valid_loss: 0.28118 time per epoch: 79.166 s\n",
      "Validation loss decreased (0.281428 --> 0.281176).  Saving model ...\n",
      "[ 240/1000] train_loss: 0.27253 valid_loss: 0.28120 time per epoch: 79.221 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 241/1000] train_loss: 0.27240 valid_loss: 0.28102 time per epoch: 79.323 s\n",
      "Validation loss decreased (0.281176 --> 0.281022).  Saving model ...\n",
      "[ 242/1000] train_loss: 0.27252 valid_loss: 0.28097 time per epoch: 79.682 s\n",
      "Validation loss decreased (0.281022 --> 0.280968).  Saving model ...\n",
      "[ 243/1000] train_loss: 0.27240 valid_loss: 0.28090 time per epoch: 79.224 s\n",
      "Validation loss decreased (0.280968 --> 0.280898).  Saving model ...\n",
      "[ 244/1000] train_loss: 0.27244 valid_loss: 0.28112 time per epoch: 79.061 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch 00245: reducing learning rate of group 0 to 3.2768e-05.\n",
      "[ 245/1000] train_loss: 0.27241 valid_loss: 0.28118 time per epoch: 78.952 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 246/1000] train_loss: 0.27197 valid_loss: 0.28080 time per epoch: 78.975 s\n",
      "Validation loss decreased (0.280898 --> 0.280798).  Saving model ...\n",
      "[ 247/1000] train_loss: 0.27214 valid_loss: 0.28078 time per epoch: 79.104 s\n",
      "Validation loss decreased (0.280798 --> 0.280785).  Saving model ...\n",
      "[ 248/1000] train_loss: 0.27186 valid_loss: 0.28060 time per epoch: 79.477 s\n",
      "Validation loss decreased (0.280785 --> 0.280600).  Saving model ...\n",
      "[ 249/1000] train_loss: 0.27165 valid_loss: 0.28054 time per epoch: 79.296 s\n",
      "Validation loss decreased (0.280600 --> 0.280540).  Saving model ...\n",
      "[ 250/1000] train_loss: 0.27163 valid_loss: 0.28043 time per epoch: 79.337 s\n",
      "Validation loss decreased (0.280540 --> 0.280431).  Saving model ...\n",
      "[ 251/1000] train_loss: 0.27142 valid_loss: 0.28039 time per epoch: 79.383 s\n",
      "Validation loss decreased (0.280431 --> 0.280388).  Saving model ...\n",
      "[ 252/1000] train_loss: 0.27134 valid_loss: 0.28044 time per epoch: 79.492 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 253/1000] train_loss: 0.27138 valid_loss: 0.28038 time per epoch: 79.413 s\n",
      "Validation loss decreased (0.280388 --> 0.280385).  Saving model ...\n",
      "[ 254/1000] train_loss: 0.27134 valid_loss: 0.28024 time per epoch: 79.345 s\n",
      "Validation loss decreased (0.280385 --> 0.280241).  Saving model ...\n",
      "[ 255/1000] train_loss: 0.27091 valid_loss: 0.28021 time per epoch: 79.205 s\n",
      "Validation loss decreased (0.280241 --> 0.280206).  Saving model ...\n",
      "Epoch 00256: reducing learning rate of group 0 to 2.6214e-05.\n",
      "[ 256/1000] train_loss: 0.27093 valid_loss: 0.28022 time per epoch: 79.182 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 257/1000] train_loss: 0.27099 valid_loss: 0.28003 time per epoch: 79.041 s\n",
      "Validation loss decreased (0.280206 --> 0.280033).  Saving model ...\n",
      "[ 258/1000] train_loss: 0.27085 valid_loss: 0.28003 time per epoch: 79.056 s\n",
      "Validation loss decreased (0.280033 --> 0.280029).  Saving model ...\n",
      "[ 259/1000] train_loss: 0.27091 valid_loss: 0.28003 time per epoch: 79.188 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 260/1000] train_loss: 0.27080 valid_loss: 0.27987 time per epoch: 79.191 s\n",
      "Validation loss decreased (0.280029 --> 0.279875).  Saving model ...\n",
      "[ 261/1000] train_loss: 0.27072 valid_loss: 0.27982 time per epoch: 79.056 s\n",
      "Validation loss decreased (0.279875 --> 0.279822).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 262/1000] train_loss: 0.27067 valid_loss: 0.27988 time per epoch: 79.223 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch 00263: reducing learning rate of group 0 to 2.0972e-05.\n",
      "[ 263/1000] train_loss: 0.27031 valid_loss: 0.27976 time per epoch: 79.238 s\n",
      "Validation loss decreased (0.279822 --> 0.279762).  Saving model ...\n",
      "[ 264/1000] train_loss: 0.27019 valid_loss: 0.27974 time per epoch: 79.173 s\n",
      "Validation loss decreased (0.279762 --> 0.279743).  Saving model ...\n",
      "[ 265/1000] train_loss: 0.27024 valid_loss: 0.27968 time per epoch: 79.147 s\n",
      "Validation loss decreased (0.279743 --> 0.279676).  Saving model ...\n",
      "[ 266/1000] train_loss: 0.27010 valid_loss: 0.27964 time per epoch: 79.269 s\n",
      "Validation loss decreased (0.279676 --> 0.279638).  Saving model ...\n",
      "[ 267/1000] train_loss: 0.26994 valid_loss: 0.27964 time per epoch: 79.110 s\n",
      "Validation loss decreased (0.279638 --> 0.279636).  Saving model ...\n",
      "[ 268/1000] train_loss: 0.26998 valid_loss: 0.27953 time per epoch: 79.822 s\n",
      "Validation loss decreased (0.279636 --> 0.279528).  Saving model ...\n",
      "[ 269/1000] train_loss: 0.26997 valid_loss: 0.27953 time per epoch: 79.285 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch 00270: reducing learning rate of group 0 to 1.6777e-05.\n",
      "[ 270/1000] train_loss: 0.26976 valid_loss: 0.27951 time per epoch: 79.465 s\n",
      "Validation loss decreased (0.279528 --> 0.279505).  Saving model ...\n",
      "[ 271/1000] train_loss: 0.26969 valid_loss: 0.27941 time per epoch: 79.349 s\n",
      "Validation loss decreased (0.279505 --> 0.279414).  Saving model ...\n",
      "[ 272/1000] train_loss: 0.26952 valid_loss: 0.27939 time per epoch: 79.269 s\n",
      "Validation loss decreased (0.279414 --> 0.279392).  Saving model ...\n",
      "[ 273/1000] train_loss: 0.26957 valid_loss: 0.27943 time per epoch: 79.457 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 274/1000] train_loss: 0.26945 valid_loss: 0.27940 time per epoch: 79.780 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 275/1000] train_loss: 0.26953 valid_loss: 0.27929 time per epoch: 79.548 s\n",
      "Validation loss decreased (0.279392 --> 0.279291).  Saving model ...\n",
      "[ 276/1000] train_loss: 0.26934 valid_loss: 0.27921 time per epoch: 79.072 s\n",
      "Validation loss decreased (0.279291 --> 0.279210).  Saving model ...\n",
      "Epoch 00277: reducing learning rate of group 0 to 1.3422e-05.\n",
      "[ 277/1000] train_loss: 0.26934 valid_loss: 0.27917 time per epoch: 79.064 s\n",
      "Validation loss decreased (0.279210 --> 0.279167).  Saving model ...\n",
      "[ 278/1000] train_loss: 0.26944 valid_loss: 0.27917 time per epoch: 79.052 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 279/1000] train_loss: 0.26907 valid_loss: 0.27912 time per epoch: 79.190 s\n",
      "Validation loss decreased (0.279167 --> 0.279117).  Saving model ...\n",
      "[ 280/1000] train_loss: 0.26918 valid_loss: 0.27915 time per epoch: 79.306 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 281/1000] train_loss: 0.26920 valid_loss: 0.27908 time per epoch: 78.943 s\n",
      "Validation loss decreased (0.279117 --> 0.279081).  Saving model ...\n",
      "[ 282/1000] train_loss: 0.26926 valid_loss: 0.27909 time per epoch: 79.015 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 283/1000] train_loss: 0.26943 valid_loss: 0.27907 time per epoch: 79.107 s\n",
      "Validation loss decreased (0.279081 --> 0.279070).  Saving model ...\n",
      "[ 284/1000] train_loss: 0.26921 valid_loss: 0.27901 time per epoch: 79.081 s\n",
      "Validation loss decreased (0.279070 --> 0.279008).  Saving model ...\n",
      "Epoch 00285: reducing learning rate of group 0 to 1.0737e-05.\n",
      "[ 285/1000] train_loss: 0.26899 valid_loss: 0.27905 time per epoch: 79.116 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 286/1000] train_loss: 0.26864 valid_loss: 0.27895 time per epoch: 79.380 s\n",
      "Validation loss decreased (0.279008 --> 0.278950).  Saving model ...\n",
      "[ 287/1000] train_loss: 0.26893 valid_loss: 0.27894 time per epoch: 79.113 s\n",
      "Validation loss decreased (0.278950 --> 0.278941).  Saving model ...\n",
      "[ 288/1000] train_loss: 0.26894 valid_loss: 0.27892 time per epoch: 79.538 s\n",
      "Validation loss decreased (0.278941 --> 0.278918).  Saving model ...\n",
      "[ 289/1000] train_loss: 0.26876 valid_loss: 0.27895 time per epoch: 78.952 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 290/1000] train_loss: 0.26876 valid_loss: 0.27890 time per epoch: 78.800 s\n",
      "Validation loss decreased (0.278918 --> 0.278899).  Saving model ...\n",
      "Epoch 00291: reducing learning rate of group 0 to 8.5899e-06.\n",
      "[ 291/1000] train_loss: 0.26872 valid_loss: 0.27886 time per epoch: 78.844 s\n",
      "Validation loss decreased (0.278899 --> 0.278864).  Saving model ...\n",
      "[ 292/1000] train_loss: 0.26876 valid_loss: 0.27879 time per epoch: 79.369 s\n",
      "Validation loss decreased (0.278864 --> 0.278785).  Saving model ...\n",
      "[ 293/1000] train_loss: 0.26875 valid_loss: 0.27876 time per epoch: 79.389 s\n",
      "Validation loss decreased (0.278785 --> 0.278757).  Saving model ...\n",
      "[ 294/1000] train_loss: 0.26855 valid_loss: 0.27876 time per epoch: 79.782 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 295/1000] train_loss: 0.26865 valid_loss: 0.27879 time per epoch: 79.612 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 296/1000] train_loss: 0.26864 valid_loss: 0.27875 time per epoch: 79.595 s\n",
      "Validation loss decreased (0.278757 --> 0.278746).  Saving model ...\n",
      "[ 297/1000] train_loss: 0.26850 valid_loss: 0.27870 time per epoch: 79.724 s\n",
      "Validation loss decreased (0.278746 --> 0.278695).  Saving model ...\n",
      "Epoch 00298: reducing learning rate of group 0 to 6.8719e-06.\n",
      "[ 298/1000] train_loss: 0.26856 valid_loss: 0.27870 time per epoch: 79.036 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 299/1000] train_loss: 0.26855 valid_loss: 0.27864 time per epoch: 78.865 s\n",
      "Validation loss decreased (0.278695 --> 0.278636).  Saving model ...\n",
      "[ 300/1000] train_loss: 0.26838 valid_loss: 0.27863 time per epoch: 79.335 s\n",
      "Validation loss decreased (0.278636 --> 0.278630).  Saving model ...\n",
      "[ 301/1000] train_loss: 0.26854 valid_loss: 0.27860 time per epoch: 79.136 s\n",
      "Validation loss decreased (0.278630 --> 0.278604).  Saving model ...\n",
      "[ 302/1000] train_loss: 0.26824 valid_loss: 0.27861 time per epoch: 78.302 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 303/1000] train_loss: 0.26840 valid_loss: 0.27859 time per epoch: 78.498 s\n",
      "Validation loss decreased (0.278604 --> 0.278591).  Saving model ...\n",
      "Epoch 00304: reducing learning rate of group 0 to 5.4976e-06.\n",
      "[ 304/1000] train_loss: 0.26836 valid_loss: 0.27864 time per epoch: 79.299 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 305/1000] train_loss: 0.26852 valid_loss: 0.27855 time per epoch: 79.228 s\n",
      "Validation loss decreased (0.278591 --> 0.278546).  Saving model ...\n",
      "[ 306/1000] train_loss: 0.26834 valid_loss: 0.27851 time per epoch: 79.005 s\n",
      "Validation loss decreased (0.278546 --> 0.278512).  Saving model ...\n",
      "[ 307/1000] train_loss: 0.26800 valid_loss: 0.27850 time per epoch: 79.122 s\n",
      "Validation loss decreased (0.278512 --> 0.278500).  Saving model ...\n",
      "[ 308/1000] train_loss: 0.26810 valid_loss: 0.27849 time per epoch: 79.291 s\n",
      "Validation loss decreased (0.278500 --> 0.278492).  Saving model ...\n",
      "[ 309/1000] train_loss: 0.26813 valid_loss: 0.27848 time per epoch: 79.042 s\n",
      "Validation loss decreased (0.278492 --> 0.278478).  Saving model ...\n",
      "[ 310/1000] train_loss: 0.26807 valid_loss: 0.27846 time per epoch: 79.336 s\n",
      "Validation loss decreased (0.278478 --> 0.278455).  Saving model ...\n",
      "[ 311/1000] train_loss: 0.26814 valid_loss: 0.27846 time per epoch: 79.175 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 312/1000] train_loss: 0.26796 valid_loss: 0.27842 time per epoch: 78.982 s\n",
      "Validation loss decreased (0.278455 --> 0.278423).  Saving model ...\n",
      "Epoch 00313: reducing learning rate of group 0 to 4.3980e-06.\n",
      "[ 313/1000] train_loss: 0.26780 valid_loss: 0.27842 time per epoch: 78.987 s\n",
      "Validation loss decreased (0.278423 --> 0.278419).  Saving model ...\n",
      "[ 314/1000] train_loss: 0.26795 valid_loss: 0.27841 time per epoch: 78.479 s\n",
      "Validation loss decreased (0.278419 --> 0.278405).  Saving model ...\n",
      "[ 315/1000] train_loss: 0.26815 valid_loss: 0.27840 time per epoch: 78.143 s\n",
      "Validation loss decreased (0.278405 --> 0.278404).  Saving model ...\n",
      "[ 316/1000] train_loss: 0.26784 valid_loss: 0.27839 time per epoch: 78.746 s\n",
      "Validation loss decreased (0.278404 --> 0.278385).  Saving model ...\n",
      "[ 317/1000] train_loss: 0.26814 valid_loss: 0.27840 time per epoch: 78.751 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 318/1000] train_loss: 0.26810 valid_loss: 0.27840 time per epoch: 78.938 s\n",
      "EarlyStopping counter: 2 out of 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00319: reducing learning rate of group 0 to 3.5184e-06.\n",
      "[ 319/1000] train_loss: 0.26799 valid_loss: 0.27836 time per epoch: 79.113 s\n",
      "Validation loss decreased (0.278385 --> 0.278358).  Saving model ...\n",
      "[ 320/1000] train_loss: 0.26789 valid_loss: 0.27834 time per epoch: 79.064 s\n",
      "Validation loss decreased (0.278358 --> 0.278337).  Saving model ...\n",
      "[ 321/1000] train_loss: 0.26757 valid_loss: 0.27831 time per epoch: 79.225 s\n",
      "Validation loss decreased (0.278337 --> 0.278312).  Saving model ...\n",
      "[ 322/1000] train_loss: 0.26793 valid_loss: 0.27837 time per epoch: 78.890 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 323/1000] train_loss: 0.26787 valid_loss: 0.27830 time per epoch: 78.578 s\n",
      "Validation loss decreased (0.278312 --> 0.278303).  Saving model ...\n",
      "[ 324/1000] train_loss: 0.26780 valid_loss: 0.27832 time per epoch: 79.102 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch 00325: reducing learning rate of group 0 to 2.8147e-06.\n",
      "[ 325/1000] train_loss: 0.26803 valid_loss: 0.27830 time per epoch: 78.882 s\n",
      "Validation loss decreased (0.278303 --> 0.278295).  Saving model ...\n",
      "[ 326/1000] train_loss: 0.26789 valid_loss: 0.27826 time per epoch: 78.753 s\n",
      "Validation loss decreased (0.278295 --> 0.278256).  Saving model ...\n",
      "[ 327/1000] train_loss: 0.26767 valid_loss: 0.27826 time per epoch: 78.808 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 328/1000] train_loss: 0.26802 valid_loss: 0.27826 time per epoch: 78.689 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 329/1000] train_loss: 0.26774 valid_loss: 0.27826 time per epoch: 78.602 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 330/1000] train_loss: 0.26776 valid_loss: 0.27823 time per epoch: 78.818 s\n",
      "Validation loss decreased (0.278256 --> 0.278231).  Saving model ...\n",
      "[ 331/1000] train_loss: 0.26789 valid_loss: 0.27822 time per epoch: 78.957 s\n",
      "Validation loss decreased (0.278231 --> 0.278220).  Saving model ...\n",
      "[ 332/1000] train_loss: 0.26783 valid_loss: 0.27823 time per epoch: 78.894 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 333/1000] train_loss: 0.26782 valid_loss: 0.27823 time per epoch: 78.847 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 334/1000] train_loss: 0.26762 valid_loss: 0.27823 time per epoch: 78.989 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 335/1000] train_loss: 0.26785 valid_loss: 0.27819 time per epoch: 79.058 s\n",
      "Validation loss decreased (0.278220 --> 0.278194).  Saving model ...\n",
      "[ 336/1000] train_loss: 0.26772 valid_loss: 0.27819 time per epoch: 78.691 s\n",
      "Validation loss decreased (0.278194 --> 0.278191).  Saving model ...\n",
      "Epoch 00337: reducing learning rate of group 0 to 2.2518e-06.\n",
      "[ 337/1000] train_loss: 0.26759 valid_loss: 0.27817 time per epoch: 78.687 s\n",
      "Validation loss decreased (0.278191 --> 0.278172).  Saving model ...\n",
      "[ 338/1000] train_loss: 0.26766 valid_loss: 0.27818 time per epoch: 78.393 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 339/1000] train_loss: 0.26768 valid_loss: 0.27816 time per epoch: 78.493 s\n",
      "Validation loss decreased (0.278172 --> 0.278156).  Saving model ...\n",
      "[ 340/1000] train_loss: 0.26785 valid_loss: 0.27814 time per epoch: 78.549 s\n",
      "Validation loss decreased (0.278156 --> 0.278144).  Saving model ...\n",
      "[ 341/1000] train_loss: 0.26746 valid_loss: 0.27813 time per epoch: 78.866 s\n",
      "Validation loss decreased (0.278144 --> 0.278134).  Saving model ...\n",
      "[ 342/1000] train_loss: 0.26747 valid_loss: 0.27815 time per epoch: 78.751 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch 00343: reducing learning rate of group 0 to 1.8014e-06.\n",
      "[ 343/1000] train_loss: 0.26744 valid_loss: 0.27813 time per epoch: 78.737 s\n",
      "Validation loss decreased (0.278134 --> 0.278126).  Saving model ...\n",
      "[ 344/1000] train_loss: 0.26763 valid_loss: 0.27812 time per epoch: 79.082 s\n",
      "Validation loss decreased (0.278126 --> 0.278124).  Saving model ...\n",
      "[ 345/1000] train_loss: 0.26760 valid_loss: 0.27812 time per epoch: 78.750 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 346/1000] train_loss: 0.26745 valid_loss: 0.27809 time per epoch: 78.505 s\n",
      "Validation loss decreased (0.278124 --> 0.278092).  Saving model ...\n",
      "[ 347/1000] train_loss: 0.26763 valid_loss: 0.27812 time per epoch: 78.538 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 348/1000] train_loss: 0.26743 valid_loss: 0.27809 time per epoch: 78.546 s\n",
      "Validation loss decreased (0.278092 --> 0.278090).  Saving model ...\n",
      "Epoch 00349: reducing learning rate of group 0 to 1.4412e-06.\n",
      "[ 349/1000] train_loss: 0.26752 valid_loss: 0.27810 time per epoch: 78.721 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 350/1000] train_loss: 0.26743 valid_loss: 0.27808 time per epoch: 79.493 s\n",
      "Validation loss decreased (0.278090 --> 0.278078).  Saving model ...\n",
      "[ 351/1000] train_loss: 0.26769 valid_loss: 0.27806 time per epoch: 79.360 s\n",
      "Validation loss decreased (0.278078 --> 0.278059).  Saving model ...\n",
      "[ 352/1000] train_loss: 0.26765 valid_loss: 0.27807 time per epoch: 79.208 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 353/1000] train_loss: 0.26735 valid_loss: 0.27806 time per epoch: 79.314 s\n",
      "Validation loss decreased (0.278059 --> 0.278058).  Saving model ...\n",
      "[ 354/1000] train_loss: 0.26741 valid_loss: 0.27806 time per epoch: 79.237 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch 00355: reducing learning rate of group 0 to 1.1529e-06.\n",
      "[ 355/1000] train_loss: 0.26732 valid_loss: 0.27805 time per epoch: 79.142 s\n",
      "Validation loss decreased (0.278058 --> 0.278054).  Saving model ...\n",
      "[ 356/1000] train_loss: 0.26758 valid_loss: 0.27807 time per epoch: 79.046 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 357/1000] train_loss: 0.26750 valid_loss: 0.27805 time per epoch: 79.353 s\n",
      "Validation loss decreased (0.278054 --> 0.278051).  Saving model ...\n",
      "[ 358/1000] train_loss: 0.26727 valid_loss: 0.27805 time per epoch: 79.392 s\n",
      "Validation loss decreased (0.278051 --> 0.278046).  Saving model ...\n",
      "[ 359/1000] train_loss: 0.26760 valid_loss: 0.27804 time per epoch: 79.244 s\n",
      "Validation loss decreased (0.278046 --> 0.278035).  Saving model ...\n",
      "[ 360/1000] train_loss: 0.26737 valid_loss: 0.27804 time per epoch: 79.269 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch 00361: reducing learning rate of group 0 to 1.0000e-06.\n",
      "[ 361/1000] train_loss: 0.26756 valid_loss: 0.27803 time per epoch: 79.374 s\n",
      "Validation loss decreased (0.278035 --> 0.278028).  Saving model ...\n",
      "[ 362/1000] train_loss: 0.26773 valid_loss: 0.27801 time per epoch: 79.274 s\n",
      "Validation loss decreased (0.278028 --> 0.278014).  Saving model ...\n",
      "[ 363/1000] train_loss: 0.26738 valid_loss: 0.27801 time per epoch: 79.401 s\n",
      "Validation loss decreased (0.278014 --> 0.278013).  Saving model ...\n",
      "[ 364/1000] train_loss: 0.26754 valid_loss: 0.27803 time per epoch: 79.471 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 365/1000] train_loss: 0.26754 valid_loss: 0.27802 time per epoch: 79.542 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 366/1000] train_loss: 0.26747 valid_loss: 0.27802 time per epoch: 79.141 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 367/1000] train_loss: 0.26748 valid_loss: 0.27801 time per epoch: 78.925 s\n",
      "Validation loss decreased (0.278013 --> 0.278006).  Saving model ...\n",
      "[ 368/1000] train_loss: 0.26751 valid_loss: 0.27800 time per epoch: 78.874 s\n",
      "Validation loss decreased (0.278006 --> 0.278000).  Saving model ...\n",
      "[ 369/1000] train_loss: 0.26731 valid_loss: 0.27802 time per epoch: 79.065 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 370/1000] train_loss: 0.26720 valid_loss: 0.27799 time per epoch: 79.141 s\n",
      "Validation loss decreased (0.278000 --> 0.277994).  Saving model ...\n",
      "[ 371/1000] train_loss: 0.26743 valid_loss: 0.27799 time per epoch: 79.199 s\n",
      "Validation loss decreased (0.277994 --> 0.277989).  Saving model ...\n",
      "[ 372/1000] train_loss: 0.26740 valid_loss: 0.27799 time per epoch: 78.865 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 373/1000] train_loss: 0.26748 valid_loss: 0.27798 time per epoch: 79.088 s\n",
      "Validation loss decreased (0.277989 --> 0.277985).  Saving model ...\n",
      "[ 374/1000] train_loss: 0.26729 valid_loss: 0.27799 time per epoch: 79.084 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 375/1000] train_loss: 0.26752 valid_loss: 0.27798 time per epoch: 78.824 s\n",
      "Validation loss decreased (0.277985 --> 0.277978).  Saving model ...\n",
      "[ 376/1000] train_loss: 0.26765 valid_loss: 0.27797 time per epoch: 78.936 s\n",
      "Validation loss decreased (0.277978 --> 0.277972).  Saving model ...\n",
      "[ 377/1000] train_loss: 0.26730 valid_loss: 0.27798 time per epoch: 78.544 s\n",
      "EarlyStopping counter: 1 out of 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 378/1000] train_loss: 0.26728 valid_loss: 0.27797 time per epoch: 78.463 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 379/1000] train_loss: 0.26722 valid_loss: 0.27796 time per epoch: 78.482 s\n",
      "Validation loss decreased (0.277972 --> 0.277963).  Saving model ...\n",
      "[ 380/1000] train_loss: 0.26754 valid_loss: 0.27795 time per epoch: 78.834 s\n",
      "Validation loss decreased (0.277963 --> 0.277949).  Saving model ...\n",
      "[ 381/1000] train_loss: 0.26713 valid_loss: 0.27795 time per epoch: 78.771 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 382/1000] train_loss: 0.26726 valid_loss: 0.27795 time per epoch: 78.875 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 383/1000] train_loss: 0.26716 valid_loss: 0.27796 time per epoch: 78.884 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 384/1000] train_loss: 0.26738 valid_loss: 0.27795 time per epoch: 78.900 s\n",
      "Validation loss decreased (0.277949 --> 0.277949).  Saving model ...\n",
      "[ 385/1000] train_loss: 0.26731 valid_loss: 0.27794 time per epoch: 78.478 s\n",
      "Validation loss decreased (0.277949 --> 0.277943).  Saving model ...\n",
      "[ 386/1000] train_loss: 0.26737 valid_loss: 0.27796 time per epoch: 78.979 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 387/1000] train_loss: 0.26744 valid_loss: 0.27794 time per epoch: 79.020 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 388/1000] train_loss: 0.26718 valid_loss: 0.27792 time per epoch: 78.877 s\n",
      "Validation loss decreased (0.277943 --> 0.277922).  Saving model ...\n",
      "[ 389/1000] train_loss: 0.26742 valid_loss: 0.27792 time per epoch: 78.904 s\n",
      "Validation loss decreased (0.277922 --> 0.277922).  Saving model ...\n",
      "[ 390/1000] train_loss: 0.26723 valid_loss: 0.27793 time per epoch: 79.126 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 391/1000] train_loss: 0.26720 valid_loss: 0.27792 time per epoch: 79.055 s\n",
      "Validation loss decreased (0.277922 --> 0.277922).  Saving model ...\n",
      "[ 392/1000] train_loss: 0.26728 valid_loss: 0.27791 time per epoch: 79.127 s\n",
      "Validation loss decreased (0.277922 --> 0.277910).  Saving model ...\n",
      "[ 393/1000] train_loss: 0.26716 valid_loss: 0.27791 time per epoch: 78.950 s\n",
      "Validation loss decreased (0.277910 --> 0.277910).  Saving model ...\n",
      "[ 394/1000] train_loss: 0.26745 valid_loss: 0.27790 time per epoch: 78.760 s\n",
      "Validation loss decreased (0.277910 --> 0.277903).  Saving model ...\n",
      "[ 395/1000] train_loss: 0.26742 valid_loss: 0.27791 time per epoch: 78.728 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 396/1000] train_loss: 0.26739 valid_loss: 0.27790 time per epoch: 78.809 s\n",
      "Validation loss decreased (0.277903 --> 0.277898).  Saving model ...\n",
      "[ 397/1000] train_loss: 0.26763 valid_loss: 0.27788 time per epoch: 79.001 s\n",
      "Validation loss decreased (0.277898 --> 0.277881).  Saving model ...\n",
      "[ 398/1000] train_loss: 0.26751 valid_loss: 0.27790 time per epoch: 78.997 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 399/1000] train_loss: 0.26718 valid_loss: 0.27790 time per epoch: 79.237 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 400/1000] train_loss: 0.26710 valid_loss: 0.27788 time per epoch: 79.766 s\n",
      "Validation loss decreased (0.277881 --> 0.277880).  Saving model ...\n",
      "[ 401/1000] train_loss: 0.26730 valid_loss: 0.27787 time per epoch: 78.862 s\n",
      "Validation loss decreased (0.277880 --> 0.277873).  Saving model ...\n",
      "[ 402/1000] train_loss: 0.26711 valid_loss: 0.27787 time per epoch: 79.174 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 403/1000] train_loss: 0.26718 valid_loss: 0.27787 time per epoch: 79.202 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 404/1000] train_loss: 0.26714 valid_loss: 0.27787 time per epoch: 78.986 s\n",
      "Validation loss decreased (0.277873 --> 0.277866).  Saving model ...\n",
      "[ 405/1000] train_loss: 0.26721 valid_loss: 0.27787 time per epoch: 78.865 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 406/1000] train_loss: 0.26709 valid_loss: 0.27787 time per epoch: 78.886 s\n",
      "Validation loss decreased (0.277866 --> 0.277866).  Saving model ...\n",
      "[ 407/1000] train_loss: 0.26735 valid_loss: 0.27785 time per epoch: 79.019 s\n",
      "Validation loss decreased (0.277866 --> 0.277854).  Saving model ...\n",
      "[ 408/1000] train_loss: 0.26720 valid_loss: 0.27785 time per epoch: 78.924 s\n",
      "Validation loss decreased (0.277854 --> 0.277850).  Saving model ...\n",
      "[ 409/1000] train_loss: 0.26726 valid_loss: 0.27787 time per epoch: 78.765 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 410/1000] train_loss: 0.26731 valid_loss: 0.27787 time per epoch: 78.592 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 411/1000] train_loss: 0.26710 valid_loss: 0.27784 time per epoch: 78.812 s\n",
      "Validation loss decreased (0.277850 --> 0.277836).  Saving model ...\n",
      "[ 412/1000] train_loss: 0.26713 valid_loss: 0.27783 time per epoch: 79.381 s\n",
      "Validation loss decreased (0.277836 --> 0.277832).  Saving model ...\n",
      "[ 413/1000] train_loss: 0.26714 valid_loss: 0.27784 time per epoch: 79.519 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 414/1000] train_loss: 0.26739 valid_loss: 0.27782 time per epoch: 79.632 s\n",
      "Validation loss decreased (0.277832 --> 0.277824).  Saving model ...\n",
      "[ 415/1000] train_loss: 0.26710 valid_loss: 0.27783 time per epoch: 79.166 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 416/1000] train_loss: 0.26752 valid_loss: 0.27784 time per epoch: 79.106 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 417/1000] train_loss: 0.26751 valid_loss: 0.27785 time per epoch: 79.281 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 418/1000] train_loss: 0.26695 valid_loss: 0.27782 time per epoch: 79.080 s\n",
      "Validation loss decreased (0.277824 --> 0.277815).  Saving model ...\n",
      "[ 419/1000] train_loss: 0.26697 valid_loss: 0.27780 time per epoch: 79.305 s\n",
      "Validation loss decreased (0.277815 --> 0.277795).  Saving model ...\n",
      "[ 420/1000] train_loss: 0.26722 valid_loss: 0.27781 time per epoch: 79.324 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 421/1000] train_loss: 0.26721 valid_loss: 0.27780 time per epoch: 79.584 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 422/1000] train_loss: 0.26694 valid_loss: 0.27778 time per epoch: 79.052 s\n",
      "Validation loss decreased (0.277795 --> 0.277782).  Saving model ...\n",
      "[ 423/1000] train_loss: 0.26697 valid_loss: 0.27781 time per epoch: 78.841 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 424/1000] train_loss: 0.26697 valid_loss: 0.27780 time per epoch: 78.921 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 425/1000] train_loss: 0.26698 valid_loss: 0.27780 time per epoch: 79.317 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 426/1000] train_loss: 0.26717 valid_loss: 0.27779 time per epoch: 79.586 s\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[ 427/1000] train_loss: 0.26709 valid_loss: 0.27777 time per epoch: 79.174 s\n",
      "Validation loss decreased (0.277782 --> 0.277771).  Saving model ...\n",
      "[ 428/1000] train_loss: 0.26734 valid_loss: 0.27779 time per epoch: 78.962 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 429/1000] train_loss: 0.26714 valid_loss: 0.27776 time per epoch: 79.257 s\n",
      "Validation loss decreased (0.277771 --> 0.277761).  Saving model ...\n",
      "[ 430/1000] train_loss: 0.26727 valid_loss: 0.27777 time per epoch: 79.340 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 431/1000] train_loss: 0.26741 valid_loss: 0.27776 time per epoch: 79.442 s\n",
      "Validation loss decreased (0.277761 --> 0.277760).  Saving model ...\n",
      "[ 432/1000] train_loss: 0.26713 valid_loss: 0.27775 time per epoch: 79.344 s\n",
      "Validation loss decreased (0.277760 --> 0.277754).  Saving model ...\n",
      "[ 433/1000] train_loss: 0.26695 valid_loss: 0.27776 time per epoch: 79.101 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 434/1000] train_loss: 0.26711 valid_loss: 0.27778 time per epoch: 78.825 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 435/1000] train_loss: 0.26724 valid_loss: 0.27776 time per epoch: 78.222 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 436/1000] train_loss: 0.26708 valid_loss: 0.27776 time per epoch: 78.411 s\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[ 437/1000] train_loss: 0.26710 valid_loss: 0.27774 time per epoch: 78.451 s\n",
      "Validation loss decreased (0.277754 --> 0.277742).  Saving model ...\n",
      "[ 438/1000] train_loss: 0.26697 valid_loss: 0.27774 time per epoch: 78.342 s\n",
      "Validation loss decreased (0.277742 --> 0.277735).  Saving model ...\n",
      "[ 439/1000] train_loss: 0.26691 valid_loss: 0.27775 time per epoch: 78.599 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 440/1000] train_loss: 0.26704 valid_loss: 0.27774 time per epoch: 79.301 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 441/1000] train_loss: 0.26730 valid_loss: 0.27774 time per epoch: 79.049 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 442/1000] train_loss: 0.26693 valid_loss: 0.27773 time per epoch: 79.115 s\n",
      "Validation loss decreased (0.277735 --> 0.277727).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 443/1000] train_loss: 0.26699 valid_loss: 0.27772 time per epoch: 79.107 s\n",
      "Validation loss decreased (0.277727 --> 0.277717).  Saving model ...\n",
      "[ 444/1000] train_loss: 0.26706 valid_loss: 0.27771 time per epoch: 79.126 s\n",
      "Validation loss decreased (0.277717 --> 0.277707).  Saving model ...\n",
      "[ 445/1000] train_loss: 0.26683 valid_loss: 0.27770 time per epoch: 78.861 s\n",
      "Validation loss decreased (0.277707 --> 0.277703).  Saving model ...\n",
      "[ 446/1000] train_loss: 0.26712 valid_loss: 0.27771 time per epoch: 78.772 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 447/1000] train_loss: 0.26706 valid_loss: 0.27770 time per epoch: 79.029 s\n",
      "Validation loss decreased (0.277703 --> 0.277698).  Saving model ...\n",
      "[ 448/1000] train_loss: 0.26711 valid_loss: 0.27770 time per epoch: 79.044 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 449/1000] train_loss: 0.26703 valid_loss: 0.27770 time per epoch: 79.104 s\n",
      "Validation loss decreased (0.277698 --> 0.277696).  Saving model ...\n",
      "[ 450/1000] train_loss: 0.26672 valid_loss: 0.27769 time per epoch: 78.824 s\n",
      "Validation loss decreased (0.277696 --> 0.277690).  Saving model ...\n",
      "[ 451/1000] train_loss: 0.26684 valid_loss: 0.27770 time per epoch: 78.814 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 452/1000] train_loss: 0.26691 valid_loss: 0.27769 time per epoch: 78.973 s\n",
      "Validation loss decreased (0.277690 --> 0.277686).  Saving model ...\n",
      "[ 453/1000] train_loss: 0.26698 valid_loss: 0.27767 time per epoch: 78.991 s\n",
      "Validation loss decreased (0.277686 --> 0.277665).  Saving model ...\n",
      "[ 454/1000] train_loss: 0.26687 valid_loss: 0.27767 time per epoch: 79.000 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 455/1000] train_loss: 0.26666 valid_loss: 0.27767 time per epoch: 78.896 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 456/1000] train_loss: 0.26700 valid_loss: 0.27768 time per epoch: 78.988 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 457/1000] train_loss: 0.26683 valid_loss: 0.27765 time per epoch: 79.103 s\n",
      "Validation loss decreased (0.277665 --> 0.277651).  Saving model ...\n",
      "[ 458/1000] train_loss: 0.26676 valid_loss: 0.27765 time per epoch: 79.329 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 459/1000] train_loss: 0.26712 valid_loss: 0.27767 time per epoch: 79.258 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 460/1000] train_loss: 0.26681 valid_loss: 0.27765 time per epoch: 78.995 s\n",
      "Validation loss decreased (0.277651 --> 0.277646).  Saving model ...\n",
      "[ 461/1000] train_loss: 0.26663 valid_loss: 0.27765 time per epoch: 79.521 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 462/1000] train_loss: 0.26689 valid_loss: 0.27764 time per epoch: 79.300 s\n",
      "Validation loss decreased (0.277646 --> 0.277636).  Saving model ...\n",
      "[ 463/1000] train_loss: 0.26697 valid_loss: 0.27764 time per epoch: 79.201 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 464/1000] train_loss: 0.26686 valid_loss: 0.27763 time per epoch: 79.123 s\n",
      "Validation loss decreased (0.277636 --> 0.277627).  Saving model ...\n",
      "[ 465/1000] train_loss: 0.26705 valid_loss: 0.27763 time per epoch: 79.188 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 466/1000] train_loss: 0.26697 valid_loss: 0.27762 time per epoch: 79.371 s\n",
      "Validation loss decreased (0.277627 --> 0.277617).  Saving model ...\n",
      "[ 467/1000] train_loss: 0.26691 valid_loss: 0.27762 time per epoch: 79.448 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 468/1000] train_loss: 0.26681 valid_loss: 0.27763 time per epoch: 79.478 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 469/1000] train_loss: 0.26680 valid_loss: 0.27761 time per epoch: 79.497 s\n",
      "Validation loss decreased (0.277617 --> 0.277613).  Saving model ...\n",
      "[ 470/1000] train_loss: 0.26692 valid_loss: 0.27759 time per epoch: 79.398 s\n",
      "Validation loss decreased (0.277613 --> 0.277593).  Saving model ...\n",
      "[ 471/1000] train_loss: 0.26684 valid_loss: 0.27760 time per epoch: 79.543 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 472/1000] train_loss: 0.26681 valid_loss: 0.27760 time per epoch: 79.387 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 473/1000] train_loss: 0.26680 valid_loss: 0.27760 time per epoch: 79.356 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 474/1000] train_loss: 0.26690 valid_loss: 0.27758 time per epoch: 79.705 s\n",
      "Validation loss decreased (0.277593 --> 0.277575).  Saving model ...\n",
      "[ 475/1000] train_loss: 0.26687 valid_loss: 0.27758 time per epoch: 79.628 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 476/1000] train_loss: 0.26656 valid_loss: 0.27757 time per epoch: 79.769 s\n",
      "Validation loss decreased (0.277575 --> 0.277566).  Saving model ...\n",
      "[ 477/1000] train_loss: 0.26676 valid_loss: 0.27761 time per epoch: 79.605 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 478/1000] train_loss: 0.26665 valid_loss: 0.27758 time per epoch: 79.650 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 479/1000] train_loss: 0.26700 valid_loss: 0.27760 time per epoch: 79.640 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 480/1000] train_loss: 0.26680 valid_loss: 0.27758 time per epoch: 79.604 s\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[ 481/1000] train_loss: 0.26669 valid_loss: 0.27755 time per epoch: 79.546 s\n",
      "Validation loss decreased (0.277566 --> 0.277553).  Saving model ...\n",
      "[ 482/1000] train_loss: 0.26678 valid_loss: 0.27757 time per epoch: 79.689 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 483/1000] train_loss: 0.26663 valid_loss: 0.27756 time per epoch: 79.676 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 484/1000] train_loss: 0.26701 valid_loss: 0.27755 time per epoch: 79.700 s\n",
      "Validation loss decreased (0.277553 --> 0.277546).  Saving model ...\n",
      "[ 485/1000] train_loss: 0.26687 valid_loss: 0.27753 time per epoch: 79.716 s\n",
      "Validation loss decreased (0.277546 --> 0.277533).  Saving model ...\n",
      "[ 486/1000] train_loss: 0.26682 valid_loss: 0.27754 time per epoch: 79.664 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 487/1000] train_loss: 0.26673 valid_loss: 0.27754 time per epoch: 79.418 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 488/1000] train_loss: 0.26655 valid_loss: 0.27753 time per epoch: 79.621 s\n",
      "Validation loss decreased (0.277533 --> 0.277526).  Saving model ...\n",
      "[ 489/1000] train_loss: 0.26658 valid_loss: 0.27753 time per epoch: 79.735 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 490/1000] train_loss: 0.26666 valid_loss: 0.27753 time per epoch: 79.667 s\n",
      "Validation loss decreased (0.277526 --> 0.277525).  Saving model ...\n",
      "[ 491/1000] train_loss: 0.26653 valid_loss: 0.27752 time per epoch: 79.561 s\n",
      "Validation loss decreased (0.277525 --> 0.277519).  Saving model ...\n",
      "[ 492/1000] train_loss: 0.26661 valid_loss: 0.27752 time per epoch: 79.564 s\n",
      "Validation loss decreased (0.277519 --> 0.277517).  Saving model ...\n",
      "[ 493/1000] train_loss: 0.26666 valid_loss: 0.27752 time per epoch: 79.192 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 494/1000] train_loss: 0.26667 valid_loss: 0.27751 time per epoch: 78.946 s\n",
      "Validation loss decreased (0.277517 --> 0.277514).  Saving model ...\n",
      "[ 495/1000] train_loss: 0.26671 valid_loss: 0.27752 time per epoch: 79.155 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 496/1000] train_loss: 0.26657 valid_loss: 0.27750 time per epoch: 78.890 s\n",
      "Validation loss decreased (0.277514 --> 0.277496).  Saving model ...\n",
      "[ 497/1000] train_loss: 0.26672 valid_loss: 0.27749 time per epoch: 78.969 s\n",
      "Validation loss decreased (0.277496 --> 0.277494).  Saving model ...\n",
      "[ 498/1000] train_loss: 0.26657 valid_loss: 0.27749 time per epoch: 79.007 s\n",
      "Validation loss decreased (0.277494 --> 0.277489).  Saving model ...\n",
      "[ 499/1000] train_loss: 0.26674 valid_loss: 0.27749 time per epoch: 79.266 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 500/1000] train_loss: 0.26654 valid_loss: 0.27748 time per epoch: 79.289 s\n",
      "Validation loss decreased (0.277489 --> 0.277484).  Saving model ...\n",
      "[ 501/1000] train_loss: 0.26684 valid_loss: 0.27747 time per epoch: 79.230 s\n",
      "Validation loss decreased (0.277484 --> 0.277465).  Saving model ...\n",
      "[ 502/1000] train_loss: 0.26683 valid_loss: 0.27748 time per epoch: 78.796 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 503/1000] train_loss: 0.26660 valid_loss: 0.27749 time per epoch: 79.103 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 504/1000] train_loss: 0.26652 valid_loss: 0.27747 time per epoch: 78.809 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 505/1000] train_loss: 0.26648 valid_loss: 0.27746 time per epoch: 79.052 s\n",
      "Validation loss decreased (0.277465 --> 0.277459).  Saving model ...\n",
      "[ 506/1000] train_loss: 0.26661 valid_loss: 0.27745 time per epoch: 78.937 s\n",
      "Validation loss decreased (0.277459 --> 0.277454).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 507/1000] train_loss: 0.26659 valid_loss: 0.27746 time per epoch: 78.951 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 508/1000] train_loss: 0.26685 valid_loss: 0.27747 time per epoch: 78.996 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 509/1000] train_loss: 0.26648 valid_loss: 0.27745 time per epoch: 79.176 s\n",
      "Validation loss decreased (0.277454 --> 0.277445).  Saving model ...\n",
      "[ 510/1000] train_loss: 0.26664 valid_loss: 0.27745 time per epoch: 79.108 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 511/1000] train_loss: 0.26655 valid_loss: 0.27743 time per epoch: 79.327 s\n",
      "Validation loss decreased (0.277445 --> 0.277433).  Saving model ...\n",
      "[ 512/1000] train_loss: 0.26658 valid_loss: 0.27742 time per epoch: 79.433 s\n",
      "Validation loss decreased (0.277433 --> 0.277424).  Saving model ...\n",
      "[ 513/1000] train_loss: 0.26656 valid_loss: 0.27744 time per epoch: 79.306 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 514/1000] train_loss: 0.26671 valid_loss: 0.27743 time per epoch: 79.260 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 515/1000] train_loss: 0.26653 valid_loss: 0.27742 time per epoch: 79.279 s\n",
      "Validation loss decreased (0.277424 --> 0.277419).  Saving model ...\n",
      "[ 516/1000] train_loss: 0.26665 valid_loss: 0.27743 time per epoch: 79.281 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 517/1000] train_loss: 0.26644 valid_loss: 0.27742 time per epoch: 79.242 s\n",
      "Validation loss decreased (0.277419 --> 0.277415).  Saving model ...\n",
      "[ 518/1000] train_loss: 0.26681 valid_loss: 0.27742 time per epoch: 79.071 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 519/1000] train_loss: 0.26652 valid_loss: 0.27742 time per epoch: 79.030 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 520/1000] train_loss: 0.26647 valid_loss: 0.27741 time per epoch: 79.045 s\n",
      "Validation loss decreased (0.277415 --> 0.277410).  Saving model ...\n",
      "[ 521/1000] train_loss: 0.26655 valid_loss: 0.27741 time per epoch: 79.221 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 522/1000] train_loss: 0.26654 valid_loss: 0.27740 time per epoch: 79.107 s\n",
      "Validation loss decreased (0.277410 --> 0.277403).  Saving model ...\n",
      "[ 523/1000] train_loss: 0.26655 valid_loss: 0.27737 time per epoch: 79.049 s\n",
      "Validation loss decreased (0.277403 --> 0.277371).  Saving model ...\n",
      "[ 524/1000] train_loss: 0.26645 valid_loss: 0.27739 time per epoch: 79.207 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 525/1000] train_loss: 0.26674 valid_loss: 0.27737 time per epoch: 79.111 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 526/1000] train_loss: 0.26635 valid_loss: 0.27739 time per epoch: 79.119 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 527/1000] train_loss: 0.26653 valid_loss: 0.27739 time per epoch: 79.193 s\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[ 528/1000] train_loss: 0.26657 valid_loss: 0.27736 time per epoch: 79.104 s\n",
      "Validation loss decreased (0.277371 --> 0.277365).  Saving model ...\n",
      "[ 529/1000] train_loss: 0.26688 valid_loss: 0.27739 time per epoch: 79.070 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 530/1000] train_loss: 0.26662 valid_loss: 0.27737 time per epoch: 78.906 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 531/1000] train_loss: 0.26644 valid_loss: 0.27735 time per epoch: 78.956 s\n",
      "Validation loss decreased (0.277365 --> 0.277351).  Saving model ...\n",
      "[ 532/1000] train_loss: 0.26649 valid_loss: 0.27736 time per epoch: 79.131 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 533/1000] train_loss: 0.26645 valid_loss: 0.27736 time per epoch: 79.094 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 534/1000] train_loss: 0.26640 valid_loss: 0.27734 time per epoch: 78.842 s\n",
      "Validation loss decreased (0.277351 --> 0.277345).  Saving model ...\n",
      "[ 535/1000] train_loss: 0.26642 valid_loss: 0.27735 time per epoch: 78.863 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 536/1000] train_loss: 0.26630 valid_loss: 0.27734 time per epoch: 79.043 s\n",
      "Validation loss decreased (0.277345 --> 0.277338).  Saving model ...\n",
      "[ 537/1000] train_loss: 0.26644 valid_loss: 0.27734 time per epoch: 79.349 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 538/1000] train_loss: 0.26655 valid_loss: 0.27735 time per epoch: 79.197 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 539/1000] train_loss: 0.26654 valid_loss: 0.27732 time per epoch: 78.947 s\n",
      "Validation loss decreased (0.277338 --> 0.277315).  Saving model ...\n",
      "[ 540/1000] train_loss: 0.26630 valid_loss: 0.27731 time per epoch: 78.881 s\n",
      "Validation loss decreased (0.277315 --> 0.277312).  Saving model ...\n",
      "[ 541/1000] train_loss: 0.26652 valid_loss: 0.27733 time per epoch: 78.990 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 542/1000] train_loss: 0.26631 valid_loss: 0.27732 time per epoch: 79.097 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 543/1000] train_loss: 0.26631 valid_loss: 0.27731 time per epoch: 79.065 s\n",
      "Validation loss decreased (0.277312 --> 0.277311).  Saving model ...\n",
      "[ 544/1000] train_loss: 0.26621 valid_loss: 0.27730 time per epoch: 79.107 s\n",
      "Validation loss decreased (0.277311 --> 0.277301).  Saving model ...\n",
      "[ 545/1000] train_loss: 0.26619 valid_loss: 0.27730 time per epoch: 78.995 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 546/1000] train_loss: 0.26628 valid_loss: 0.27728 time per epoch: 79.218 s\n",
      "Validation loss decreased (0.277301 --> 0.277285).  Saving model ...\n",
      "[ 547/1000] train_loss: 0.26654 valid_loss: 0.27730 time per epoch: 79.001 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 548/1000] train_loss: 0.26619 valid_loss: 0.27728 time per epoch: 79.109 s\n",
      "Validation loss decreased (0.277285 --> 0.277277).  Saving model ...\n",
      "[ 549/1000] train_loss: 0.26636 valid_loss: 0.27728 time per epoch: 79.039 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 550/1000] train_loss: 0.26640 valid_loss: 0.27729 time per epoch: 79.045 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 551/1000] train_loss: 0.26624 valid_loss: 0.27728 time per epoch: 78.924 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 552/1000] train_loss: 0.26612 valid_loss: 0.27726 time per epoch: 79.438 s\n",
      "Validation loss decreased (0.277277 --> 0.277263).  Saving model ...\n",
      "[ 553/1000] train_loss: 0.26652 valid_loss: 0.27727 time per epoch: 79.005 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 554/1000] train_loss: 0.26645 valid_loss: 0.27727 time per epoch: 79.217 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 555/1000] train_loss: 0.26648 valid_loss: 0.27726 time per epoch: 79.267 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 556/1000] train_loss: 0.26649 valid_loss: 0.27727 time per epoch: 79.266 s\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[ 557/1000] train_loss: 0.26629 valid_loss: 0.27724 time per epoch: 79.252 s\n",
      "Validation loss decreased (0.277263 --> 0.277241).  Saving model ...\n",
      "[ 558/1000] train_loss: 0.26662 valid_loss: 0.27725 time per epoch: 78.593 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 559/1000] train_loss: 0.26637 valid_loss: 0.27725 time per epoch: 79.009 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 560/1000] train_loss: 0.26639 valid_loss: 0.27725 time per epoch: 79.312 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 561/1000] train_loss: 0.26641 valid_loss: 0.27722 time per epoch: 79.306 s\n",
      "Validation loss decreased (0.277241 --> 0.277224).  Saving model ...\n",
      "[ 562/1000] train_loss: 0.26618 valid_loss: 0.27724 time per epoch: 79.415 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 563/1000] train_loss: 0.26649 valid_loss: 0.27723 time per epoch: 79.329 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 564/1000] train_loss: 0.26615 valid_loss: 0.27724 time per epoch: 79.579 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 565/1000] train_loss: 0.26625 valid_loss: 0.27722 time per epoch: 79.110 s\n",
      "Validation loss decreased (0.277224 --> 0.277220).  Saving model ...\n",
      "[ 566/1000] train_loss: 0.26624 valid_loss: 0.27723 time per epoch: 79.172 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 567/1000] train_loss: 0.26635 valid_loss: 0.27721 time per epoch: 79.056 s\n",
      "Validation loss decreased (0.277220 --> 0.277215).  Saving model ...\n",
      "[ 568/1000] train_loss: 0.26625 valid_loss: 0.27723 time per epoch: 79.147 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 569/1000] train_loss: 0.26620 valid_loss: 0.27720 time per epoch: 79.023 s\n",
      "Validation loss decreased (0.277215 --> 0.277203).  Saving model ...\n",
      "[ 570/1000] train_loss: 0.26618 valid_loss: 0.27719 time per epoch: 79.725 s\n",
      "Validation loss decreased (0.277203 --> 0.277185).  Saving model ...\n",
      "[ 571/1000] train_loss: 0.26625 valid_loss: 0.27721 time per epoch: 79.084 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 572/1000] train_loss: 0.26632 valid_loss: 0.27720 time per epoch: 79.237 s\n",
      "EarlyStopping counter: 2 out of 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 573/1000] train_loss: 0.26614 valid_loss: 0.27718 time per epoch: 79.216 s\n",
      "Validation loss decreased (0.277185 --> 0.277184).  Saving model ...\n",
      "[ 574/1000] train_loss: 0.26644 valid_loss: 0.27719 time per epoch: 79.364 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 575/1000] train_loss: 0.26630 valid_loss: 0.27718 time per epoch: 79.336 s\n",
      "Validation loss decreased (0.277184 --> 0.277178).  Saving model ...\n",
      "[ 576/1000] train_loss: 0.26615 valid_loss: 0.27717 time per epoch: 79.252 s\n",
      "Validation loss decreased (0.277178 --> 0.277166).  Saving model ...\n",
      "[ 577/1000] train_loss: 0.26612 valid_loss: 0.27716 time per epoch: 79.276 s\n",
      "Validation loss decreased (0.277166 --> 0.277155).  Saving model ...\n",
      "[ 578/1000] train_loss: 0.26610 valid_loss: 0.27716 time per epoch: 78.838 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 579/1000] train_loss: 0.26610 valid_loss: 0.27716 time per epoch: 78.813 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 580/1000] train_loss: 0.26628 valid_loss: 0.27715 time per epoch: 78.869 s\n",
      "Validation loss decreased (0.277155 --> 0.277153).  Saving model ...\n",
      "[ 581/1000] train_loss: 0.26614 valid_loss: 0.27713 time per epoch: 78.697 s\n",
      "Validation loss decreased (0.277153 --> 0.277131).  Saving model ...\n",
      "[ 582/1000] train_loss: 0.26620 valid_loss: 0.27714 time per epoch: 79.033 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 583/1000] train_loss: 0.26617 valid_loss: 0.27713 time per epoch: 79.025 s\n",
      "Validation loss decreased (0.277131 --> 0.277128).  Saving model ...\n",
      "[ 584/1000] train_loss: 0.26604 valid_loss: 0.27714 time per epoch: 79.145 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 585/1000] train_loss: 0.26622 valid_loss: 0.27712 time per epoch: 79.047 s\n",
      "Validation loss decreased (0.277128 --> 0.277120).  Saving model ...\n",
      "[ 586/1000] train_loss: 0.26614 valid_loss: 0.27712 time per epoch: 79.089 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 587/1000] train_loss: 0.26623 valid_loss: 0.27713 time per epoch: 79.163 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 588/1000] train_loss: 0.26615 valid_loss: 0.27711 time per epoch: 79.485 s\n",
      "Validation loss decreased (0.277120 --> 0.277113).  Saving model ...\n",
      "[ 589/1000] train_loss: 0.26611 valid_loss: 0.27713 time per epoch: 79.312 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 590/1000] train_loss: 0.26607 valid_loss: 0.27711 time per epoch: 79.297 s\n",
      "Validation loss decreased (0.277113 --> 0.277106).  Saving model ...\n",
      "[ 591/1000] train_loss: 0.26592 valid_loss: 0.27709 time per epoch: 79.040 s\n",
      "Validation loss decreased (0.277106 --> 0.277093).  Saving model ...\n",
      "[ 592/1000] train_loss: 0.26595 valid_loss: 0.27710 time per epoch: 78.942 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 593/1000] train_loss: 0.26583 valid_loss: 0.27708 time per epoch: 78.611 s\n",
      "Validation loss decreased (0.277093 --> 0.277084).  Saving model ...\n",
      "[ 594/1000] train_loss: 0.26608 valid_loss: 0.27709 time per epoch: 79.105 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 595/1000] train_loss: 0.26595 valid_loss: 0.27709 time per epoch: 79.055 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 596/1000] train_loss: 0.26610 valid_loss: 0.27710 time per epoch: 79.031 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 597/1000] train_loss: 0.26594 valid_loss: 0.27708 time per epoch: 78.806 s\n",
      "Validation loss decreased (0.277084 --> 0.277078).  Saving model ...\n",
      "[ 598/1000] train_loss: 0.26602 valid_loss: 0.27709 time per epoch: 78.947 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 599/1000] train_loss: 0.26602 valid_loss: 0.27707 time per epoch: 79.005 s\n",
      "Validation loss decreased (0.277078 --> 0.277068).  Saving model ...\n",
      "[ 600/1000] train_loss: 0.26594 valid_loss: 0.27706 time per epoch: 79.241 s\n",
      "Validation loss decreased (0.277068 --> 0.277063).  Saving model ...\n",
      "[ 601/1000] train_loss: 0.26612 valid_loss: 0.27706 time per epoch: 79.286 s\n",
      "Validation loss decreased (0.277063 --> 0.277062).  Saving model ...\n",
      "[ 602/1000] train_loss: 0.26610 valid_loss: 0.27706 time per epoch: 79.465 s\n",
      "Validation loss decreased (0.277062 --> 0.277056).  Saving model ...\n",
      "[ 603/1000] train_loss: 0.26615 valid_loss: 0.27706 time per epoch: 79.227 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 604/1000] train_loss: 0.26597 valid_loss: 0.27704 time per epoch: 79.182 s\n",
      "Validation loss decreased (0.277056 --> 0.277041).  Saving model ...\n",
      "[ 605/1000] train_loss: 0.26596 valid_loss: 0.27704 time per epoch: 79.275 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 606/1000] train_loss: 0.26596 valid_loss: 0.27705 time per epoch: 79.193 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 607/1000] train_loss: 0.26599 valid_loss: 0.27704 time per epoch: 78.969 s\n",
      "Validation loss decreased (0.277041 --> 0.277039).  Saving model ...\n",
      "[ 608/1000] train_loss: 0.26598 valid_loss: 0.27704 time per epoch: 79.088 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 609/1000] train_loss: 0.26606 valid_loss: 0.27702 time per epoch: 79.332 s\n",
      "Validation loss decreased (0.277039 --> 0.277023).  Saving model ...\n",
      "[ 610/1000] train_loss: 0.26607 valid_loss: 0.27700 time per epoch: 79.403 s\n",
      "Validation loss decreased (0.277023 --> 0.277004).  Saving model ...\n",
      "[ 611/1000] train_loss: 0.26613 valid_loss: 0.27701 time per epoch: 79.362 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 612/1000] train_loss: 0.26589 valid_loss: 0.27702 time per epoch: 79.377 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 613/1000] train_loss: 0.26579 valid_loss: 0.27702 time per epoch: 79.026 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 614/1000] train_loss: 0.26580 valid_loss: 0.27700 time per epoch: 79.081 s\n",
      "Validation loss decreased (0.277004 --> 0.276997).  Saving model ...\n",
      "[ 615/1000] train_loss: 0.26608 valid_loss: 0.27699 time per epoch: 79.250 s\n",
      "Validation loss decreased (0.276997 --> 0.276993).  Saving model ...\n",
      "[ 616/1000] train_loss: 0.26605 valid_loss: 0.27701 time per epoch: 79.253 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 617/1000] train_loss: 0.26613 valid_loss: 0.27699 time per epoch: 79.028 s\n",
      "Validation loss decreased (0.276993 --> 0.276989).  Saving model ...\n",
      "[ 618/1000] train_loss: 0.26596 valid_loss: 0.27699 time per epoch: 79.025 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 619/1000] train_loss: 0.26593 valid_loss: 0.27699 time per epoch: 79.232 s\n",
      "Validation loss decreased (0.276989 --> 0.276986).  Saving model ...\n",
      "[ 620/1000] train_loss: 0.26591 valid_loss: 0.27697 time per epoch: 79.277 s\n",
      "Validation loss decreased (0.276986 --> 0.276975).  Saving model ...\n",
      "[ 621/1000] train_loss: 0.26583 valid_loss: 0.27698 time per epoch: 79.381 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 622/1000] train_loss: 0.26596 valid_loss: 0.27697 time per epoch: 79.321 s\n",
      "Validation loss decreased (0.276975 --> 0.276967).  Saving model ...\n",
      "[ 623/1000] train_loss: 0.26592 valid_loss: 0.27697 time per epoch: 79.212 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 624/1000] train_loss: 0.26591 valid_loss: 0.27694 time per epoch: 79.456 s\n",
      "Validation loss decreased (0.276967 --> 0.276945).  Saving model ...\n",
      "[ 625/1000] train_loss: 0.26580 valid_loss: 0.27697 time per epoch: 79.518 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 626/1000] train_loss: 0.26600 valid_loss: 0.27698 time per epoch: 79.367 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 627/1000] train_loss: 0.26605 valid_loss: 0.27696 time per epoch: 79.479 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 628/1000] train_loss: 0.26595 valid_loss: 0.27696 time per epoch: 79.291 s\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[ 629/1000] train_loss: 0.26588 valid_loss: 0.27694 time per epoch: 79.358 s\n",
      "Validation loss decreased (0.276945 --> 0.276944).  Saving model ...\n",
      "[ 630/1000] train_loss: 0.26599 valid_loss: 0.27694 time per epoch: 79.160 s\n",
      "Validation loss decreased (0.276944 --> 0.276938).  Saving model ...\n",
      "[ 631/1000] train_loss: 0.26571 valid_loss: 0.27694 time per epoch: 79.187 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 632/1000] train_loss: 0.26589 valid_loss: 0.27694 time per epoch: 78.975 s\n",
      "Validation loss decreased (0.276938 --> 0.276936).  Saving model ...\n",
      "[ 633/1000] train_loss: 0.26590 valid_loss: 0.27694 time per epoch: 78.986 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 634/1000] train_loss: 0.26600 valid_loss: 0.27691 time per epoch: 79.237 s\n",
      "Validation loss decreased (0.276936 --> 0.276911).  Saving model ...\n",
      "[ 635/1000] train_loss: 0.26585 valid_loss: 0.27692 time per epoch: 79.349 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 636/1000] train_loss: 0.26577 valid_loss: 0.27693 time per epoch: 79.288 s\n",
      "EarlyStopping counter: 2 out of 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 637/1000] train_loss: 0.26593 valid_loss: 0.27692 time per epoch: 79.290 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 638/1000] train_loss: 0.26585 valid_loss: 0.27692 time per epoch: 79.262 s\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[ 639/1000] train_loss: 0.26583 valid_loss: 0.27690 time per epoch: 79.179 s\n",
      "Validation loss decreased (0.276911 --> 0.276898).  Saving model ...\n",
      "[ 640/1000] train_loss: 0.26579 valid_loss: 0.27690 time per epoch: 79.302 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 641/1000] train_loss: 0.26602 valid_loss: 0.27690 time per epoch: 78.981 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 642/1000] train_loss: 0.26590 valid_loss: 0.27690 time per epoch: 79.221 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 643/1000] train_loss: 0.26584 valid_loss: 0.27687 time per epoch: 79.553 s\n",
      "Validation loss decreased (0.276898 --> 0.276866).  Saving model ...\n",
      "[ 644/1000] train_loss: 0.26568 valid_loss: 0.27687 time per epoch: 79.246 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 645/1000] train_loss: 0.26553 valid_loss: 0.27687 time per epoch: 79.092 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 646/1000] train_loss: 0.26576 valid_loss: 0.27687 time per epoch: 79.148 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 647/1000] train_loss: 0.26581 valid_loss: 0.27686 time per epoch: 79.016 s\n",
      "Validation loss decreased (0.276866 --> 0.276859).  Saving model ...\n",
      "[ 648/1000] train_loss: 0.26593 valid_loss: 0.27685 time per epoch: 79.040 s\n",
      "Validation loss decreased (0.276859 --> 0.276853).  Saving model ...\n",
      "[ 649/1000] train_loss: 0.26572 valid_loss: 0.27685 time per epoch: 78.682 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 650/1000] train_loss: 0.26585 valid_loss: 0.27685 time per epoch: 78.495 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 651/1000] train_loss: 0.26582 valid_loss: 0.27685 time per epoch: 78.376 s\n",
      "Validation loss decreased (0.276853 --> 0.276850).  Saving model ...\n",
      "[ 652/1000] train_loss: 0.26567 valid_loss: 0.27684 time per epoch: 78.631 s\n",
      "Validation loss decreased (0.276850 --> 0.276845).  Saving model ...\n",
      "[ 653/1000] train_loss: 0.26563 valid_loss: 0.27684 time per epoch: 78.872 s\n",
      "Validation loss decreased (0.276845 --> 0.276843).  Saving model ...\n",
      "[ 654/1000] train_loss: 0.26573 valid_loss: 0.27684 time per epoch: 78.961 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 655/1000] train_loss: 0.26568 valid_loss: 0.27683 time per epoch: 78.552 s\n",
      "Validation loss decreased (0.276843 --> 0.276829).  Saving model ...\n",
      "[ 656/1000] train_loss: 0.26559 valid_loss: 0.27683 time per epoch: 78.589 s\n",
      "Validation loss decreased (0.276829 --> 0.276828).  Saving model ...\n",
      "[ 657/1000] train_loss: 0.26572 valid_loss: 0.27684 time per epoch: 78.609 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 658/1000] train_loss: 0.26570 valid_loss: 0.27682 time per epoch: 78.346 s\n",
      "Validation loss decreased (0.276828 --> 0.276824).  Saving model ...\n",
      "[ 659/1000] train_loss: 0.26549 valid_loss: 0.27681 time per epoch: 78.184 s\n",
      "Validation loss decreased (0.276824 --> 0.276807).  Saving model ...\n",
      "[ 660/1000] train_loss: 0.26577 valid_loss: 0.27681 time per epoch: 78.323 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 661/1000] train_loss: 0.26565 valid_loss: 0.27680 time per epoch: 78.893 s\n",
      "Validation loss decreased (0.276807 --> 0.276803).  Saving model ...\n",
      "[ 662/1000] train_loss: 0.26566 valid_loss: 0.27680 time per epoch: 78.687 s\n",
      "Validation loss decreased (0.276803 --> 0.276796).  Saving model ...\n",
      "[ 663/1000] train_loss: 0.26591 valid_loss: 0.27681 time per epoch: 78.449 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 664/1000] train_loss: 0.26588 valid_loss: 0.27679 time per epoch: 78.463 s\n",
      "Validation loss decreased (0.276796 --> 0.276795).  Saving model ...\n",
      "[ 665/1000] train_loss: 0.26578 valid_loss: 0.27679 time per epoch: 78.529 s\n",
      "Validation loss decreased (0.276795 --> 0.276791).  Saving model ...\n",
      "[ 666/1000] train_loss: 0.26561 valid_loss: 0.27678 time per epoch: 78.914 s\n",
      "Validation loss decreased (0.276791 --> 0.276777).  Saving model ...\n",
      "[ 667/1000] train_loss: 0.26566 valid_loss: 0.27680 time per epoch: 78.619 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 668/1000] train_loss: 0.26567 valid_loss: 0.27677 time per epoch: 79.073 s\n",
      "Validation loss decreased (0.276777 --> 0.276773).  Saving model ...\n",
      "[ 669/1000] train_loss: 0.26571 valid_loss: 0.27678 time per epoch: 79.100 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 670/1000] train_loss: 0.26569 valid_loss: 0.27677 time per epoch: 79.055 s\n",
      "Validation loss decreased (0.276773 --> 0.276769).  Saving model ...\n",
      "[ 671/1000] train_loss: 0.26579 valid_loss: 0.27677 time per epoch: 79.269 s\n",
      "Validation loss decreased (0.276769 --> 0.276766).  Saving model ...\n",
      "[ 672/1000] train_loss: 0.26572 valid_loss: 0.27676 time per epoch: 79.192 s\n",
      "Validation loss decreased (0.276766 --> 0.276763).  Saving model ...\n",
      "[ 673/1000] train_loss: 0.26559 valid_loss: 0.27677 time per epoch: 79.191 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 674/1000] train_loss: 0.26562 valid_loss: 0.27675 time per epoch: 78.945 s\n",
      "Validation loss decreased (0.276763 --> 0.276750).  Saving model ...\n",
      "[ 675/1000] train_loss: 0.26558 valid_loss: 0.27675 time per epoch: 79.495 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 676/1000] train_loss: 0.26570 valid_loss: 0.27673 time per epoch: 79.418 s\n",
      "Validation loss decreased (0.276750 --> 0.276733).  Saving model ...\n",
      "[ 677/1000] train_loss: 0.26576 valid_loss: 0.27674 time per epoch: 79.150 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 678/1000] train_loss: 0.26549 valid_loss: 0.27674 time per epoch: 78.781 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 679/1000] train_loss: 0.26548 valid_loss: 0.27673 time per epoch: 79.227 s\n",
      "Validation loss decreased (0.276733 --> 0.276731).  Saving model ...\n",
      "[ 680/1000] train_loss: 0.26559 valid_loss: 0.27672 time per epoch: 79.529 s\n",
      "Validation loss decreased (0.276731 --> 0.276722).  Saving model ...\n",
      "[ 681/1000] train_loss: 0.26545 valid_loss: 0.27672 time per epoch: 79.081 s\n",
      "Validation loss decreased (0.276722 --> 0.276720).  Saving model ...\n",
      "[ 682/1000] train_loss: 0.26556 valid_loss: 0.27673 time per epoch: 79.068 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 683/1000] train_loss: 0.26568 valid_loss: 0.27672 time per epoch: 79.204 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 684/1000] train_loss: 0.26552 valid_loss: 0.27673 time per epoch: 79.138 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 685/1000] train_loss: 0.26530 valid_loss: 0.27671 time per epoch: 79.457 s\n",
      "Validation loss decreased (0.276720 --> 0.276713).  Saving model ...\n",
      "[ 686/1000] train_loss: 0.26563 valid_loss: 0.27670 time per epoch: 79.448 s\n",
      "Validation loss decreased (0.276713 --> 0.276700).  Saving model ...\n",
      "[ 687/1000] train_loss: 0.26547 valid_loss: 0.27672 time per epoch: 79.301 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 688/1000] train_loss: 0.26558 valid_loss: 0.27671 time per epoch: 78.354 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 689/1000] train_loss: 0.26558 valid_loss: 0.27668 time per epoch: 78.914 s\n",
      "Validation loss decreased (0.276700 --> 0.276677).  Saving model ...\n",
      "[ 690/1000] train_loss: 0.26552 valid_loss: 0.27668 time per epoch: 79.111 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 691/1000] train_loss: 0.26556 valid_loss: 0.27668 time per epoch: 79.154 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 692/1000] train_loss: 0.26552 valid_loss: 0.27668 time per epoch: 78.889 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 693/1000] train_loss: 0.26555 valid_loss: 0.27668 time per epoch: 78.930 s\n",
      "Validation loss decreased (0.276677 --> 0.276676).  Saving model ...\n",
      "[ 694/1000] train_loss: 0.26529 valid_loss: 0.27667 time per epoch: 79.257 s\n",
      "Validation loss decreased (0.276676 --> 0.276668).  Saving model ...\n",
      "[ 695/1000] train_loss: 0.26534 valid_loss: 0.27668 time per epoch: 79.177 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 696/1000] train_loss: 0.26542 valid_loss: 0.27665 time per epoch: 79.169 s\n",
      "Validation loss decreased (0.276668 --> 0.276650).  Saving model ...\n",
      "[ 697/1000] train_loss: 0.26565 valid_loss: 0.27666 time per epoch: 79.012 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 698/1000] train_loss: 0.26557 valid_loss: 0.27665 time per epoch: 79.234 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 699/1000] train_loss: 0.26542 valid_loss: 0.27665 time per epoch: 79.209 s\n",
      "Validation loss decreased (0.276650 --> 0.276647).  Saving model ...\n",
      "[ 700/1000] train_loss: 0.26544 valid_loss: 0.27666 time per epoch: 79.400 s\n",
      "EarlyStopping counter: 1 out of 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 701/1000] train_loss: 0.26549 valid_loss: 0.27666 time per epoch: 79.331 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 702/1000] train_loss: 0.26525 valid_loss: 0.27664 time per epoch: 79.023 s\n",
      "Validation loss decreased (0.276647 --> 0.276636).  Saving model ...\n",
      "[ 703/1000] train_loss: 0.26529 valid_loss: 0.27664 time per epoch: 79.302 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 704/1000] train_loss: 0.26555 valid_loss: 0.27663 time per epoch: 79.270 s\n",
      "Validation loss decreased (0.276636 --> 0.276632).  Saving model ...\n",
      "[ 705/1000] train_loss: 0.26569 valid_loss: 0.27664 time per epoch: 79.338 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 706/1000] train_loss: 0.26530 valid_loss: 0.27662 time per epoch: 79.306 s\n",
      "Validation loss decreased (0.276632 --> 0.276616).  Saving model ...\n",
      "[ 707/1000] train_loss: 0.26541 valid_loss: 0.27662 time per epoch: 79.063 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 708/1000] train_loss: 0.26532 valid_loss: 0.27661 time per epoch: 79.037 s\n",
      "Validation loss decreased (0.276616 --> 0.276613).  Saving model ...\n",
      "[ 709/1000] train_loss: 0.26513 valid_loss: 0.27661 time per epoch: 79.102 s\n",
      "Validation loss decreased (0.276613 --> 0.276607).  Saving model ...\n",
      "[ 710/1000] train_loss: 0.26545 valid_loss: 0.27660 time per epoch: 79.059 s\n",
      "Validation loss decreased (0.276607 --> 0.276603).  Saving model ...\n",
      "[ 711/1000] train_loss: 0.26530 valid_loss: 0.27659 time per epoch: 79.013 s\n",
      "Validation loss decreased (0.276603 --> 0.276590).  Saving model ...\n",
      "[ 712/1000] train_loss: 0.26531 valid_loss: 0.27659 time per epoch: 78.882 s\n",
      "Validation loss decreased (0.276590 --> 0.276589).  Saving model ...\n",
      "[ 713/1000] train_loss: 0.26516 valid_loss: 0.27659 time per epoch: 79.147 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 714/1000] train_loss: 0.26540 valid_loss: 0.27658 time per epoch: 79.271 s\n",
      "Validation loss decreased (0.276589 --> 0.276577).  Saving model ...\n",
      "[ 715/1000] train_loss: 0.26535 valid_loss: 0.27657 time per epoch: 78.805 s\n",
      "Validation loss decreased (0.276577 --> 0.276570).  Saving model ...\n",
      "[ 716/1000] train_loss: 0.26532 valid_loss: 0.27657 time per epoch: 78.770 s\n",
      "Validation loss decreased (0.276570 --> 0.276566).  Saving model ...\n",
      "[ 717/1000] train_loss: 0.26521 valid_loss: 0.27658 time per epoch: 78.588 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 718/1000] train_loss: 0.26537 valid_loss: 0.27658 time per epoch: 78.480 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 719/1000] train_loss: 0.26514 valid_loss: 0.27656 time per epoch: 78.585 s\n",
      "Validation loss decreased (0.276566 --> 0.276556).  Saving model ...\n",
      "[ 720/1000] train_loss: 0.26544 valid_loss: 0.27656 time per epoch: 78.678 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 721/1000] train_loss: 0.26542 valid_loss: 0.27656 time per epoch: 79.123 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 722/1000] train_loss: 0.26517 valid_loss: 0.27653 time per epoch: 79.313 s\n",
      "Validation loss decreased (0.276556 --> 0.276531).  Saving model ...\n",
      "[ 723/1000] train_loss: 0.26522 valid_loss: 0.27653 time per epoch: 79.705 s\n",
      "Validation loss decreased (0.276531 --> 0.276529).  Saving model ...\n",
      "[ 724/1000] train_loss: 0.26529 valid_loss: 0.27653 time per epoch: 79.611 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 725/1000] train_loss: 0.26518 valid_loss: 0.27652 time per epoch: 78.937 s\n",
      "Validation loss decreased (0.276529 --> 0.276525).  Saving model ...\n",
      "[ 726/1000] train_loss: 0.26516 valid_loss: 0.27652 time per epoch: 79.196 s\n",
      "Validation loss decreased (0.276525 --> 0.276519).  Saving model ...\n",
      "[ 727/1000] train_loss: 0.26554 valid_loss: 0.27652 time per epoch: 79.045 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 728/1000] train_loss: 0.26527 valid_loss: 0.27651 time per epoch: 79.179 s\n",
      "Validation loss decreased (0.276519 --> 0.276509).  Saving model ...\n",
      "[ 729/1000] train_loss: 0.26534 valid_loss: 0.27652 time per epoch: 79.106 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 730/1000] train_loss: 0.26547 valid_loss: 0.27649 time per epoch: 78.767 s\n",
      "Validation loss decreased (0.276509 --> 0.276494).  Saving model ...\n",
      "[ 731/1000] train_loss: 0.26517 valid_loss: 0.27650 time per epoch: 78.976 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 732/1000] train_loss: 0.26556 valid_loss: 0.27651 time per epoch: 78.989 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 733/1000] train_loss: 0.26535 valid_loss: 0.27651 time per epoch: 78.009 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 734/1000] train_loss: 0.26513 valid_loss: 0.27650 time per epoch: 78.284 s\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[ 735/1000] train_loss: 0.26552 valid_loss: 0.27650 time per epoch: 78.302 s\n",
      "EarlyStopping counter: 5 out of 30\n",
      "[ 736/1000] train_loss: 0.26507 valid_loss: 0.27650 time per epoch: 78.231 s\n",
      "EarlyStopping counter: 6 out of 30\n",
      "[ 737/1000] train_loss: 0.26533 valid_loss: 0.27648 time per epoch: 78.302 s\n",
      "Validation loss decreased (0.276494 --> 0.276483).  Saving model ...\n",
      "[ 738/1000] train_loss: 0.26522 valid_loss: 0.27650 time per epoch: 78.246 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 739/1000] train_loss: 0.26529 valid_loss: 0.27647 time per epoch: 78.015 s\n",
      "Validation loss decreased (0.276483 --> 0.276474).  Saving model ...\n",
      "[ 740/1000] train_loss: 0.26526 valid_loss: 0.27649 time per epoch: 78.032 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 741/1000] train_loss: 0.26532 valid_loss: 0.27649 time per epoch: 78.051 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 742/1000] train_loss: 0.26510 valid_loss: 0.27646 time per epoch: 77.996 s\n",
      "Validation loss decreased (0.276474 --> 0.276465).  Saving model ...\n",
      "[ 743/1000] train_loss: 0.26527 valid_loss: 0.27645 time per epoch: 78.047 s\n",
      "Validation loss decreased (0.276465 --> 0.276452).  Saving model ...\n",
      "[ 744/1000] train_loss: 0.26522 valid_loss: 0.27645 time per epoch: 77.962 s\n",
      "Validation loss decreased (0.276452 --> 0.276446).  Saving model ...\n",
      "[ 745/1000] train_loss: 0.26520 valid_loss: 0.27645 time per epoch: 78.041 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 746/1000] train_loss: 0.26511 valid_loss: 0.27645 time per epoch: 78.174 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 747/1000] train_loss: 0.26520 valid_loss: 0.27645 time per epoch: 78.441 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 748/1000] train_loss: 0.26501 valid_loss: 0.27642 time per epoch: 78.413 s\n",
      "Validation loss decreased (0.276446 --> 0.276423).  Saving model ...\n",
      "[ 749/1000] train_loss: 0.26508 valid_loss: 0.27642 time per epoch: 78.435 s\n",
      "Validation loss decreased (0.276423 --> 0.276418).  Saving model ...\n",
      "[ 750/1000] train_loss: 0.26512 valid_loss: 0.27644 time per epoch: 78.425 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 751/1000] train_loss: 0.26533 valid_loss: 0.27643 time per epoch: 78.510 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 752/1000] train_loss: 0.26490 valid_loss: 0.27641 time per epoch: 78.438 s\n",
      "Validation loss decreased (0.276418 --> 0.276406).  Saving model ...\n",
      "[ 753/1000] train_loss: 0.26523 valid_loss: 0.27642 time per epoch: 78.152 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 754/1000] train_loss: 0.26506 valid_loss: 0.27640 time per epoch: 78.385 s\n",
      "Validation loss decreased (0.276406 --> 0.276401).  Saving model ...\n",
      "[ 755/1000] train_loss: 0.26499 valid_loss: 0.27642 time per epoch: 78.261 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 756/1000] train_loss: 0.26487 valid_loss: 0.27642 time per epoch: 78.105 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 757/1000] train_loss: 0.26519 valid_loss: 0.27639 time per epoch: 78.130 s\n",
      "Validation loss decreased (0.276401 --> 0.276391).  Saving model ...\n",
      "[ 758/1000] train_loss: 0.26486 valid_loss: 0.27640 time per epoch: 77.946 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 759/1000] train_loss: 0.26507 valid_loss: 0.27639 time per epoch: 78.707 s\n",
      "Validation loss decreased (0.276391 --> 0.276386).  Saving model ...\n",
      "[ 760/1000] train_loss: 0.26513 valid_loss: 0.27637 time per epoch: 78.785 s\n",
      "Validation loss decreased (0.276386 --> 0.276366).  Saving model ...\n",
      "[ 761/1000] train_loss: 0.26525 valid_loss: 0.27637 time per epoch: 78.943 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 762/1000] train_loss: 0.26556 valid_loss: 0.27637 time per epoch: 78.935 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 763/1000] train_loss: 0.26501 valid_loss: 0.27636 time per epoch: 78.850 s\n",
      "Validation loss decreased (0.276366 --> 0.276363).  Saving model ...\n",
      "[ 764/1000] train_loss: 0.26523 valid_loss: 0.27636 time per epoch: 78.843 s\n",
      "Validation loss decreased (0.276363 --> 0.276362).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 765/1000] train_loss: 0.26505 valid_loss: 0.27637 time per epoch: 78.918 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 766/1000] train_loss: 0.26491 valid_loss: 0.27636 time per epoch: 79.045 s\n",
      "Validation loss decreased (0.276362 --> 0.276358).  Saving model ...\n",
      "[ 767/1000] train_loss: 0.26508 valid_loss: 0.27635 time per epoch: 78.994 s\n",
      "Validation loss decreased (0.276358 --> 0.276353).  Saving model ...\n",
      "[ 768/1000] train_loss: 0.26517 valid_loss: 0.27636 time per epoch: 78.900 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 769/1000] train_loss: 0.26496 valid_loss: 0.27634 time per epoch: 78.909 s\n",
      "Validation loss decreased (0.276353 --> 0.276336).  Saving model ...\n",
      "[ 770/1000] train_loss: 0.26499 valid_loss: 0.27632 time per epoch: 79.018 s\n",
      "Validation loss decreased (0.276336 --> 0.276324).  Saving model ...\n",
      "[ 771/1000] train_loss: 0.26507 valid_loss: 0.27633 time per epoch: 79.171 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 772/1000] train_loss: 0.26526 valid_loss: 0.27636 time per epoch: 79.212 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 773/1000] train_loss: 0.26494 valid_loss: 0.27633 time per epoch: 79.066 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 774/1000] train_loss: 0.26491 valid_loss: 0.27633 time per epoch: 79.051 s\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[ 775/1000] train_loss: 0.26498 valid_loss: 0.27632 time per epoch: 79.285 s\n",
      "EarlyStopping counter: 5 out of 30\n",
      "[ 776/1000] train_loss: 0.26513 valid_loss: 0.27631 time per epoch: 79.276 s\n",
      "Validation loss decreased (0.276324 --> 0.276314).  Saving model ...\n",
      "[ 777/1000] train_loss: 0.26500 valid_loss: 0.27632 time per epoch: 78.991 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 778/1000] train_loss: 0.26505 valid_loss: 0.27629 time per epoch: 79.122 s\n",
      "Validation loss decreased (0.276314 --> 0.276291).  Saving model ...\n",
      "[ 779/1000] train_loss: 0.26488 valid_loss: 0.27630 time per epoch: 79.231 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 780/1000] train_loss: 0.26498 valid_loss: 0.27631 time per epoch: 79.157 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 781/1000] train_loss: 0.26510 valid_loss: 0.27630 time per epoch: 79.085 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 782/1000] train_loss: 0.26504 valid_loss: 0.27630 time per epoch: 79.025 s\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[ 783/1000] train_loss: 0.26493 valid_loss: 0.27629 time per epoch: 79.084 s\n",
      "Validation loss decreased (0.276291 --> 0.276286).  Saving model ...\n",
      "[ 784/1000] train_loss: 0.26493 valid_loss: 0.27627 time per epoch: 79.201 s\n",
      "Validation loss decreased (0.276286 --> 0.276268).  Saving model ...\n",
      "[ 785/1000] train_loss: 0.26498 valid_loss: 0.27629 time per epoch: 79.030 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 786/1000] train_loss: 0.26496 valid_loss: 0.27627 time per epoch: 79.188 s\n",
      "Validation loss decreased (0.276268 --> 0.276265).  Saving model ...\n",
      "[ 787/1000] train_loss: 0.26501 valid_loss: 0.27627 time per epoch: 79.267 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 788/1000] train_loss: 0.26505 valid_loss: 0.27625 time per epoch: 79.266 s\n",
      "Validation loss decreased (0.276265 --> 0.276254).  Saving model ...\n",
      "[ 789/1000] train_loss: 0.26488 valid_loss: 0.27628 time per epoch: 79.283 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 790/1000] train_loss: 0.26486 valid_loss: 0.27627 time per epoch: 79.352 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 791/1000] train_loss: 0.26492 valid_loss: 0.27625 time per epoch: 79.300 s\n",
      "Validation loss decreased (0.276254 --> 0.276248).  Saving model ...\n",
      "[ 792/1000] train_loss: 0.26496 valid_loss: 0.27624 time per epoch: 79.284 s\n",
      "Validation loss decreased (0.276248 --> 0.276235).  Saving model ...\n",
      "[ 793/1000] train_loss: 0.26489 valid_loss: 0.27624 time per epoch: 79.323 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 794/1000] train_loss: 0.26493 valid_loss: 0.27624 time per epoch: 79.220 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 795/1000] train_loss: 0.26478 valid_loss: 0.27625 time per epoch: 79.259 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 796/1000] train_loss: 0.26501 valid_loss: 0.27624 time per epoch: 79.335 s\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[ 797/1000] train_loss: 0.26488 valid_loss: 0.27623 time per epoch: 79.202 s\n",
      "Validation loss decreased (0.276235 --> 0.276235).  Saving model ...\n",
      "[ 798/1000] train_loss: 0.26479 valid_loss: 0.27623 time per epoch: 78.965 s\n",
      "Validation loss decreased (0.276235 --> 0.276227).  Saving model ...\n",
      "[ 799/1000] train_loss: 0.26494 valid_loss: 0.27623 time per epoch: 79.022 s\n",
      "Validation loss decreased (0.276227 --> 0.276226).  Saving model ...\n",
      "[ 800/1000] train_loss: 0.26481 valid_loss: 0.27621 time per epoch: 79.002 s\n",
      "Validation loss decreased (0.276226 --> 0.276214).  Saving model ...\n",
      "[ 801/1000] train_loss: 0.26484 valid_loss: 0.27621 time per epoch: 78.884 s\n",
      "Validation loss decreased (0.276214 --> 0.276212).  Saving model ...\n",
      "[ 802/1000] train_loss: 0.26476 valid_loss: 0.27622 time per epoch: 79.016 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 803/1000] train_loss: 0.26478 valid_loss: 0.27620 time per epoch: 78.944 s\n",
      "Validation loss decreased (0.276212 --> 0.276203).  Saving model ...\n",
      "[ 804/1000] train_loss: 0.26475 valid_loss: 0.27619 time per epoch: 79.290 s\n",
      "Validation loss decreased (0.276203 --> 0.276190).  Saving model ...\n",
      "[ 805/1000] train_loss: 0.26480 valid_loss: 0.27619 time per epoch: 79.438 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 806/1000] train_loss: 0.26461 valid_loss: 0.27620 time per epoch: 79.435 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 807/1000] train_loss: 0.26469 valid_loss: 0.27618 time per epoch: 79.209 s\n",
      "Validation loss decreased (0.276190 --> 0.276180).  Saving model ...\n",
      "[ 808/1000] train_loss: 0.26480 valid_loss: 0.27619 time per epoch: 79.295 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 809/1000] train_loss: 0.26462 valid_loss: 0.27616 time per epoch: 79.269 s\n",
      "Validation loss decreased (0.276180 --> 0.276163).  Saving model ...\n",
      "[ 810/1000] train_loss: 0.26507 valid_loss: 0.27618 time per epoch: 79.266 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 811/1000] train_loss: 0.26473 valid_loss: 0.27617 time per epoch: 79.341 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 812/1000] train_loss: 0.26477 valid_loss: 0.27617 time per epoch: 79.288 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 813/1000] train_loss: 0.26495 valid_loss: 0.27616 time per epoch: 79.181 s\n",
      "Validation loss decreased (0.276163 --> 0.276157).  Saving model ...\n",
      "[ 814/1000] train_loss: 0.26484 valid_loss: 0.27615 time per epoch: 79.171 s\n",
      "Validation loss decreased (0.276157 --> 0.276153).  Saving model ...\n",
      "[ 815/1000] train_loss: 0.26473 valid_loss: 0.27615 time per epoch: 78.844 s\n",
      "Validation loss decreased (0.276153 --> 0.276146).  Saving model ...\n",
      "[ 816/1000] train_loss: 0.26497 valid_loss: 0.27614 time per epoch: 78.938 s\n",
      "Validation loss decreased (0.276146 --> 0.276144).  Saving model ...\n",
      "[ 817/1000] train_loss: 0.26487 valid_loss: 0.27614 time per epoch: 79.310 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 818/1000] train_loss: 0.26482 valid_loss: 0.27614 time per epoch: 79.451 s\n",
      "Validation loss decreased (0.276144 --> 0.276139).  Saving model ...\n",
      "[ 819/1000] train_loss: 0.26476 valid_loss: 0.27615 time per epoch: 79.328 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 820/1000] train_loss: 0.26494 valid_loss: 0.27613 time per epoch: 79.486 s\n",
      "Validation loss decreased (0.276139 --> 0.276131).  Saving model ...\n",
      "[ 821/1000] train_loss: 0.26487 valid_loss: 0.27614 time per epoch: 79.396 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 822/1000] train_loss: 0.26474 valid_loss: 0.27612 time per epoch: 79.373 s\n",
      "Validation loss decreased (0.276131 --> 0.276116).  Saving model ...\n",
      "[ 823/1000] train_loss: 0.26467 valid_loss: 0.27611 time per epoch: 79.330 s\n",
      "Validation loss decreased (0.276116 --> 0.276107).  Saving model ...\n",
      "[ 824/1000] train_loss: 0.26471 valid_loss: 0.27612 time per epoch: 79.231 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 825/1000] train_loss: 0.26469 valid_loss: 0.27610 time per epoch: 79.171 s\n",
      "Validation loss decreased (0.276107 --> 0.276098).  Saving model ...\n",
      "[ 826/1000] train_loss: 0.26462 valid_loss: 0.27610 time per epoch: 79.148 s\n",
      "Validation loss decreased (0.276098 --> 0.276096).  Saving model ...\n",
      "[ 827/1000] train_loss: 0.26457 valid_loss: 0.27610 time per epoch: 79.233 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 828/1000] train_loss: 0.26480 valid_loss: 0.27610 time per epoch: 79.368 s\n",
      "EarlyStopping counter: 2 out of 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 829/1000] train_loss: 0.26493 valid_loss: 0.27608 time per epoch: 79.486 s\n",
      "Validation loss decreased (0.276096 --> 0.276085).  Saving model ...\n",
      "[ 830/1000] train_loss: 0.26489 valid_loss: 0.27610 time per epoch: 79.219 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 831/1000] train_loss: 0.26476 valid_loss: 0.27609 time per epoch: 79.215 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 832/1000] train_loss: 0.26459 valid_loss: 0.27608 time per epoch: 79.451 s\n",
      "Validation loss decreased (0.276085 --> 0.276077).  Saving model ...\n",
      "[ 833/1000] train_loss: 0.26466 valid_loss: 0.27608 time per epoch: 79.447 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 834/1000] train_loss: 0.26477 valid_loss: 0.27608 time per epoch: 79.382 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 835/1000] train_loss: 0.26477 valid_loss: 0.27606 time per epoch: 79.309 s\n",
      "Validation loss decreased (0.276077 --> 0.276059).  Saving model ...\n",
      "[ 836/1000] train_loss: 0.26449 valid_loss: 0.27605 time per epoch: 79.472 s\n",
      "Validation loss decreased (0.276059 --> 0.276047).  Saving model ...\n",
      "[ 837/1000] train_loss: 0.26477 valid_loss: 0.27606 time per epoch: 79.513 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 838/1000] train_loss: 0.26462 valid_loss: 0.27605 time per epoch: 79.334 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 839/1000] train_loss: 0.26465 valid_loss: 0.27606 time per epoch: 79.445 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 840/1000] train_loss: 0.26451 valid_loss: 0.27604 time per epoch: 79.410 s\n",
      "Validation loss decreased (0.276047 --> 0.276044).  Saving model ...\n",
      "[ 841/1000] train_loss: 0.26455 valid_loss: 0.27603 time per epoch: 79.362 s\n",
      "Validation loss decreased (0.276044 --> 0.276031).  Saving model ...\n",
      "[ 842/1000] train_loss: 0.26452 valid_loss: 0.27603 time per epoch: 79.516 s\n",
      "Validation loss decreased (0.276031 --> 0.276030).  Saving model ...\n",
      "[ 843/1000] train_loss: 0.26471 valid_loss: 0.27603 time per epoch: 79.500 s\n",
      "Validation loss decreased (0.276030 --> 0.276029).  Saving model ...\n",
      "[ 844/1000] train_loss: 0.26452 valid_loss: 0.27602 time per epoch: 79.712 s\n",
      "Validation loss decreased (0.276029 --> 0.276018).  Saving model ...\n",
      "[ 845/1000] train_loss: 0.26456 valid_loss: 0.27601 time per epoch: 79.368 s\n",
      "Validation loss decreased (0.276018 --> 0.276010).  Saving model ...\n",
      "[ 846/1000] train_loss: 0.26476 valid_loss: 0.27604 time per epoch: 79.384 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 847/1000] train_loss: 0.26463 valid_loss: 0.27603 time per epoch: 79.317 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 848/1000] train_loss: 0.26448 valid_loss: 0.27600 time per epoch: 79.261 s\n",
      "Validation loss decreased (0.276010 --> 0.276001).  Saving model ...\n",
      "[ 849/1000] train_loss: 0.26449 valid_loss: 0.27601 time per epoch: 79.370 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 850/1000] train_loss: 0.26451 valid_loss: 0.27601 time per epoch: 79.094 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 851/1000] train_loss: 0.26466 valid_loss: 0.27600 time per epoch: 79.268 s\n",
      "Validation loss decreased (0.276001 --> 0.275997).  Saving model ...\n",
      "[ 852/1000] train_loss: 0.26448 valid_loss: 0.27598 time per epoch: 79.142 s\n",
      "Validation loss decreased (0.275997 --> 0.275984).  Saving model ...\n",
      "[ 853/1000] train_loss: 0.26445 valid_loss: 0.27601 time per epoch: 79.019 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 854/1000] train_loss: 0.26441 valid_loss: 0.27597 time per epoch: 78.777 s\n",
      "Validation loss decreased (0.275984 --> 0.275969).  Saving model ...\n",
      "[ 855/1000] train_loss: 0.26476 valid_loss: 0.27598 time per epoch: 78.852 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 856/1000] train_loss: 0.26458 valid_loss: 0.27598 time per epoch: 79.105 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 857/1000] train_loss: 0.26461 valid_loss: 0.27597 time per epoch: 78.863 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 858/1000] train_loss: 0.26458 valid_loss: 0.27597 time per epoch: 79.131 s\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[ 859/1000] train_loss: 0.26432 valid_loss: 0.27595 time per epoch: 78.913 s\n",
      "Validation loss decreased (0.275969 --> 0.275946).  Saving model ...\n",
      "[ 860/1000] train_loss: 0.26438 valid_loss: 0.27595 time per epoch: 78.965 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 861/1000] train_loss: 0.26454 valid_loss: 0.27597 time per epoch: 78.881 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 862/1000] train_loss: 0.26451 valid_loss: 0.27594 time per epoch: 78.440 s\n",
      "Validation loss decreased (0.275946 --> 0.275941).  Saving model ...\n",
      "[ 863/1000] train_loss: 0.26445 valid_loss: 0.27596 time per epoch: 78.836 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 864/1000] train_loss: 0.26447 valid_loss: 0.27594 time per epoch: 79.243 s\n",
      "Validation loss decreased (0.275941 --> 0.275937).  Saving model ...\n",
      "[ 865/1000] train_loss: 0.26477 valid_loss: 0.27596 time per epoch: 79.482 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 866/1000] train_loss: 0.26431 valid_loss: 0.27592 time per epoch: 79.102 s\n",
      "Validation loss decreased (0.275937 --> 0.275922).  Saving model ...\n",
      "[ 867/1000] train_loss: 0.26470 valid_loss: 0.27594 time per epoch: 79.656 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 868/1000] train_loss: 0.26445 valid_loss: 0.27591 time per epoch: 78.666 s\n",
      "Validation loss decreased (0.275922 --> 0.275915).  Saving model ...\n",
      "[ 869/1000] train_loss: 0.26423 valid_loss: 0.27592 time per epoch: 78.677 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 870/1000] train_loss: 0.26441 valid_loss: 0.27591 time per epoch: 78.592 s\n",
      "Validation loss decreased (0.275915 --> 0.275912).  Saving model ...\n",
      "[ 871/1000] train_loss: 0.26442 valid_loss: 0.27589 time per epoch: 78.814 s\n",
      "Validation loss decreased (0.275912 --> 0.275887).  Saving model ...\n",
      "[ 872/1000] train_loss: 0.26440 valid_loss: 0.27590 time per epoch: 78.449 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 873/1000] train_loss: 0.26450 valid_loss: 0.27589 time per epoch: 78.586 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 874/1000] train_loss: 0.26475 valid_loss: 0.27590 time per epoch: 78.340 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 875/1000] train_loss: 0.26422 valid_loss: 0.27589 time per epoch: 78.312 s\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[ 876/1000] train_loss: 0.26446 valid_loss: 0.27590 time per epoch: 78.396 s\n",
      "EarlyStopping counter: 5 out of 30\n",
      "[ 877/1000] train_loss: 0.26426 valid_loss: 0.27589 time per epoch: 78.678 s\n",
      "EarlyStopping counter: 6 out of 30\n",
      "[ 878/1000] train_loss: 0.26446 valid_loss: 0.27586 time per epoch: 78.605 s\n",
      "Validation loss decreased (0.275887 --> 0.275864).  Saving model ...\n",
      "[ 879/1000] train_loss: 0.26451 valid_loss: 0.27588 time per epoch: 78.464 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 880/1000] train_loss: 0.26441 valid_loss: 0.27589 time per epoch: 78.368 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 881/1000] train_loss: 0.26447 valid_loss: 0.27589 time per epoch: 78.274 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 882/1000] train_loss: 0.26435 valid_loss: 0.27587 time per epoch: 78.298 s\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[ 883/1000] train_loss: 0.26433 valid_loss: 0.27586 time per epoch: 78.794 s\n",
      "Validation loss decreased (0.275864 --> 0.275860).  Saving model ...\n",
      "[ 884/1000] train_loss: 0.26429 valid_loss: 0.27585 time per epoch: 79.261 s\n",
      "Validation loss decreased (0.275860 --> 0.275849).  Saving model ...\n",
      "[ 885/1000] train_loss: 0.26439 valid_loss: 0.27584 time per epoch: 79.441 s\n",
      "Validation loss decreased (0.275849 --> 0.275844).  Saving model ...\n",
      "[ 886/1000] train_loss: 0.26420 valid_loss: 0.27585 time per epoch: 78.901 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 887/1000] train_loss: 0.26443 valid_loss: 0.27588 time per epoch: 78.978 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 888/1000] train_loss: 0.26434 valid_loss: 0.27583 time per epoch: 79.005 s\n",
      "Validation loss decreased (0.275844 --> 0.275831).  Saving model ...\n",
      "[ 889/1000] train_loss: 0.26428 valid_loss: 0.27584 time per epoch: 78.946 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 890/1000] train_loss: 0.26434 valid_loss: 0.27583 time per epoch: 79.083 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 891/1000] train_loss: 0.26431 valid_loss: 0.27582 time per epoch: 79.090 s\n",
      "Validation loss decreased (0.275831 --> 0.275820).  Saving model ...\n",
      "[ 892/1000] train_loss: 0.26424 valid_loss: 0.27582 time per epoch: 79.241 s\n",
      "Validation loss decreased (0.275820 --> 0.275819).  Saving model ...\n",
      "[ 893/1000] train_loss: 0.26432 valid_loss: 0.27581 time per epoch: 79.684 s\n",
      "Validation loss decreased (0.275819 --> 0.275812).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 894/1000] train_loss: 0.26422 valid_loss: 0.27581 time per epoch: 79.310 s\n",
      "Validation loss decreased (0.275812 --> 0.275809).  Saving model ...\n",
      "[ 895/1000] train_loss: 0.26436 valid_loss: 0.27581 time per epoch: 79.176 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 896/1000] train_loss: 0.26417 valid_loss: 0.27581 time per epoch: 79.132 s\n",
      "Validation loss decreased (0.275809 --> 0.275806).  Saving model ...\n",
      "[ 897/1000] train_loss: 0.26431 valid_loss: 0.27581 time per epoch: 78.696 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 898/1000] train_loss: 0.26435 valid_loss: 0.27579 time per epoch: 79.890 s\n",
      "Validation loss decreased (0.275806 --> 0.275795).  Saving model ...\n",
      "[ 899/1000] train_loss: 0.26427 valid_loss: 0.27579 time per epoch: 79.248 s\n",
      "Validation loss decreased (0.275795 --> 0.275793).  Saving model ...\n",
      "[ 900/1000] train_loss: 0.26428 valid_loss: 0.27578 time per epoch: 78.493 s\n",
      "Validation loss decreased (0.275793 --> 0.275784).  Saving model ...\n",
      "[ 901/1000] train_loss: 0.26434 valid_loss: 0.27577 time per epoch: 79.749 s\n",
      "Validation loss decreased (0.275784 --> 0.275773).  Saving model ...\n",
      "[ 902/1000] train_loss: 0.26409 valid_loss: 0.27577 time per epoch: 79.408 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 903/1000] train_loss: 0.26407 valid_loss: 0.27577 time per epoch: 79.541 s\n",
      "Validation loss decreased (0.275773 --> 0.275768).  Saving model ...\n",
      "[ 904/1000] train_loss: 0.26434 valid_loss: 0.27578 time per epoch: 79.448 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 905/1000] train_loss: 0.26429 valid_loss: 0.27576 time per epoch: 79.520 s\n",
      "Validation loss decreased (0.275768 --> 0.275756).  Saving model ...\n",
      "[ 906/1000] train_loss: 0.26419 valid_loss: 0.27576 time per epoch: 79.585 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 907/1000] train_loss: 0.26419 valid_loss: 0.27573 time per epoch: 79.455 s\n",
      "Validation loss decreased (0.275756 --> 0.275734).  Saving model ...\n",
      "[ 908/1000] train_loss: 0.26407 valid_loss: 0.27574 time per epoch: 79.454 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 909/1000] train_loss: 0.26433 valid_loss: 0.27574 time per epoch: 79.386 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 910/1000] train_loss: 0.26426 valid_loss: 0.27573 time per epoch: 79.218 s\n",
      "Validation loss decreased (0.275734 --> 0.275731).  Saving model ...\n",
      "[ 911/1000] train_loss: 0.26438 valid_loss: 0.27574 time per epoch: 79.158 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 912/1000] train_loss: 0.26402 valid_loss: 0.27571 time per epoch: 79.274 s\n",
      "Validation loss decreased (0.275731 --> 0.275715).  Saving model ...\n",
      "[ 913/1000] train_loss: 0.26407 valid_loss: 0.27572 time per epoch: 79.297 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 914/1000] train_loss: 0.26406 valid_loss: 0.27572 time per epoch: 79.202 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 915/1000] train_loss: 0.26413 valid_loss: 0.27571 time per epoch: 79.548 s\n",
      "Validation loss decreased (0.275715 --> 0.275710).  Saving model ...\n",
      "[ 916/1000] train_loss: 0.26412 valid_loss: 0.27571 time per epoch: 78.920 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 917/1000] train_loss: 0.26410 valid_loss: 0.27570 time per epoch: 79.050 s\n",
      "Validation loss decreased (0.275710 --> 0.275704).  Saving model ...\n",
      "[ 918/1000] train_loss: 0.26412 valid_loss: 0.27570 time per epoch: 78.759 s\n",
      "Validation loss decreased (0.275704 --> 0.275698).  Saving model ...\n",
      "[ 919/1000] train_loss: 0.26429 valid_loss: 0.27569 time per epoch: 78.603 s\n",
      "Validation loss decreased (0.275698 --> 0.275693).  Saving model ...\n",
      "[ 920/1000] train_loss: 0.26428 valid_loss: 0.27570 time per epoch: 78.640 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 921/1000] train_loss: 0.26423 valid_loss: 0.27568 time per epoch: 78.689 s\n",
      "Validation loss decreased (0.275693 --> 0.275682).  Saving model ...\n",
      "[ 922/1000] train_loss: 0.26404 valid_loss: 0.27568 time per epoch: 79.268 s\n",
      "Validation loss decreased (0.275682 --> 0.275680).  Saving model ...\n",
      "[ 923/1000] train_loss: 0.26415 valid_loss: 0.27569 time per epoch: 79.019 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 924/1000] train_loss: 0.26399 valid_loss: 0.27568 time per epoch: 79.200 s\n",
      "Validation loss decreased (0.275680 --> 0.275678).  Saving model ...\n",
      "[ 925/1000] train_loss: 0.26394 valid_loss: 0.27566 time per epoch: 79.179 s\n",
      "Validation loss decreased (0.275678 --> 0.275663).  Saving model ...\n",
      "[ 926/1000] train_loss: 0.26415 valid_loss: 0.27567 time per epoch: 79.279 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 927/1000] train_loss: 0.26410 valid_loss: 0.27567 time per epoch: 79.032 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 928/1000] train_loss: 0.26401 valid_loss: 0.27567 time per epoch: 79.095 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 929/1000] train_loss: 0.26407 valid_loss: 0.27568 time per epoch: 78.760 s\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[ 930/1000] train_loss: 0.26399 valid_loss: 0.27564 time per epoch: 78.625 s\n",
      "Validation loss decreased (0.275663 --> 0.275642).  Saving model ...\n",
      "[ 931/1000] train_loss: 0.26432 valid_loss: 0.27566 time per epoch: 78.563 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 932/1000] train_loss: 0.26402 valid_loss: 0.27565 time per epoch: 78.594 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 933/1000] train_loss: 0.26419 valid_loss: 0.27564 time per epoch: 78.693 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 934/1000] train_loss: 0.26408 valid_loss: 0.27563 time per epoch: 78.857 s\n",
      "Validation loss decreased (0.275642 --> 0.275632).  Saving model ...\n",
      "[ 935/1000] train_loss: 0.26390 valid_loss: 0.27563 time per epoch: 78.909 s\n",
      "Validation loss decreased (0.275632 --> 0.275625).  Saving model ...\n",
      "[ 936/1000] train_loss: 0.26408 valid_loss: 0.27562 time per epoch: 78.901 s\n",
      "Validation loss decreased (0.275625 --> 0.275615).  Saving model ...\n",
      "[ 937/1000] train_loss: 0.26409 valid_loss: 0.27562 time per epoch: 78.769 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 938/1000] train_loss: 0.26405 valid_loss: 0.27561 time per epoch: 79.015 s\n",
      "Validation loss decreased (0.275615 --> 0.275611).  Saving model ...\n",
      "[ 939/1000] train_loss: 0.26399 valid_loss: 0.27561 time per epoch: 79.039 s\n",
      "Validation loss decreased (0.275611 --> 0.275609).  Saving model ...\n",
      "[ 940/1000] train_loss: 0.26392 valid_loss: 0.27561 time per epoch: 79.037 s\n",
      "Validation loss decreased (0.275609 --> 0.275605).  Saving model ...\n",
      "[ 941/1000] train_loss: 0.26394 valid_loss: 0.27562 time per epoch: 79.316 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 942/1000] train_loss: 0.26406 valid_loss: 0.27558 time per epoch: 79.152 s\n",
      "Validation loss decreased (0.275605 --> 0.275581).  Saving model ...\n",
      "[ 943/1000] train_loss: 0.26390 valid_loss: 0.27558 time per epoch: 79.206 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 944/1000] train_loss: 0.26398 valid_loss: 0.27559 time per epoch: 79.311 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 945/1000] train_loss: 0.26390 valid_loss: 0.27558 time per epoch: 79.169 s\n",
      "Validation loss decreased (0.275581 --> 0.275580).  Saving model ...\n",
      "[ 946/1000] train_loss: 0.26430 valid_loss: 0.27558 time per epoch: 79.229 s\n",
      "Validation loss decreased (0.275580 --> 0.275578).  Saving model ...\n",
      "[ 947/1000] train_loss: 0.26383 valid_loss: 0.27557 time per epoch: 79.409 s\n",
      "Validation loss decreased (0.275578 --> 0.275575).  Saving model ...\n",
      "[ 948/1000] train_loss: 0.26409 valid_loss: 0.27558 time per epoch: 79.226 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 949/1000] train_loss: 0.26411 valid_loss: 0.27558 time per epoch: 79.354 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 950/1000] train_loss: 0.26411 valid_loss: 0.27557 time per epoch: 79.497 s\n",
      "Validation loss decreased (0.275575 --> 0.275566).  Saving model ...\n",
      "[ 951/1000] train_loss: 0.26398 valid_loss: 0.27557 time per epoch: 79.553 s\n",
      "Validation loss decreased (0.275566 --> 0.275565).  Saving model ...\n",
      "[ 952/1000] train_loss: 0.26397 valid_loss: 0.27556 time per epoch: 79.350 s\n",
      "Validation loss decreased (0.275565 --> 0.275563).  Saving model ...\n",
      "[ 953/1000] train_loss: 0.26380 valid_loss: 0.27556 time per epoch: 79.215 s\n",
      "Validation loss decreased (0.275563 --> 0.275558).  Saving model ...\n",
      "[ 954/1000] train_loss: 0.26407 valid_loss: 0.27554 time per epoch: 79.046 s\n",
      "Validation loss decreased (0.275558 --> 0.275542).  Saving model ...\n",
      "[ 955/1000] train_loss: 0.26382 valid_loss: 0.27555 time per epoch: 79.228 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 956/1000] train_loss: 0.26398 valid_loss: 0.27554 time per epoch: 79.261 s\n",
      "EarlyStopping counter: 2 out of 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 957/1000] train_loss: 0.26387 valid_loss: 0.27553 time per epoch: 79.545 s\n",
      "Validation loss decreased (0.275542 --> 0.275527).  Saving model ...\n",
      "[ 958/1000] train_loss: 0.26387 valid_loss: 0.27554 time per epoch: 79.381 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 959/1000] train_loss: 0.26393 valid_loss: 0.27554 time per epoch: 79.449 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 960/1000] train_loss: 0.26370 valid_loss: 0.27552 time per epoch: 79.669 s\n",
      "Validation loss decreased (0.275527 --> 0.275524).  Saving model ...\n",
      "[ 961/1000] train_loss: 0.26386 valid_loss: 0.27555 time per epoch: 79.470 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 962/1000] train_loss: 0.26384 valid_loss: 0.27552 time per epoch: 79.176 s\n",
      "Validation loss decreased (0.275524 --> 0.275518).  Saving model ...\n",
      "[ 963/1000] train_loss: 0.26400 valid_loss: 0.27550 time per epoch: 79.055 s\n",
      "Validation loss decreased (0.275518 --> 0.275502).  Saving model ...\n",
      "[ 964/1000] train_loss: 0.26410 valid_loss: 0.27549 time per epoch: 78.895 s\n",
      "Validation loss decreased (0.275502 --> 0.275495).  Saving model ...\n",
      "[ 965/1000] train_loss: 0.26383 valid_loss: 0.27551 time per epoch: 78.987 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 966/1000] train_loss: 0.26371 valid_loss: 0.27549 time per epoch: 79.382 s\n",
      "Validation loss decreased (0.275495 --> 0.275494).  Saving model ...\n",
      "[ 967/1000] train_loss: 0.26400 valid_loss: 0.27550 time per epoch: 79.502 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 968/1000] train_loss: 0.26382 valid_loss: 0.27546 time per epoch: 79.559 s\n",
      "Validation loss decreased (0.275494 --> 0.275462).  Saving model ...\n",
      "[ 969/1000] train_loss: 0.26362 valid_loss: 0.27548 time per epoch: 79.397 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 970/1000] train_loss: 0.26381 valid_loss: 0.27548 time per epoch: 79.539 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 971/1000] train_loss: 0.26396 valid_loss: 0.27547 time per epoch: 79.207 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 972/1000] train_loss: 0.26384 valid_loss: 0.27546 time per epoch: 79.334 s\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[ 973/1000] train_loss: 0.26396 valid_loss: 0.27546 time per epoch: 79.597 s\n",
      "Validation loss decreased (0.275462 --> 0.275461).  Saving model ...\n",
      "[ 974/1000] train_loss: 0.26380 valid_loss: 0.27544 time per epoch: 79.637 s\n",
      "Validation loss decreased (0.275461 --> 0.275436).  Saving model ...\n",
      "[ 975/1000] train_loss: 0.26380 valid_loss: 0.27545 time per epoch: 79.137 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 976/1000] train_loss: 0.26368 valid_loss: 0.27544 time per epoch: 79.032 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 977/1000] train_loss: 0.26381 valid_loss: 0.27545 time per epoch: 78.926 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 978/1000] train_loss: 0.26373 valid_loss: 0.27543 time per epoch: 78.987 s\n",
      "Validation loss decreased (0.275436 --> 0.275435).  Saving model ...\n",
      "[ 979/1000] train_loss: 0.26372 valid_loss: 0.27542 time per epoch: 78.982 s\n",
      "Validation loss decreased (0.275435 --> 0.275424).  Saving model ...\n",
      "[ 980/1000] train_loss: 0.26379 valid_loss: 0.27541 time per epoch: 79.144 s\n",
      "Validation loss decreased (0.275424 --> 0.275412).  Saving model ...\n",
      "[ 981/1000] train_loss: 0.26372 valid_loss: 0.27544 time per epoch: 79.203 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 982/1000] train_loss: 0.26374 valid_loss: 0.27542 time per epoch: 79.050 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 983/1000] train_loss: 0.26369 valid_loss: 0.27541 time per epoch: 79.453 s\n",
      "Validation loss decreased (0.275412 --> 0.275410).  Saving model ...\n",
      "[ 984/1000] train_loss: 0.26393 valid_loss: 0.27542 time per epoch: 78.933 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 985/1000] train_loss: 0.26385 valid_loss: 0.27539 time per epoch: 78.869 s\n",
      "Validation loss decreased (0.275410 --> 0.275391).  Saving model ...\n",
      "[ 986/1000] train_loss: 0.26374 valid_loss: 0.27539 time per epoch: 78.736 s\n",
      "Validation loss decreased (0.275391 --> 0.275387).  Saving model ...\n",
      "[ 987/1000] train_loss: 0.26368 valid_loss: 0.27538 time per epoch: 78.838 s\n",
      "Validation loss decreased (0.275387 --> 0.275382).  Saving model ...\n",
      "[ 988/1000] train_loss: 0.26362 valid_loss: 0.27540 time per epoch: 78.982 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 989/1000] train_loss: 0.26371 valid_loss: 0.27539 time per epoch: 78.991 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 990/1000] train_loss: 0.26373 valid_loss: 0.27538 time per epoch: 79.098 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 991/1000] train_loss: 0.26368 valid_loss: 0.27536 time per epoch: 79.119 s\n",
      "Validation loss decreased (0.275382 --> 0.275364).  Saving model ...\n",
      "[ 992/1000] train_loss: 0.26372 valid_loss: 0.27537 time per epoch: 78.996 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 993/1000] train_loss: 0.26363 valid_loss: 0.27538 time per epoch: 79.057 s\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[ 994/1000] train_loss: 0.26364 valid_loss: 0.27537 time per epoch: 79.227 s\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[ 995/1000] train_loss: 0.26385 valid_loss: 0.27536 time per epoch: 79.602 s\n",
      "Validation loss decreased (0.275364 --> 0.275362).  Saving model ...\n",
      "[ 996/1000] train_loss: 0.26404 valid_loss: 0.27537 time per epoch: 79.343 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[ 997/1000] train_loss: 0.26378 valid_loss: 0.27535 time per epoch: 79.149 s\n",
      "Validation loss decreased (0.275362 --> 0.275346).  Saving model ...\n",
      "[ 998/1000] train_loss: 0.26354 valid_loss: 0.27534 time per epoch: 79.018 s\n",
      "Validation loss decreased (0.275346 --> 0.275342).  Saving model ...\n",
      "[ 999/1000] train_loss: 0.26346 valid_loss: 0.27535 time per epoch: 79.348 s\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[1000/1000] train_loss: 0.26380 valid_loss: 0.27535 time per epoch: 78.889 s\n",
      "EarlyStopping counter: 2 out of 30\n"
     ]
    }
   ],
   "source": [
    "avg_train_losses, \\\n",
    "avg_valid_losses = train_augmentation_fly(train_iter,\n",
    "                                   validate_iter,\n",
    "                                   model,\n",
    "                                   loss_fn,\n",
    "                                   optimizer,\n",
    "                                   lr_schedule=lr_schedule,\n",
    "                                   epochs=1000,\n",
    "                                   patience=30,\n",
    "                                   device=devc,\n",
    "                                   Nx_sub=1280,\n",
    "                                   Nt=1280,\n",
    "                                   mask_ratio=0.0, \n",
    "                                   minimum_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4379296",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %% Show loss evolution when training is done\n",
    "loss = avg_train_losses\n",
    "val_loss = avg_valid_losses\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.plot(loss[1:], '-', label='loss')\n",
    "plt.plot(val_loss, '-', label='Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.title('loss curves')\n",
    "plt.savefig('history_checkpoint_batch128_noskip_mask0.0_lossFullimage_patch10.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a163bfbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo (SHARED)",
   "language": "python",
   "name": "seismo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
