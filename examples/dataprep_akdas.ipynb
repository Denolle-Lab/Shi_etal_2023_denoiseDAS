{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10ad34f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import time\n",
    "import numpy as np\n",
    "import obspy as op\n",
    "\n",
    "from obspy import UTCDateTime\n",
    "from obspy.taup import TauPyModel\n",
    "from scipy.signal import butter, filtfilt, detrend\n",
    "from obspy.core.event import Catalog\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy.geodetics.base import locations2degrees, degrees2kilometers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc8594f",
   "metadata": {},
   "source": [
    "## get catalog from Alaska network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "605aad00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Event(s) in Catalog:\n",
      "2023-07-16T06:51:20.149000Z | +54.628, -160.815 | 5.8  mb | manual\n",
      "2023-07-16T06:48:21.158000Z | +54.393, -160.762 | 7.2  mww | manual\n",
      "[UTCDateTime(2023, 7, 16, 6, 52, 57, 17601)\n",
      " UTCDateTime(2023, 7, 16, 6, 50, 1, 126176)]\n"
     ]
    }
   ],
   "source": [
    "seis_arrays = ['KKFLS','TERRA']\n",
    "rec_dirs = ['/mnt/qnap/KKFL-S_FIberA_25Hz','/mnt/qnap/TERRA_FiberA_25Hz']\n",
    "format_part = ['decimator2_%Y-%m-%d_%H.%M.??_UTC.h5','decimator2_%Y-%m-%d_%H.%M.??_UTC.h5']\n",
    "format_full = ['decimator2_%Y-%m-%d_%H.%M.%S_UTC.h5','decimator2_%Y-%m-%d_%H.%M.%S_UTC.h5']\n",
    "\n",
    "t1 = UTCDateTime(\"2023-07-16T06:00:00\")\n",
    "t2 = UTCDateTime(\"2023-07-16T07:00:00\")\n",
    "cat, pt = ak_catalog(t1, t2, b=0.6)\n",
    "print(cat)\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eb96ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ak_catalog(t1, t2, lat0=59.441, lon0=-152.028, a=-1, b=0.55):\n",
    "    '''\n",
    "    In:  t1, t2: start and ending timestamps\n",
    "         lat0,lon0: Reference point of DAS network\n",
    "         a, b: simple GMM parameters\n",
    "    Out: cat : USGS AK catalog meeting GMM threshold\n",
    "         ptimes : absolute P arrival times\n",
    "    '''\n",
    "    events = []; ptimes = []\n",
    "    \n",
    "    # Get local catalog\n",
    "    catalog = Client('USGS').get_events(\n",
    "                starttime=t1,\n",
    "                endtime=t2,\n",
    "                catalog='ak',\n",
    "                includeallorigins=True,\n",
    "                includeallmagnitudes=True)\n",
    "    \n",
    "    for event in catalog:\n",
    "        lon = event.origins[0]['longitude']\n",
    "        lat = event.origins[0]['latitude']\n",
    "        dep = event.origins[0]['depth'] * 1e-3\n",
    "        mag = event.magnitudes[0]['mag']\n",
    "        distdeg = locations2degrees(lat0,lon0,lat,lon)\n",
    "        distkm = degrees2kilometers(distdeg)\n",
    "        rad = np.sqrt(distkm**2 + dep**2)\n",
    "        \n",
    "        if (mag - 10**(a + b*np.log10(rad)) >= 0):\n",
    "            model = TauPyModel(model='iasp91')\n",
    "            arr = model.get_travel_times(\n",
    "                source_depth_in_km=dep,\n",
    "                distance_in_degree=distdeg)\n",
    "            \n",
    "            t0 = event.origins[0]['time']\n",
    "            ptimes.append(t0 + arr[0].time)\n",
    "            events.append(event)\n",
    "\n",
    "    return Catalog(events=events), np.array(ptimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d56861fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ak_record_lists(rec_dir,format_part,format_full,times):\n",
    "    '''\n",
    "    In:  rec_dir : path to the raw data\n",
    "         format_part/full: file name format\n",
    "         times: event first arrival time\n",
    "    Out: elist : list of files records events\n",
    "         nlist : list of files of noises\n",
    "    '''\n",
    "    elist = []; nlist = []\n",
    "    \n",
    "    for t_arrival in times:\n",
    "        fname = UTCDateTime.strftime(t_arrival, format=format_part)\n",
    "        fname = os.path.basename(glob.glob(rec_dir + fname)[0])\n",
    "        t_file = UTCDateTime.strptime(fname, format=format_full)\n",
    "        if (t_arrival-t_file) > 0:\n",
    "            t_eq = t_file\n",
    "        else:\n",
    "            t_eq = t_file - 60\n",
    "        t_no = t_eq - 60\n",
    "        \n",
    "        fname = UTCDateTime.strftime(t_eq, format=format_part)\n",
    "        eq_file = os.path.basename(glob.glob(rec_dir + fname)[0])\n",
    "        fname = UTCDateTime.strftime(t_no, format=format_part)\n",
    "        no_file = os.path.basename(glob.glob(rec_dir + fname)[0])\n",
    "        \n",
    "        elist.append(os.path.join(rec_dir, eq_file))\n",
    "        nlist.append(os.path.join(rec_dir, no_file))\n",
    "    \n",
    "    return elist, nlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4da3daea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataprep_akdas(outdir,seis_arrays,rec_dirs,format_part,format_full,times):\n",
    "    \n",
    "    for rec_dir, seis_array in zip(rec_dirs, seis_arrays):\n",
    "        elist, nlist = ak_record_lists(rec_dir,format_part,format_full,times)\n",
    "        if not len(elist) == len(nlist):\n",
    "            print('Inconsistent number of quake and noise files')\n",
    "            raise ValueError\n",
    "        \n",
    "        all_quake = np.zeros((len(elist), 7500, 1500), dtype=np.float32)\n",
    "        all_noise = np.zeros((len(nlist), 7500, 1500), dtype=np.float32)\n",
    "        \n",
    "        for i, (eq_file, no_file) in enumerate(zip(elist, nlist)):\n",
    "            \n",
    "            with h5py.File(eq_file, 'r') as f:\n",
    "                time_data = f['Acquisition']['Raw[0]']['RawData'][:1500, 100:7600]\n",
    "                \n",
    "            time_data=(time_data-np.mean(time_data))/np.std(time_data)\n",
    "            all_quake[i,:,:] = time_data.T\n",
    "            \n",
    "            with h5py.File(no_file, 'r') as f:\n",
    "                time_data = f['Acquisition']['Raw[0]']['RawData'][:1500, 100:7600]\n",
    "                \n",
    "            time_data=(time_data-np.mean(time_data))/np.std(time_data)\n",
    "            all_noise[i,:,:] = time_data.T\n",
    "        \n",
    "        today = UTCDateTime.strftime(UTCDateTime.now(), format='%Y_%m_%d')\n",
    "        with h5py.File(out_dir + seis_arrays + 'till' + today + '.hdf5', 'w') as f:\n",
    "            f.create_dataset(\"quake\", data=all_quake)\n",
    "            f.create_dataset(\"noise\", data=all_noise)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo (SHARED)",
   "language": "python",
   "name": "seismo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
