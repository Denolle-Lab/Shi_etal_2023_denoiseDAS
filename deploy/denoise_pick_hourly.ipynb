{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/denoiser/')\n",
    "sys.path.append('../src/ensemble_picker/')\n",
    "\n",
    "import gc\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import seisbench.models as sbm\n",
    "from ELEP.elep.ensemble_coherence import ensemble_semblance\n",
    "from ELEP.elep.trigger_func import picks_summary_simple\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from das_util import *\n",
    "from detect_util import *\n",
    "from das_denoise_models import unet\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import filtfilt, butter\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import obspy\n",
    "from obspy import UTCDateTime\n",
    "\n",
    "\n",
    "\n",
    "############################################# Loop for hours\n",
    "filepath = '/fd1/QibinShi_data/akdas/qibin_data/elep_pyocto/coast_only/'\n",
    "rawdata_dir = '/home/niyiyu/Research/DAS-NIR/datasets/earthquakes_raw/11720793/'\n",
    "model_dir = '../models/checkpoint_noatt_LRdecays0.8_mask0.5_raw2raw_chmax4500.pt'\n",
    "kkfls_dir = rawdata_dir + 'KKFL-S/'\n",
    "terra_dir = rawdata_dir + 'TERRA/'\n",
    "format_part = 'decimator2_%Y-%m-%d_%H.??.??_UTC.h5'\n",
    "### Bandpass filter\n",
    "b, a = butter(4, (0.5, 12), fs=25, btype='bandpass')\n",
    "\n",
    "### Initialize the U-net\n",
    "devc = try_gpu(i=0)\n",
    "model_1 = unet(1, 16, 1024, factors=(5, 3, 2, 2), use_att=False)\n",
    "model_1 = nn.DataParallel(model_1, device_ids=[0])\n",
    "model_1.to(devc)\n",
    "### Load the pretrained weights\n",
    "model_1.load_state_dict(torch.load(model_dir))\n",
    "model_1.eval() \n",
    "\n",
    "### ELEP models\n",
    "pn_ethz_model = sbm.EQTransformer.from_pretrained(\"ethz\")\n",
    "pn_neic_model = sbm.EQTransformer.from_pretrained(\"neic\")\n",
    "pn_scedc_model = sbm.EQTransformer.from_pretrained(\"scedc\")\n",
    "pn_stead_model = sbm.EQTransformer.from_pretrained(\"stead\")\n",
    "pn_geofon_model = sbm.EQTransformer.from_pretrained(\"geofon\")\n",
    "pn_instance_model = sbm.EQTransformer.from_pretrained(\"instance\")\n",
    "pn_ethz_model.to(devc); pn_ethz_model.eval()\n",
    "pn_neic_model.to(devc); pn_neic_model.eval()\n",
    "pn_scedc_model.to(devc); pn_scedc_model.eval()\n",
    "pn_stead_model.to(devc); pn_stead_model.eval()\n",
    "pn_geofon_model.to(devc); pn_geofon_model.eval()\n",
    "pn_instance_model.to(devc); pn_instance_model.eval()\n",
    "list_models = [pn_ethz_model,\n",
    "            pn_neic_model,\n",
    "            pn_scedc_model,\n",
    "            pn_stead_model,\n",
    "            pn_geofon_model,\n",
    "            pn_instance_model]\n",
    "fs=100; ch_itv=500  # data are downsampled to pick\n",
    "\n",
    "### Cable coordinates from Ethan Williams. We only use Ch. 500-5000\n",
    "kkfls = pd.read_csv('cable_geometry/KKFLS_coords.xycz',header=None,names=['lon','lat','cha','dep'],delim_whitespace=True)\n",
    "terra = pd.read_csv('cable_geometry/TERRA_coords.xycz',header=None,names=['lon','lat','cha','dep'],delim_whitespace=True)\n",
    "\n",
    "\n",
    "# for ihour in range(31*24):\n",
    "for ihour in tqdm(range(23,24)):\n",
    "    ############################################# Read hour data\n",
    "    print('---- Read {ihour}th hour ----')\n",
    "    t0 = UTCDateTime(\"2023-07-14\") + ihour*3600\n",
    "    fname = UTCDateTime.strftime(t0, format=format_part)\n",
    "    kkfls_files = sorted(glob.glob(kkfls_dir+fname))\n",
    "    terra_files = sorted(glob.glob(terra_dir+fname))\n",
    "\n",
    "    kkfls_data = np.zeros((len(kkfls_files), 4500, 1500), dtype=np.float32)\n",
    "    terra_data = np.zeros((len(terra_files), 4500, 1500), dtype=np.float32)\n",
    "    kkfls_btimes = np.zeros(len(kkfls_files), dtype=object)\n",
    "    terra_btimes = np.zeros(len(terra_files), dtype=object)\n",
    "\n",
    "    for i, kkfls_file in enumerate(kkfls_files):\n",
    "        with h5py.File(kkfls_file, 'r') as f:\n",
    "            time_data = f['Acquisition']['Raw[0]']['RawData'][:1500, 500:5000]\n",
    "            kkfls_data[i, :time_data.shape[1], :time_data.shape[0]] = time_data.T\n",
    "            kkfls_btimes[i] = datetime.utcfromtimestamp(f['Acquisition']['Raw[0]']['RawDataTime'][0]/1e6)\n",
    "        del time_data\n",
    "        gc.collect()\n",
    "\n",
    "    for i, terra_file in enumerate(terra_files):\n",
    "        with h5py.File(terra_file, 'r') as f:\n",
    "            time_data = f['Acquisition']['Raw[0]']['RawData'][:1500, 500:5000]\n",
    "            terra_data[i, :time_data.shape[1], :time_data.shape[0]] = time_data.T\n",
    "            terra_btimes[i] = datetime.utcfromtimestamp(f['Acquisition']['Raw[0]']['RawDataTime'][0]/1e6)\n",
    "        del time_data\n",
    "        gc.collect()\n",
    "\n",
    "    ### merge two arrays and filter\n",
    "    rawdata = np.append(kkfls_data[:, ::-1, :], terra_data[:,:,:], axis=1)\n",
    "    rawdata = np.nan_to_num(rawdata)\n",
    "    filt = filtfilt(b, a, rawdata, axis=2)\n",
    "    rawdata = filt / np.std(filt, axis=(1,2), keepdims=True)\n",
    "    len_cat = len(rawdata)\n",
    "\n",
    "    del filt, kkfls_data, terra_data, kkfls_files, terra_files, \n",
    "    gc.collect()\n",
    "\n",
    "    ############################################# Denoise\n",
    "    print('---- Denoising ----')\n",
    "    mul_denoised = np.zeros_like(rawdata)\n",
    "    for imin in np.arange(len_cat):\n",
    "        _, mul_denoised[imin,:,:] = Denoise_largeDAS(rawdata[imin], model_1, devc, repeat=4, norm_batch=False)\n",
    "    del rawdata\n",
    "    gc.collect()\n",
    "    # torch.cuda.empty_cache()\n",
    "    \n",
    "    ### Interpolate\n",
    "    interp_func = interp1d(np.linspace(0, 1, 1500), mul_denoised, axis=-1, kind='linear')\n",
    "    interpolated_muldenoised = interp_func(np.linspace(0, 1, 6000))\n",
    "\n",
    "    ############################################# Pick\n",
    "    print('---- Picking ----')\n",
    "    ### ELEP parameters\n",
    "    paras_semblance = {'dt':0.01, \n",
    "                    'semblance_order':2, \n",
    "                    'window_flag':True, \n",
    "                    'semblance_win':0.5, \n",
    "                    'weight_flag':'max'}\n",
    "    \n",
    "    sel_ch = np.arange(int(ch_itv/2), interpolated_muldenoised.shape[1], ch_itv)\n",
    "    nsta = len(sel_ch)\n",
    "    mul_picks = np.zeros([len_cat, nsta, 2, 2], dtype = np.float32)\n",
    "    for imin in np.arange(len_cat):\n",
    "        mul_picks[imin,:,:,:] = apply_elep(interpolated_muldenoised[imin,sel_ch,:], \n",
    "                                           list_models, fs, paras_semblance, devc)\n",
    "    del interpolated_muldenoised, interp_func, mul_denoised\n",
    "    gc.collect()\n",
    "    \n",
    "    ############################################# Save\n",
    "    print('---- Saving ----')\n",
    "    df_deno = pd.DataFrame(columns=[\n",
    "            'event_id',\n",
    "            'source_type',\n",
    "            'station_network_code',\n",
    "            'station_channel_code',\n",
    "            'station_code',\n",
    "            'station_location_code',\n",
    "            'station_latitude_deg',\n",
    "            'station_longitude_deg',\n",
    "            'station_elevation_m',\n",
    "            'trace_name',\n",
    "            'trace_sampling_rate_hz',\n",
    "            'trace_start_time',\n",
    "            'trace_S_arrival_sample',\n",
    "            'trace_P_arrival_sample',\n",
    "            'trace_S_onset',\n",
    "            'trace_P_onset',\n",
    "            'trace_snr_db',\n",
    "            'trace_s_arrival',\n",
    "            'trace_p_arrival'])\n",
    "\n",
    "    for ch in np.arange(nsta):\n",
    "        if ch >= (nsta/2):  # terra\n",
    "            ch1 = int(sel_ch[ch] - 4000) \n",
    "            longitude = terra.loc[ch1, 'lon']\n",
    "            latitude = terra.loc[ch1, 'lat']\n",
    "            elevation = terra.loc[ch1, 'dep']\n",
    "            b_t = terra_btimes\n",
    "        else:  # kkfls\n",
    "            ch1 = int(5000 - sel_ch[ch])\n",
    "            longitude = kkfls.loc[ch1, 'lon']\n",
    "            latitude = kkfls.loc[ch1, 'lat']\n",
    "            elevation = kkfls.loc[ch1, 'dep']\n",
    "            b_t = kkfls_btimes\n",
    "\n",
    "        p_den = [b_t[i] + timedelta(seconds=np.float64(mul_picks[i, ch, 0, 0])) if mul_picks[i, ch, 0, 1] > 0.10 else np.nan for i in range(len_cat)]\n",
    "        s_den = [b_t[i] + timedelta(seconds=np.float64(mul_picks[i, ch, 1, 0])) if mul_picks[i, ch, 1, 1] > 0.05 else np.nan for i in range(len_cat)]\n",
    "        \n",
    "        df_deno = pd.concat([df_deno, pd.DataFrame(data={\n",
    "            'event_id': [' '] * len_cat,\n",
    "            'source_type': [' '] * len_cat,\n",
    "            'station_network_code': ['CIDAS'] * len_cat,\n",
    "            'station_channel_code': [' '] * len_cat,\n",
    "            'station_code': ['das'+str(ch*100)] * len_cat,\n",
    "            'station_location_code': [' '] * len_cat,\n",
    "            'station_latitude_deg': [latitude] * len_cat,\n",
    "            'station_longitude_deg': [longitude] * len_cat,\n",
    "            'station_elevation_m': [elevation] * len_cat,\n",
    "            'trace_name': [' '] * len_cat,\n",
    "            'trace_sampling_rate_hz': [25] * len_cat,\n",
    "            'trace_start_time': b_t,\n",
    "            'trace_S_arrival_sample': [' '] * len_cat,\n",
    "            'trace_P_arrival_sample': [' '] * len_cat,\n",
    "            'trace_S_onset': [' '] * len_cat,\n",
    "            'trace_P_onset': [' '] * len_cat,\n",
    "            'trace_snr_db': [' '] * len_cat,\n",
    "            'trace_s_arrival': s_den,\n",
    "            'trace_p_arrival': p_den})], ignore_index=True)\n",
    "        \n",
    "    df_deno.to_csv(filepath+'1hour/' + 'CIDAS_' + t0.strftime('%Y%m%d_%H') + '_deno' + '.csv')\n",
    "        \n",
    "    del kkfls_btimes, terra_btimes\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "denoise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
